{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Document Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "563d8f10",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.documents import Document\n",
                "\n",
                "doc = Document(\n",
                "    page_content=\"MAIN TEXT CONTENT USED FOR THIS RAG\",\n",
                "    metadata={\n",
                "        \"source\": \"exmaple.txt\",\n",
                "        \"pages\": [1, 2, 3],\n",
                "        \"author\": \"Prajwal\",\n",
                "        \"date_created\": \"2025-12-31\"\n",
                "    }\n",
                ")\n",
                "doc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2ef8c6b5",
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_text ={\"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
                "\n",
                "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
                "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
                "programming languages in the world.\n",
                "\n",
                "Key Features:\n",
                "- Easy to learn and use\n",
                "- Extensive standard library\n",
                "- Cross-platform compatibility\n",
                "- Strong community support\n",
                "\n",
                "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
                "    \n",
                "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
                "\n",
                "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
                "from experience without being explicitly programmed. It focuses on developing computer programs\n",
                "that can access data and use it to learn for themselves.\n",
                "\n",
                "Types of Machine Learning:\n",
                "1. Supervised Learning: Learning with labeled data\n",
                "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
                "3. Reinforcement Learning: Learning through rewards and penalties\n",
                "\n",
                "Applications include image recognition, speech processing, and recommendation systems\n",
                "    \n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "}\n",
                "\n",
                "for filepath,content in sample_text.items():\n",
                "    with open(filepath,\"w\", encoding=\"utf-8\") as f:\n",
                "        f.write(content)\n",
                "\n",
                "        \n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "60e217ca",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
                    ]
                }
            ],
            "source": [
                "# In newer versions of LangChain, document loaders are moved to langchain_community\n",
                "#Text loader\n",
                "from langchain_community.document_loaders import TextLoader\n",
                "# from langchain_community.document_loaders import PyPDFLoader\n",
                "\n",
                "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
                "document = loader.load()\n",
                "\n",
                "print(document)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "d1a94c77",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'/Users/prajwal/Desktop/RAG/data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "##Creating a PDF directory for RAG \n",
                "\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "source = os.path.expanduser(\"~/Downloads/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf\")\n",
                "destination = os.path.expanduser(\"~/Desktop/RAG/data/pdf\")\n",
                "\n",
                "# Copy the directory\n",
                "shutil.copy(source, destination)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "e72934cf",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.'),\n",
                            " Document(metadata={'source': '../data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    ')]"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### Directory Loader\n",
                "from langchain_community.document_loaders import DirectoryLoader\n",
                "\n",
                "## load all the text files from the directory\n",
                "dir_loader=DirectoryLoader(\n",
                "    \"../data/text_files\",\n",
                "    glob=\"**/*.txt\", ## Pattern to match files  \n",
                "    loader_cls= TextLoader, ##loader class to use\n",
                "    loader_kwargs={'encoding': 'utf-8'},\n",
                "    show_progress=False\n",
                "\n",
                ")\n",
                "\n",
                "documents=dir_loader.load()\n",
                "documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0c848c32",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 0}, page_content='HA201\\nSAP HANA 2.0 SPS05 - High\\nAvailability and Disaster Tolerance\\nAdministration\\n.\\n.\\nPARTICIPANT HANDBOOK\\nINSTRUCTOR-LED TRAINING\\n.\\nCourse Version: 17\\nCourse Duration: 3 Day(s)\\ne-book Duration: 7 Hours 5 Minutes\\nMaterial Number: 50155431'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 1}, page_content=''),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 2}, page_content='SAP Copyrights, Trademarks and\\nDisclaimers\\n© 2020 SAP SE or an SAP affiliate company. All rights reserved.\\nNo part of this publication may be reproduced or transmitted in any form or for any purpose without the\\nexpress permission of SAP SE or an SAP affiliate company.\\nSAP and other SAP products and services mentioned herein as well as their respective logos are\\ntrademarks or registered trademarks of SAP SE (or an SAP affiliate company) in Germany and other\\ncountries. Please see http://global12.sap.com/corporate-en/legal/copyright/index.epx\\n for additional\\ntrademark information and notices.\\nSome software products marketed by SAP SE and its distributors contain proprietary software\\ncomponents of other software vendors.\\nNational product specifications may vary.\\nThese materials may have been machine translated and may contain grammatical errors or\\ninaccuracies.\\nThese materials are provided by SAP SE or an SAP affiliate company for informational purposes only,\\nwithout representation or warranty of any kind, and SAP SE or its affiliated companies shall not be liable\\nfor errors or omissions with respect to the materials. The only warranties for SAP SE or SAP affiliate\\ncompany products and services are those that are set forth in the express warranty statements\\naccompanying such products and services, if any. Nothing herein should be construed as constituting an\\nadditional warranty.\\nIn particular, SAP SE or its affiliated companies have no obligation to pursue any course of business\\noutlined in this document or any related presentation, or to develop or release any functionality\\nmentioned therein. This document, or any related presentation, and SAP SE’s or its affiliated companies’\\nstrategy and possible future developments, products, and/or platform directions and functionality are\\nall subject to change and may be changed by SAP SE or its affiliated companies at any time for any\\nreason without notice. The information in this document is not a commitment, promise, or legal\\nobligation to deliver any material, code, or functionality. All forward-looking statements are subject to\\nvarious risks and uncertainties that could cause actual results to differ materially from expectations.\\nReaders are cautioned not to place undue reliance on these forward-looking statements, which speak\\nonly as of their dates, and they should not be relied upon in making purchasing decisions.\\n© Copyright. All rights reserved.\\niii'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 3}, page_content='Typographic Conventions\\nAmerican English is the standard used in this handbook.\\nThe following typographic conventions are also used.\\nThis information is displayed in the instructor’s presentation\\nDemonstration\\nProcedure\\nWarning or Caution\\nHint\\nRelated or Additional Information\\nFacilitated Discussion\\nUser interface control\\nExample text\\nWindow title\\nExample text\\n© Copyright. All rights reserved.\\niv'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 4}, page_content='Contents\\nvi\\nCourse Overview\\n1\\nUnit 1:\\nSAP HANA High Availability Features Overview\\n2\\nLesson: Explaining the SAP HANA High Availability Features\\n9\\nLesson: Exploring Disaster Recovery in SAP HANA\\n14\\nLesson: Exploring Fault Recovery in SAP HANA\\n24\\nUnit 2:\\nSAP HANA Fault Tolerance\\n26\\nLesson: Installing High Availability SAP HANA\\n34\\nLesson: Explaining SAP HANA Scale-Out\\n39\\nLesson: Partitioning Tables\\n51\\nLesson: Table Placement\\n63\\nLesson: Reconfiguring a Scale-Out SAP HANA System\\n68\\nLesson: Understanding Failure of an SAP HANA Slave Node\\n76\\nLesson: Understanding Failure of the SAP HANA Master Node\\n83\\nLesson: Removing a Host from a Scale-Out System\\n87\\nLesson: Adding a Host to a Scale-Out System\\n102\\nUnit 3:\\nSAP HANA Disaster Tolerance\\n104\\nLesson: Explaining SAP HANA Storage Replication\\n108\\nLesson: Explaining SAP HANA System Replication\\n117\\nLesson: Setting up SAP HANA System Replication\\n133\\nLesson: Creating Tenant Databases in a System Replication\\nScenario\\n135\\nLesson: Performing a Takeover on the Secondary System\\n146\\nLesson: Setting up Active/Active System Replication\\n150\\nLesson: Setting up SAP HANA System Replication with Secondary\\nTime Travel\\n156\\nLesson: Explaining Zero Downtime Maintenance\\n159\\nLesson: Introducing Multitier and Multitarget System Replication\\n176\\nUnit 4:\\nSAP HANA Tenant Replication\\n177\\nLesson: Explaining Tenant Replication\\n187\\nUnit 5:\\nAppendix: HANA Additional Scripts\\n188\\nLesson: Appendix: Using Python Support Scripts in SAP HANA\\n195\\nLesson: Appendix: Reinitializing a Non-Recoverable System\\nDatabase\\n© Copyright. All rights reserved.\\nv'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 5}, page_content='Course Overview\\nTARGET AUDIENCE\\nThis course is intended for the following audiences:\\nTechnology Consultant\\nDatabase Administrator\\nSystem Administrator\\n© Copyright. All rights reserved.\\nvi'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 6}, page_content='UNIT 1\\nSAP HANA High\\nAvailability Features\\nOverview\\nLesson 1\\nExplaining the SAP HANA High Availability Features\\n2\\nLesson 2\\nExploring Disaster Recovery in SAP HANA\\n9\\nLesson 3\\nExploring Fault Recovery in SAP HANA\\n14\\nUNIT OBJECTIVES\\nUnderstand the different SAP HANA high availability features\\nDescribe the disaster recovery features in SAP HANA\\nExplain the fault recovery features of SAP HANA\\n© Copyright. All rights reserved.\\n1'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 7}, page_content='Unit 1\\nLesson 1\\nExplaining the SAP HANA High Availability\\nFeatures\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nUnderstand the different SAP HANA high availability features\\nSAP HANA High Availability\\nBusiness Example\\nFor your company’s SAP ERP and SAP Business Warehouse (SAP BW) systems, high\\navailability and disaster tolerance are important requirements that need to be built into the\\nlandscape architecture.\\nYour SAP ERP and SAP BW systems are running on the SAP HANA database, which is why\\nyou are looking into the native high availability and disaster tolerance features of the SAP\\nHANA database system. You want to learn how to incorporate these features into your\\ncompany’s landscape architecture.\\nSAP HANA and High Availability\\nSAP HANA is specifically developed to take full advantage of the capabilities provided by\\nmodern hardware to increase application performance. By keeping all relevant data in the\\nmain memory, data processing operations are significantly accelerated.\\nAnother core design principle for SAP HANA is scalability. The SAP HANA database can be\\ndistributed across multiple hosts to achieve scalability in terms of size and user concurrency.\\nA distributed (also called “scale-out”) SAP HANA system spreads the data efficiently over the\\navailable servers, thereby achieving high scaling without I/O delays.\\nFor a company, the loss of critical business systems directly translates into loss of revenue. In\\nalmost every company, this is unacceptable. Therefore, the goal of every company should be\\nbusiness continuity, and consequently they should use systems designed for continuous\\noperation even in the presence of inevitable failures. These mission-critical systems require\\nhigh availability that is built-in on every level of the landscape, and should not rely on external\\ntools to provide these features.\\n© Copyright. All rights reserved.\\n2'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 8}, page_content='Figure 1: Continuous Availability Overview\\nThe SAP HANA database platform is designed with high availability and disaster tolerance in\\nmind. SAP HANA supports a broad range of recovery scenarios, from simple software errors\\nor hardware failures, to disasters that take out an entire site.\\nWhat is High Availability?\\nAvailability is usually indicated as a percentage of the operational uptime of a system,\\nmeasured over the course of a year. For example, if a system is designed to be available\\n99.99% of the time (sometimes called \"four nines\"), its downtime per year must be less than\\n0.01%, or 52 minutes and 56 seconds.\\nThat means less than an hour of downtime per year. This can be a very challenging target. To\\nmeet such challenging targets, high availability and disaster tolerance should be an integral\\npart of the architectural design, that is, implemented on every layer of the infrastructure.\\nDowntime is the consequence of outages, which may be planned downtime (such as that for\\nsystem upgrades or hardware replacements) or caused by unplanned downtime (such as that\\nfor software or hardware failures). Unplanned downtime can be triggered by equipment\\nmalfunction, software, or network failures, or a major disaster such as a fire, earthquake, a\\nregional power loss, or a construction accident which may decommission the entire data\\ncenter.\\nHigh Availability is a set of techniques, engineering practices, and design principles for\\nbusiness continuity. This is achieved by eliminating single points of failure (fault tolerance),\\nand providing the ability to rapidly resume operations after a system outage with minimal\\nbusiness loss (fault resilience).\\nFault Recovery is the process of recovering and resuming normal operations after an outage\\ndue to a fault.\\nLesson: Explaining the SAP HANA High Availability Features\\n© Copyright. All rights reserved.\\n3'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 9}, page_content='Disaster Recovery is the process of recovering operations after an outage due to a prolonged\\ndata center or site failure. Preparing for disasters may require backing up data across longer\\ndistances, and may thus be more complex and costly.\\nRecovery - Key Performance Indicators (KPIs)\\nCustomers commonly use two key measures to specify the recovery parameters of a system\\nfollowing an outage, the Recovery Point Objective (RPO) and the Recovery Time Objective\\n(RTO). The RPO and RTO of a system are illustrated in the following figure.\\nFigure 2: RPO and RTO\\nThe RPO is the maximum permissible amount of time during which operational data may\\nbe lost without the ability to recover. It is the time between the last backup (data or log)\\nand the crash. Almost every customer tries to achieve an RPO of 0, because the loss of\\nbusiness data is unacceptable.\\nThe RTO is the maximum permissible amount of time it takes to recover the system, so\\nthat normal operations can resume. Many companies aim for a near-zero RTO, because\\nduring the RTO period, normal business is interrupted. Interrupted business leads to loss\\nin revenue, which should be avoided as much as possible.\\nEliminating Single Points of Failure\\nThe key to achieving fault tolerance is to eliminate single points of failure by introducing\\nredundancy. SAP HANA hardware vendors deliver several levels of redundancy to avoid\\noutage due to component failure.\\nGenerally speaking, these techniques are transparent to SAP HANA’s operation.\\nNevertheless, they form a crucial line of defense against avoidable system outage, and\\ntherefore greatly contribute to business continuity.\\nHardware Redundancy\\nSAP HANA hardware vendors design multiple layers of redundancy in their hardware\\ncomponents and subsystems. These include redundant and hot-swappable Power\\nSupply Units (PSUs), fans, network interface cards, and enterprise-grade, error-\\ncorrecting code memory.\\nThese subsystems are designed in such a way that the redundant components can\\nsustain operations of the system even when other components fail.\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n4'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 10}, page_content='The storage system is particularly critical. Enterprise-grade storage systems combine\\nmultiple physical drives into logical units, with built-in standard Redundant Array of\\nIndependent Disks (RAID) techniques for redundancy and error recovery. These include\\nmirroring (the writing of the same data to two different drives in parallel) and parity (the\\nwriting of extra bits to allow the detection and automatic correction of errors).\\nNetwork Redundancy\\nRedundant networks, network equipment, and network connectivity are required to avoid\\nnetwork failures affecting system availability. This is typically accomplished by deploying\\na completely redundant switch topology, using the Spanning Tree Protocol (STP) to\\navoid loops.\\nRouters can be configured with the Hot Standby Router Protocol (HSRP) for automatic\\nfailover. The Border Gateway Protocol (BGP) is commonly used to manage dual WAN\\nconnections.\\nData Center Redundancy\\nData centers that host SAP HANA solutions are equipped with Uninterrupted Power\\nSupply (UPS) units and backup power generators, redundant cooling systems, and multi-\\nsourced providers of network connectivity and electricity. This is done to achieve\\noperational availability in the presence of individual failures, and the significant reduction\\nof the probability of a business-impacting outage. Some enterprises operate fully\\nduplicated data centers, providing a high level of disaster tolerance.\\nSAP HANA High Availability Support\\nAs an in-memory database, SAP HANA must not only concern itself with maintaining the\\nreliability of its data in the event of failures. It should also be concerned with resuming\\noperations as quickly as possible with most of its data loaded back into memory.\\nThe following figure shows the phases of SAP HANA High Availability support.\\nFigure 3: SAP HANA RPO and RTO Support\\nPrepare Phase\\nThis first phase means being ready for disaster. During this time, the database is\\nregularly backed up (data and log backups). The local or remote standby systems are\\noperational and ready to take over.\\nLesson: Explaining the SAP HANA High Availability Features\\n© Copyright. All rights reserved.\\n5'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 11}, page_content='This phase is often taken for granted, because everything is working within the defined\\nparameters. Due to this relaxed attitude, some check procedures might be skipped. This\\nis a disaster waiting to happen. Ensure that there are checks in place.\\nDetect Phase\\nBefore a takeover can be initiated, a fault must be detected. This fault detection can be\\ndone automatically or manually. In both cases, false positives must be avoided, so a\\nfailure must be re-tested.\\nTry to keep the detect phase as short as possible to avoid the loss of revenue while\\nsystems are down.\\nRecover Phase\\nWhen a real failure has been detected, the takeover is triggered. Depending on the fault,\\ndifferent recovery processes can be triggered. The different recovery processes have\\ndifferent recovery runtimes. The runtime is also heavily dependent on the available\\nhardware resources.\\nRamp-up Phase\\nAs soon as recovery is completed, the system is available in a ramp-up state. This is due\\nto the fact that not all the data is loaded into memory yet and external interfaces might\\nstill be initializing.\\nTo optimize this phase, you could investigate which data is needed most, so that this data\\ncan be loaded first.\\nFailback Phase\\nWhen all of the other phases are complete, the fault needs to be repaired. This can be a\\nhardware repair or software updates. Both take time and may require additional testing\\nbefore being applied to the production system.\\nWhen these repairs are done, the system may need to failback to the original data center\\nand hardware. This can be triggered immediately or at the next data center maintenance\\nwindow. If and when this failback is triggered is up to the customer, because this depends\\non contracts and service level agreements with third-party vendors and may involve\\nadditional costs.\\nSAP HANA Recovery Features\\nDifferent RPO and RTO values can be associated with different kinds of faults. Business-\\ncritical systems are expected to operate with an RPO of zero data loss in the case of local\\nfaults, and often even in the case of a disaster.\\nThe challenges of disaster recovery are different for locally recoverable faults compared to\\ntotal disasters. To achieve zero RPO and low RTO in a total disaster, data must be replicated\\nsynchronously over longer distances, which impacts regular system performance and may\\nrequire more expensive standby and failover solutions.\\nAll of this leads to trade-off decisions around the attributes of fault recovery functionality,\\ncost, and complexity. SAP offers complementary design options, including three levels of\\ndisaster recovery support and three levels of automatic fault recovery support. These are\\nsummarized in the following table. More details on fault recovery and disaster recovery are\\nprovided in the next units of this course.\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n6'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 12}, page_content='Figure 4: SAP HANA Recovery Features\\nFault Recovery Support\\nLocal faults, such as hardware and software failures, can often be handled in the same data\\ncenter and hardware. Possible solutions to repair the error include restarting a failing service\\non the same server, or switching to a new host in the same data center. Such solutions can be\\nimplemented at almost no extra cost, as they are often a default part of the software and\\nhardware solution provided by hardware vendors.\\nService Auto-Restart\\nIn the event of a software failure of one of the configured SAP HANA services (Index\\nServer, Name Server, and so on), the failing service is restarted by the SAP HANA service\\nauto-restart watchdog function.\\nThis watchdog function is provided by the SAP HANA daemon process, which\\nautomatically detects the failure and restarts the stopped service process. Upon restart,\\nthe service loads data into memory and resumes its function. While all data remains safe,\\nthe service recovery takes some time.\\nSAP HANA Auto-Restart\\nThe SAP HANA database system can be configured in an auto-restart mode. This can be\\nuseful after a power failure. When the power returns and the Linux operating system has\\nbeen started successfully, the SAP HANA database system automatically performs a\\nstartup and recovery. The SAP HANA database system is available again for normal\\noperations as soon as the startup and recovery is finished.\\nHost Auto-Failover\\nThis is a local fault recovery solution that can be used in addition to, or as an alternative\\nmeasure to, system replication. One or more hosts are added to an SAP HANA database\\nsystem. These additional hosts are configured to work in standby mode.\\nAs long as they are in standby mode, the databases on these hosts do not contain any\\ndata and do not accept requests or queries. This means these additional standby hosts\\ncannot be used for other purposes, such as quality or test systems.\\nDisaster Recovery Support\\nBackups\\nSAP HANA is an in-memory database, but all the data is persisted on disk as well. Data is\\npersisted on disk by means of regular savepoints. These savepoints are performed by\\ndefault every five minutes. In between these savepoints, all the changes are recorded in\\ntransaction redo logs.\\nLesson: Explaining the SAP HANA High Availability Features\\n© Copyright. All rights reserved.\\n7'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 13}, page_content='To make sure that SAP HANA can recover from hardware failures, regular data and log\\nbackups must be performed. These data and log backups must be shipped to the\\nsecondary site to make sure that the system can recover from a total disaster.\\nStorage Replication\\nThis is a method to continuously replicate all persisted data and log information to the\\nsecondary site. Several SAP HANA hardware partners offer a storage-level replication\\nsolution, which delivers a backup of the volumes or file-system to a remote, networked\\nstorage system.\\nSystem Replication\\nThis is a native SAP HANA high availability solution that provides a continuously-\\nreplicated SAP HANA system on the secondary site. The data is already loaded into\\nmemory, so takeover times are short in comparison to backup and storage replication\\nsolutions.\\nSystem Replication Active/Active\\nThis is a second native SAP HANA system replication solution that allows the data to be\\nread from the secondary system. In this setup, the secondary system can be used to\\nhandle the reporting workload without disrupting the primary system.\\nSystem Replication without Data Preload\\nThis is a third native SAP HANA scenario. In this solution, the secondary system does not\\npre-load data, and hence consumes very little memory. This allows the hosts of the\\nsecondary system to serve dual purposes. For example, for development, unit testing, or\\nQA with separate storage. Before takeover, these activities must of course be turned off.\\nThe trade-off in this scenario is a longer RTO in the case of failover.\\nLESSON SUMMARY\\nYou should now be able to:\\nUnderstand the different SAP HANA high availability features\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n8'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 14}, page_content='Unit 1\\nLesson 2\\nExploring Disaster Recovery in SAP HANA\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nDescribe the disaster recovery features in SAP HANA\\nDisaster Recovery Support\\nBusiness Example\\nAs a SAP HANA database administrator, you are responsible for your company’s SAP ERP\\nand SAP Business Warehouse (SAP BW) systems. You need to understand which disaster\\nrecovery features are supported by the SAP HANA database.\\nBackups\\nBackups are one of the key disaster recovery features offered by SAP HANA.\\nSAP HANA uses in-memory technology, but of course, it fully persists any transaction that\\nchanges the data, such as row insertions, deletions, and updates, so it can resume from a\\npower outage without loss of data. SAP HANA persists two types of data to the storage\\nsystem, transaction redo logs and data changes in the form of savepoints.\\nFigure 5: SAP HANA Backups\\nA transaction redo log is used to record a change. To make a transaction durable, it is not\\nrequired to persist the complete data when the transaction is committed. Instead, it is\\nsufficient to persist the redo log. On failure, the most recent consistent state of the database\\n© Copyright. All rights reserved.\\n9'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 15}, page_content='can be restored by replaying the changes recorded in the log, redoing completed\\ntransactions, and rolling back incomplete transactions.\\nA savepoint is a periodic point in time when all the changed data is written to storage, in the\\nform of pages. One goal of performing savepoints is to speed up restart. When starting a\\nsystem, logs need not be processed from the beginning, but only from the last savepoint\\nposition. Savepoints are coordinated across all processes (called SAP HANA services) and\\ninstances of the database to ensure transaction consistency. By default, savepoints are\\nperformed every five minutes, but this value is configurable.\\nSavepoints normally overwrite older savepoints, but it is possible to freeze a savepoint for\\nfuture use. This is called a snapshot. Snapshots can be replicated in the form of full data\\nbackups, which can be used to restore a database to a specific point in time. This can be\\nuseful in the event of data corruption, for instance. In addition to data backups, smaller\\nperiodic log backups ensure the ability to recover from fatal storage faults with minimal loss\\nof data.\\nSavepoints can be saved to local storage, and the additional backups can be saved to backup\\nstorage. Local recovery from the crash uses the latest savepoint, and then replays the last\\nlogs, to recover the database without any data loss. If the local storage was corrupted by the\\ncrash, it is still possible to recover the database from the data and log backups, possibly with\\nsome loss of data. Regularly shipping backups to a remote location over a network or using\\ncouriers can be a simple and relatively inexpensive way to prepare for a disaster. Depending\\non the frequency and shipping method, this approach may have a recovery time ranging from\\nhours to days.\\nStorage Replication\\nSAP HANA offers disaster recovery support for storage replication solutions provided by\\nhardware partners.\\nOne drawback of backups is the potential loss of data between the time of the last backup and\\nthe time of the failure. A preferred solution is to provide continuous replication of all persisted\\ndata. Several SAP HANA hardware partners offer a storage-level replication solution that\\ndelivers a backup of the volumes or file system to a remote, networked storage system. In\\nsome of these vendor-specific solutions, which are certified by SAP, the SAP HANA\\ntransaction only completes when the locally persisted transaction log has been replicated\\nremotely. This is called synchronous storage replication. Synchronous storage replication can\\nbe used only where the distance between the primary and backup site is relatively short\\n(typically 100 kilometers or less), allowing for sub-millisecond round-trip latencies.\\nDue to its continuous nature, storage replication (sometimes also called remote storage\\nmirroring) can be a more attractive option than backups, as it reduces the amount of time\\nbetween the last backup and a failure. Another advantage of storage replication is that it also\\nenables a much shorter recovery time. This solution requires a reliable, high-bandwidth and\\nlow-latency connection between the primary site and the secondary site.\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n10'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 16}, page_content='Figure 6: SAP HANA Storage Replication\\nDue to its continuous nature, storage replication (sometimes called “remote storage\\nmirroring”) offers a more attractive RPO than backups, but this solution of course requires a\\nreliable, high bandwidth, and low latency connection between the primary site and the\\nsecondary site.\\nIn the event of a total disaster that justifies full system failover, an administrator attaches a\\nstandby system to the replicated storage. The administrator then restarts the SAP HANA\\nsystem. The administrator must ensure that the failed primary system can no longer write to\\nthe replicated storage by fencing it from the primary system. If the primary system is not\\nfenced, then there is a risk of data corruption. This corruption can occur because two systems\\ncan write to the same storage at the same time.\\nSystem Replication\\nSystem replication is available in every SAP HANA installation offering inherent disaster\\nrecovery support.\\nSystem replication is an alternative high availability solution for SAP HANA that provides an\\nextremely short RTO, and is compatible with all SAP HANA hardware partner solutions.\\nSystem replication employs an \"N+N\" approach, with a secondary standby SAP HANA\\nsystem with the same number of active nodes as the active, primary system. Each service and\\ninstance of the primary SAP HANA system communicates pairwise with a counterpart in the\\nsecondary system.\\nThe secondary system can be located near the primary system to serve as a rapid failover\\nsolution for planned downtime, or to handle storage corruption or other local faults.\\nAlternatively, it can be installed in a remote site to be used in a disaster recovery scenario.\\nIn addition, both approaches can be chained together with multi-tier system replication. Like\\nstorage replication, this disaster recovery option requires a reliable connection channel\\nbetween the primary and secondary sites. The instances in the secondary system operate in\\nrecovery mode. In this mode, all secondary system services constantly communicate with\\ntheir primary counterparts, replicate and persist data and logs, and load data to memory. The\\nmain difference to primary systems is that the secondary systems do not accept requests or\\nqueries.\\nLesson: Exploring Disaster Recovery in SAP HANA\\n© Copyright. All rights reserved.\\n11'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 17}, page_content='Figure 7: SAP HANA System Replication\\nWhen the secondary system is started in recovery mode, each service component establishes\\na connection with its counterpart, and requests a snapshot of the data in the primary system.\\nFrom then on, all logged changes in the primary system are replicated. Whenever logs are\\npersisted in the primary system, they are also sent to the secondary system. A transaction in\\nthe primary system is not committed until the logs are replicated.\\nExplaining the HA201 System Landscape\\nThe system landscape created for the HA201 course is a landscape with five Linux servers.\\nFour of these servers are used for installations of the high availability SAP HANA scale-out\\nsystem and the SAP HANA system replication systems. The fifth server is an SAP HANA\\ncockpit 2.0 system that is used to configure and monitor the installed high availability and\\ndisaster recovery systems.\\nDuring the exercises, we simulate crashes of SAP HANA nodes, so that we can monitor what\\nhappens to the rest of the SAP HANA system. Every group of four participants gets a\\nlandscape as shown in the following figure.\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n12'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 18}, page_content='Figure 8: HA201 Course System Landscape\\nDuring the scale-out and tenant administration exercises, all the Linux servers are grouped\\ntogether into one SAP HANA scale-out system with four nodes. This four-node scale-out\\nsystem is installed and re-configured, and failures of slave and master nodes are simulated.\\nIn this setup, every participant has a Linux server to work through the exercises. As some\\nsteps of the exercises can only be performed one at a time, or even only once, these steps are\\nevenly divided over the groups of four participants.\\nDuring the system replication exercises, the four Linux servers are split into two sets of two\\nservers. Participants 1 and 2 become Group AB, and participants 3 and 4 become Group CD.\\nIn every group, the SAP HANA system replication setup is installed, configured and tested. In\\nthe last exercise, the SAP HANA system replication with Active/Active is set up and tested.\\nLESSON SUMMARY\\nYou should now be able to:\\nDescribe the disaster recovery features in SAP HANA\\nLesson: Exploring Disaster Recovery in SAP HANA\\n© Copyright. All rights reserved.\\n13'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 19}, page_content='Unit 1\\nLesson 3\\nExploring Fault Recovery in SAP HANA\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nExplain the fault recovery features of SAP HANA\\nFault Recovery in SAP HANA\\nBusiness Example\\nAs an SAP HANA database administrator, you are responsible for your company’s SAP ERP\\nand SAP Business Warehouse (BW) systems. You need to understand the SAP HANA startup\\nframework, and how the SAP HANA database handles hardware and software faults.\\nService Auto-restart\\nIn the event of a software failure that disables one of the configured SAP HANA services\\n(index server, name server, and so on), the failing service is restarted by the SAP HANA\\nService Auto-Restart watchdog function, which automatically detects the failure and restarts\\nthe stopped service process. Upon restart, the service loads data into memory and resumes\\nits function. While all data remains safe (RPO=0), the service recovery takes some time.\\nThe restarting of the failing SAP HANA services is handled by the SAP HANA daemon service.\\nOne of the tasks of this service is to watch over the other HDB services and restart them if\\nnecessary. The SAP HANA daemon itself is started by the SAP HANA startup framework. This\\nframework resembles the SAP NetWeaver startup framework and is shown in the following\\nfigure.\\nFigure 9: SAP HANA Startup Framework\\n© Copyright. All rights reserved.\\n14'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 20}, page_content='When a Linux server boots, the boot process goes through several stages that are executed\\nby different components:\\n1. BIOS/UEFI\\nAfter turning on the computer, the BIOS or the UEFI initializes the different basic hardware\\ncomponents, such as the screen and keyboard, and tests the main memory. As soon as\\nthe first bootable hard disk is identified, the BIOS/UEFI passes control to the boot loader.\\n2. Boot Loader\\nLocated on the first data sector of the first hard disk, the master boot record is loaded into\\nthe main memory. On Linux systems, this boot loader is usually GRUB 2. When the boot\\nloader is finished, it passes control to the operating system.\\n3. Operating System\\nWhen the boot loader passes control to the operating system, the Linux kernel and initial\\nRAM-based file system (initramfs) are loaded into memory.\\n4. init process\\nFrom the initramfs, the init executable is started, and then it mounts the root file system.\\nWhen the root file system is successfully mounted, control is passed to the systemd\\ndaemon. The initramfs file system is cleared.\\n5. systemd daemon\\nThe systemd daemon takes care of the booting of the rest of the operating system. The\\nsystemd daemon mounts all the defined file systems and starts the required services.\\nWhen this is finished, the Linux operating system is available for the user.\\nWhen a Linux server boots, as described in the previous steps, the systemd daemon\\nidentifies into which “target” (formerly known in System V as “runlevel”) the server needs\\nto be started. When the target runlevel is identified, the systemd daemon starts the\\nrequired programs belonging to that target runlevel.\\nAn overview of the available target runlevels on the server can be generated with the\\ncommand: systemctl list-units --type=target\\n.\\nIn the different target runlevels, only the required start scripts, programs, or daemons are\\nstarted. One of these start scripts is the sapinit script found in the \\n/etc/init.d\\n folder.\\nThe sapinit script is installed on the server during the SAP HANA installation.\\n1. The sapinit script reads the /usr/sap/sapservices\\n file and starts the sapstartsrv\\ndaemon.\\n2. The sapstartsrv then reads the SAP HANA instance profile and starts the sapstart\\nexecutable.\\n3. The sapstart program reads the SAP HANA instance profile also to see if the SAP HANA\\ndatabase needs to be started automatically.\\nLesson: Exploring Fault Recovery in SAP HANA\\n© Copyright. All rights reserved.\\n15'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 21}, page_content='Figure 10: SAP HANA Cockpit Process Overview\\nFrom the SAP HANA cockpit 2.0 in the Manage Services application, all the running SAP\\nHANA services are shown. The column Process ID is very interesting here, as it shows the\\nprocess ID (PID) of the SAP HANA services. The PID of the daemon process is also shown.\\nThis PID can also be found at the Linux operating system level. In this way, you can easily\\nidentify the SAP HANA services at the operating system level.\\nFigure 11: Operating System Process Overview\\nThe process list can also be shown at the Linux operating system level. Showing processes\\nunder Linux can be done in many ways, for example, using the command ps fx -o\\nppid,pid,args --sort=ppid\\n.\\nThis command not only shows the PIDs of all the SAP HANA services, but also their starting\\norder and hierarchy. In the previous figure, it is clearly visible that the init process starts\\nsapstart.\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n16'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 22}, page_content='The sapstart process in turn starts the SAP HANA daemon process. In the operating system\\nprocess overview, this process is not called daemon, but by looking at the PID you can see\\nthat it is indeed the SAP HANA daemon.\\nThe SAP HANA daemon, often referred to in the documentation as hdbdaemon, is\\nresponsible for starting all the other SAP HANA services such as:\\nhdbnameserver\\nhdbcompileserver\\nhdbpreprocessor\\nhdbindexserver\\nhdbxsengine\\nhdbwebdispatcher\\nThis previous list is not fixed, as it depends on the SAP HANA version and on the SAP HANA\\ntenant configuration.\\nSAP HANA Autostart\\nThe SAP HANA database can be started, stopped, and restarted at the Linux operating\\nsystem level. This is often needed to automate tasks. The scripts need the information\\ncontained in the startup profile.\\nThe startup profile can be found in the location /usr/sap/<SID>/SYS/profile\\n. The\\nstartup profile lists the SAPSYSTEMNAME, SAPSYSTEM, INSTANCE_NAME, and\\nSAPLOCALHOST, but none of these parameters should be modified.\\nFigure 12: SAP HANA Instance Profile\\nThe only exception is the Autostart parameter. This parameter controls the automatic start of\\nthe SAP HANA database by the sapstart process.\\nIf Autostart=0, the SAP HANA database does not automatically start when the operating\\nsystem starts.\\nLesson: Exploring Fault Recovery in SAP HANA\\n© Copyright. All rights reserved.\\n17'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 23}, page_content='This can be very useful if there are several SAP HANA databases (such as, end-user\\ntraining and test) installed on one server that should be manually stopped and started as\\nneeded by the system administrator.\\nIf Autostart=1, the SAP HANA database starts automatically when the operating system\\nstarts.\\nThis can be very useful for a production system that needs to be available as soon as\\npossible after a hardware failure, or for an SAP HANA database that should be\\nautomatically available after the scripted deployment of a fresh virtual image.\\nHost Auto-failover\\nHost auto-failover is a local \"N+m\" (m is often 1) fault recovery solution that can be used as a\\nsupplemental or alternative measure to the system replication solution described earlier. One\\n(or more) standby hosts are added to an SAP HANA system and configured to work in\\nstandby mode. As long as they are in standby mode, the databases on these hosts do not\\ncontain any data and do not accept requests or queries.\\nFigure 13: SAP HANA Host Auto-failover\\nWhen an active (worker) host fails, a standby host automatically takes its place. Because the\\nstandby host may take over operation from any of the primary hosts, it needs access to all the\\ndatabase volumes. This can be accomplished by using a shared, networked storage server, by\\nusing a distributed file system, or with vendor-specific solutions that use an SAP HANA\\nprogrammatic interface (the Storage Connector API) to dynamically detach and attach\\n(mount) networked storage (for example, using block storage over Fiber Channel) upon\\nfailover.\\nLESSON SUMMARY\\nYou should now be able to:\\nExplain the fault recovery features of SAP HANA\\nUnit 1: SAP HANA High Availability Features Overview\\n© Copyright. All rights reserved.\\n18'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 24}, page_content='Unit 1\\nLearning Assessment\\n1. Which of the following are the two Key Performance Indicators (KPIs) for a system\\nrecovery after a failure?\\nChoose the correct answers.\\nX\\nA PSU\\nX\\nB BGP\\nX\\nC RPO\\nX\\nD RTO\\n2. What are SAP HANA High Availability support phases?\\nChoose the correct answers.\\nX\\nA Prepare phase\\nX\\nB Disaster phase\\nX\\nC Downtime phase\\nX\\nD Recover phase\\n3. A savepoint is executed at every commit to make sure that every change is persisted on\\ndisk.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n4. What are the native SAP HANA disaster recovery features?\\nChoose the correct answers.\\nX\\nA Backups\\nX\\nB System Replication\\nX\\nC Storage Replication\\nX\\nD Host Auto-Failover\\n© Copyright. All rights reserved.\\n19'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 25}, page_content='5. Only backups are offered in the SAP HANA database for disaster recovery.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n6. In the event of a software failure, sapstartsrv restarts the failed SAP HANA services.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n7. Which services are part of the SAP HANA Startup Framework?\\nChoose the correct answers.\\nX\\nA sapcontrol\\nX\\nB sapstartsrv\\nX\\nC sapservices\\nX\\nD sapstart\\n8. Which services are part of the SAP HANA Startup Framework?\\nChoose the correct answers.\\nX\\nA sapcontrol\\nX\\nB sapstartsrv\\nX\\nC sapservices\\nX\\nD sapstart\\nUnit 1: Learning Assessment\\n© Copyright. All rights reserved.\\n20'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 26}, page_content='Unit 1\\nLearning Assessment - Answers\\n1. Which of the following are the two Key Performance Indicators (KPIs) for a system\\nrecovery after a failure?\\nChoose the correct answers.\\nX\\nA PSU\\nX\\nB BGP\\nX\\nC RPO\\nX\\nD RTO\\nYou are correct! The two Key Performance Indicators (KPIs) for a system recovery after a\\nfailure are the Recovery Period Objective (RPO) and the Recovery Time Objective (RTO).\\n2. What are SAP HANA High Availability support phases?\\nChoose the correct answers.\\nX\\nA Prepare phase\\nX\\nB Disaster phase\\nX\\nC Downtime phase\\nX\\nD Recover phase\\nYou are correct! The SAP HANA High Availability support phases are: the Prepare phase\\nand the Recover phase.\\n3. A savepoint is executed at every commit to make sure that every change is persisted on\\ndisk.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! A write to the transaction log is executed with every commit. A savepoint\\nis executed, by default, every five minutes.\\n© Copyright. All rights reserved.\\n21'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 27}, page_content='4. What are the native SAP HANA disaster recovery features?\\nChoose the correct answers.\\nX\\nA Backups\\nX\\nB System Replication\\nX\\nC Storage Replication\\nX\\nD Host Auto-Failover\\nYou are correct! Backups and System Replication are the native SAP HANA disaster\\nrecovery features.\\n5. Only backups are offered in the SAP HANA database for disaster recovery.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! Storage replication and system replication are also available for disaster\\nrecovery.\\n6. In the event of a software failure, sapstartsrv restarts the failed SAP HANA services.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! In the event of a software failure, the HDBdaemon restarts the failed SAP\\nHANA services.\\n7. Which services are part of the SAP HANA Startup Framework?\\nChoose the correct answers.\\nX\\nA sapcontrol\\nX\\nB sapstartsrv\\nX\\nC sapservices\\nX\\nD sapstart\\nYou are correct! The services sapstart and sapstartsrv are part of the SAP HANA Startup\\nFramework.\\nUnit 1: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n22'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 28}, page_content='8. Which services are part of the SAP HANA Startup Framework?\\nChoose the correct answers.\\nX\\nA sapcontrol\\nX\\nB sapstartsrv\\nX\\nC sapservices\\nX\\nD sapstart\\nYou are correct! The services sapstart and sapstartsrv are part of the SAP HANA Startup\\nFramework.\\nUnit 1: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n23'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 29}, page_content='UNIT 2\\nSAP HANA Fault\\nTolerance\\nLesson 1\\nInstalling High Availability SAP HANA\\n26\\nLesson 2\\nExplaining SAP HANA Scale-Out \\n34\\nLesson 3\\nPartitioning Tables\\n39\\nLesson 4\\nTable Placement\\n51\\nLesson 5\\nReconfiguring a Scale-Out SAP HANA System\\n63\\nLesson 6\\nUnderstanding Failure of an SAP HANA Slave Node\\n68\\nLesson 7\\nUnderstanding Failure of the SAP HANA Master Node\\n76\\nLesson 8\\nRemoving a Host from a Scale-Out System\\n83\\nLesson 9\\nAdding a Host to a Scale-Out System\\n87\\nUNIT OBJECTIVES\\nInstall a high availability SAP HANA system\\nIntroducing SAP HANA scale-out systems\\n© Copyright. All rights reserved.\\n24'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 30}, page_content='Perform table partitioning tasks\\nPerform Table Placement Tasks\\nReconfigure a scale-out SAP HANA system\\nUnderstand what happens during a failure of a slave node\\nUnderstand what happens during a failure of the master node\\nRemove a host from a scale-out system\\nAdd a host to a scale-out system\\n© Copyright. All rights reserved.\\n25'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 31}, page_content='Unit 2\\nLesson 1\\nInstalling High Availability SAP HANA\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nInstall a high availability SAP HANA system\\nInstallation of a High Availability SAP HANA System\\nBusiness Example\\nAs an SAP HANA database administrator, you need to install and administer your company’s\\nhigh availability scale-out SAP HANA systems. You need to have hands-on experience with\\ninstalling SAP HANA single-host systems and extending such a system with additional hosts.\\nInstalling a Multiple-Host System\\nThe SAP HANA database lifecycle manager can be used to install an SAP HANA multiple-host\\nsystem in one of the program interfaces, and with a combination of parameter specification\\nmethods.\\nA multiple-host system is a system with more than one host, which can be configured as\\nactive worker hosts or idle standby hosts. The SAP HANA software is built for a flexible\\narchitecture that allows a distributed installation. This means that the load can be balanced\\nbetween different hosts. The SAP HANA software can be installed on a shared file system\\nenvironment. This shared file system must be mounted by all hosts that are part of the\\nsystem.\\nFigure 14: SAP HANA Multiple-Host System\\n© Copyright. All rights reserved.\\n26'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 32}, page_content='A multiple-host system can be installed as a new system on several hosts, or by adding one or\\nmore new hosts to an already installed single-host system. To add hosts to an existing\\nsystem, use the SAP HANA resident HDBLCM.\\nMultiple-Host System Concepts\\nIt is important to review multiple-host system concepts, such as host grouping and storage\\noptions, before installing a multiple-host system.\\nHost Types\\nWhen configuring a multiple-host system, the additional hosts must be defined as \\nworker\\nhosts or standby hosts (worker is the default). Worker machines process data; standby\\nmachines do not handle any processing and instead just wait to take over processes in the\\ncase of worker machine failure.\\nAuto-Failover for High Availability\\nAs an in-memory database, SAP HANA is not only concerned with maintaining the reliability of\\nits data in the event of failures, but also with resuming operations with most of that data\\nloaded back in memory as quickly as possible. Host auto-failover is a local fault recovery\\nsolution that can be used as a supplemental or alternative measure to system replication. One\\n(or more) standby hosts are added to an SAP HANA system, and configured to work in\\nstandby mode.\\nBefore installing a multiple-host system, it is important to consider whether high availability is\\nnecessary, and how hosts should be grouped to ensure preferred host auto-failover. For host\\nauto-failover to be successful, if the active (worker) host fails, the standby host takes over its\\nrole by starting its database instance using the persisted data and log files of the failed host.\\nThe name server of one of the SAP HANA instances acts as the cluster manager that pings all\\nhosts regularly. If a failing host is detected, the cluster manager ensures that the standby host\\ntakes over the role and the failing host is no longer allowed write access to the files (called\\n“fencing”) to avoid data corruption. The crash of a single service does not trigger failover,\\nbecause services are normally restarted by hdbdaemon.\\nHigh Availability Host Grouping\\nFigure 15: Host Grouping\\nLesson: Installing High Availability SAP HANA\\n© Copyright. All rights reserved.\\n27'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 33}, page_content='Host grouping does not affect the load distribution among worker hosts; the load is\\ndistributed among all workers in an SAP HANA system. If there are multiple standby hosts in a\\nsystem, host grouping should be considered, because host grouping decides the allocation of\\nstandby resources if a worker machine fails. If no host group is specified, all hosts belong to\\none host group called \"default\". The more standby hosts in one host group, the greater the\\nfailover security.\\nIf each of the standby hosts is in a different host group, the standby host in the same group as\\nthe failing worker host is preferred. If a standby host is not available in the same host group,\\nthe system tries to fail over to a standby host that is part of another host group. The\\nadvantage of this configuration is that in an SAP HANA system with mixed machine\\nresources, similar sized machines can be grouped together. If a small worker host fails, and a\\nsmall standby in the same group takes over, the processes are moved to a machine with\\nsimilar resources, which allows processing to continue as usual with optimal resource\\nallocation.\\nWorker Host Grouping\\nFigure 16: Best Practices Host Grouping\\nIf you use SAP Business Warehouse to apply a temperature-based data strategy, you can\\nsignificantly optimize the usage of memory and hardware resources by reserving one node of\\nthe scaled-out SAP HANA landscape exclusively for warm data. In information lifecycle\\nmanagement, multi-temperature strategies are often applied whereby data is classified by\\naccess frequency as either hot, warm, or cold. Depending on this classification and data\\nusage, this data is stored in different memory areas.\\nA multi-temperature memory strategy may be required for different reasons, for example:\\nStorage of historical data.\\nClickstream logs for multiple years of Web data and detailed machine logs.\\nGuidelines for saving company data, such as the need to save all data for at least seven\\nyears for legal reasons.\\nThe standard SAP HANA sizing guidelines allow for a data footprint of 50% of the available\\nRAM. This ensures that all data can always be kept in RAM, and there is sufficient space for\\nintermediate result sets. These sizing guidelines can be significantly relaxed on the extension\\ngroup, as warm data is accessed less frequently, with reduced performance SLAs, with less\\nCPU-intensive processes, only partially at the same time.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n28'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 34}, page_content=\"To implement a multi-temperature memory strategy, you can assign hosts to worker groups.\\nHot and warm data are then distributed across hosts. To increase performance and memory\\nusage, a worker node is assigned to a separate extension node. Unlike the standard nodes\\n(master and worker), the extension node is intended exclusively for data that is not accessed\\nas frequently (warm) as other data (hot). For more information, see SAP Note: 2453736.\\nStorage and File System Options\\nIn single-host SAP HANA systems, it is possible to use local file systems residing on directly-\\nattached internal or external storage devices, such as SCSI hard drives, SSDs, SAN storage,\\nor NAS. However, to build a multiple-host system with failover capabilities, this is not\\nsufficient. Either the chosen file system type or the SAN infrastructure, along with an SAP\\nHANA functionality capable of disc fencing, must ensure the following:\\nThe standby host has file access to the data and log volumes of the failed host.\\nThe failed worker host no longer has access to write to files, called “fencing”.\\nThere are two fundamentally different storage configurations that meet these two conditions:\\nshared storage devices or separate storage devices with failover reassignment. Do not\\nconfuse shared storage with the installation directory /hana/shared that must be shared\\nacross all hosts.\\nShared File Systems\\nFigure 17: High Availability Using Shared Storage\\nA shared storage subsystem, which is accessed using file systems such as NFS or IBM's\\nGPFS, makes it easy to ensure that the standby host has access to all active host files in the\\nsystem. In a shared storage solution, the externally attached storage subsystem devices can\\nprovide dynamic mount points for hosts.\\nAs shared storage subsystems vary in their handling of fencing, it is the responsibility of the\\nhardware partner and their storage partners to develop a corruption-safe failover solution\\nthat is specific for the file system used to access that storage subsystem. An NFSv3 storage\\nsolution must be used in combination with the storage connector supplied by the hardware\\npartner. NFSv4 and GPFS storage solutions can optionally be used with a storage connector.\\nLesson: Installing High Availability SAP HANA\\n© Copyright. All rights reserved.\\n29\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 35}, page_content='A shared storage system could be configured as in the following figure. However, mounts may\\ndiffer among hardware partners and their configurations.\\nHigh Availability Using Non-shared Storage\\nFigure 18: Non-shared Storage\\nIt is also possible to assign separate storage to every SAP HANA host, which has nothing\\nmounted except the shared area. An SAN storage must be used in combination with the SAP\\nFiber Channel Storage Connector, which SAP HANA offers to storage technology vendors.\\nDuring failover, SAP HANA uses the storage connector API to tell the storage device driver to\\nre-mount the required data and log volumes to the standby host, and fence off the same\\nvolumes from the failed host.\\nIn a non-shared environment, separate storage is used in combination with the storage\\nconnector API. For more information about the storage connector API, see the SAP Fiber\\nChannel Storage Connector Admin Guide available in SAP Note: 1900823.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n30'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 36}, page_content='Adding a Host to a Single-Host System\\nFigure 19: Use Resident SAP HANA Database Lifecycle Manager to Add a Host\\nAn SAP HANA system can be configured as a multiple-host system during installation, using\\nthe SAP HANA database lifecycle manager (HDBLCM) from the installation media. It is also\\npossible to add hosts after the installation of a single-host or multiple-host SAP HANA\\nsystem, using the resident SAP HANA database lifecycle manager.\\nUse the SAP HANA database lifecycle manager graphical user interface, the command-line\\ninterface, or the SAP HANA database lifecycle manager Web user interface, to add one or\\nmultiple hosts to an existing SAP HANA system. The configuration options change depending\\non how the host is added.\\nAdding Hosts from an Integrated Host\\nThe first consideration is whether the host you are logged on to is integrated in the system. If\\nyou are logged on to a configured system host, then you are on an integrated host and adding\\na non-integrated host to the system. In the following figure, the hosts in the dotted line\\n(hanahost1 and hanahost2) are integrated hosts because they both belong to the SAP HANA\\nsystem DB1. Consider being logged on to hanahost1, and adding the non-integrated host,\\nhanahost3, to the SAP HANA system. The SAP HANA database lifecycle manager is started\\non the integrated host, hanahost1, and the addhost configuration task is carried out. The host\\ninformation for hanahost3 is entered, and hanahost3 is configured as either a worker host or a\\nstandby host. As soon as the addhost configuration task is finished, hanahost3 has access to\\nthe shared storage of the DB1 system. It is also possible to add multiple non-integrated hosts\\nto the same system at one time.\\nLesson: Installing High Availability SAP HANA\\n© Copyright. All rights reserved.\\n31'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 37}, page_content='Figure 20: Adding a Host Integrated or Non-Integrated\\nAdding Hosts from a Non-Integrated Host\\nAlternatively, a non-integrated host can add itself to an SAP HANA system. This is referred to\\nas adding a host from a non-integrated host, because you are logged on to a host that you\\nwant to add to the system.\\nTo add multiple hosts to an SAP HANA system from a non-integrated host, first the non-\\nintegrated host must be added (and, therefore, become integrated), and then it can add more\\nhosts. The SAP HANA database lifecycle manager interface is designed so that the non-\\nintegrated host and the additional hosts can be added in the same procedure. In the following\\nfigure, the non-integrated host has already been newly added to the system (become\\nintegrated), and is now adding the other hosts.\\nIf you are adding a host to a single-host system, the listen interface is automatically\\nconfigured to global during the host addition. After the host is added to the system, the\\ninternal network address can be defined and the inter-service communication can be re-\\nconfigured to a different setting, if required.\\nAdd Host Prerequisites\\nThe following prerequisites must be fulfilled before hosts can be added to a SAP HANA\\nsystem:\\nThe SAP HANA system has been installed with its server software on a shared file system\\n(export options rw, no_root_squash).\\nThe host has access to the installation directories <sapmnt> and <sapmnt>/<SID>.\\nThe SAP HANA system has been installed with the SAP HANA database lifecycle manager.\\nThe SAP HANA database server is up and running.\\nYou are logged on as root user or as the system administrator user <sid>adm.\\nThe difference between the system time set on the installation host and the additional host\\nis not greater than 180 seconds.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n32'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 38}, page_content='The operating system administrator (<sid>adm) user may exist on the additional host.\\nEnsure that you have the password of the existing <sid>adm user, and that the user\\nattributes and group assignments are correct. The SAP HANA database lifecycle manager\\nresident program does not modify the properties of any existing user or group.\\nThe Exercise Explained\\nThe following exercise demonstrates the installation of a four-node SAP HANA scale-out\\nsystem. The original system was installed as a single-host system, with the data and log\\nvolumes stored on shared storage. This single-host system is extended to a four-node SAP\\nHANA scale-out system by adding two worker nodes and one standby node.\\nFigure 21: The Exercise Explained\\n1. In Step 1, the host wdflbmt7346 is installed as a single-host system.\\n2. In Step 2, the host wdflbmt7347 is added to the system, as a worker node, from the\\nintegrated host wdflbmt7346.\\n3. In Step 3, the host wdflbmt7348 is added to the system, as a worker node, from the non-\\nintegrated host wdflbmt7348.\\n4. In Step 4, the host wdflbmt7349 is added to the system, as a standby node, from the non-\\nintegrated host wdflbmt7349.\\nRelated Information\\nSAP Note: 1900823 - SAP HANA Storage Connector API\\nSAP Note: 405827 - Linux: Recommended file systems\\nSAP Note: 2453736 - How-To: Configuring SAP HANA for SAP BW Extension Node in SAP\\nHANA 2.0\\nLESSON SUMMARY\\nYou should now be able to:\\nInstall a high availability SAP HANA system\\nLesson: Installing High Availability SAP HANA\\n© Copyright. All rights reserved.\\n33'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 39}, page_content='Unit 2\\nLesson 2\\nExplaining SAP HANA Scale-Out\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nIntroducing SAP HANA scale-out systems\\nIntroduction to SAP HANA Scale-Out Systems\\nBusiness Example\\nAs an SAP HANA database administrator, you need to install and administrate your\\ncompany’s high availability scale-out SAP HANA systems. You need to understand the basic\\nconcept behind the SAP HANA scale-out technology.\\nScaling SAP HANA\\nScale-up and scale-out are the two general approaches you can take to enlarge your SAP\\nHANA system.\\nScale-up means increasing the size of one physical machine by increasing the amount of\\nRAM available for processing.\\nScale-out means combining multiple independent computers into one system. The main\\nreason for distributing a system across multiple hosts (that is, scaling out) is to overcome\\nthe hardware limitations of a single physical server. This allows an SAP HANA system to\\ndistribute the load between multiple servers. In a distributed system, each index server is\\nusually assigned to its own host to achieve maximum performance. It is possible to assign\\ndifferent tables to different hosts (partitioning the database), as well as to split a single\\ntable between hosts (partitioning of tables).\\n© Copyright. All rights reserved.\\n34'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 40}, page_content=\"Figure 22: Scale-up vs Scale-out\\nAspects of Scalability\\nYou can use an SAP HANA scale-out architecture to manage large amounts of data or for\\nhigher availability. If you need to use more memory or more CPU power beyond the limitation\\nof a single physical hardware box, you can use a distributed landscape consisting of multiple\\nhosts.\\nBefore you decide how to scale your SAP HANA implementation, there are several aspects\\nthat need to be considered, such as scaling data, performance, applications, and hardware.\\nScaling the Data\\nOne technique you can use to deal with planned data growth is to purchase more physical\\nRAM than is initially required, to set the allocation limit according to your needs, and then to\\nincrease it over time to adapt to your data. Once you have reached the physical limits of a\\nsingle server, you can scale out over multiple machines to create a distributed SAP HANA\\nsystem. You can do this by distributing different schemata and tables to different servers\\n(complete data and user separation). However, this is not always possible, for example, when\\na single fact table is larger than the server's RAM size.\\nThe most important strategy for scaling your data is data partitioning. Partitioning supports\\nthe creation of very large tables (billions of rows) by breaking them into smaller chunks that\\ncan be placed on different machines. Partitioning is transparent for most SQL queries and\\nother data manipulations.\\nScaling Performance\\nSAP HANA’s performance is derived from its efficient, parallel approach. The more\\ncomputation cores your SAP HANA server has, the better the overall system performance.\\nScaling performance requires a more detailed understanding of your workload and\\nperformance expectations. Using simulations and estimations of your typical query\\nworkloads, you can determine the expected load that a typical SAP HANA installation may\\ncomfortably manage. At the workload level, a rough prediction of scalability can be\\nestablished by measuring the average CPU utilization while the workload is running. For\\nexample, an average CPU utilization of 45% may indicate that the system can be loaded 2X\\nbefore showing a significant reduction in individual query response time.\\nLesson: Explaining SAP HANA Scale-Out\\n© Copyright. All rights reserved.\\n35\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 41}, page_content='Scaling the Application\\nPartitioning can be used to scale the application as it supports an increasing number of\\nconcurrent sessions and complex analytical queries by spreading the calculations across\\nmultiple hosts. Particular care must be taken in distributing the data so that the majority of\\nqueries match partitioning pruning rules. This accomplishes two goals: directing different\\nusers to different hosts (load balancing) and avoiding the network overhead related to\\nfrequent data joins across hosts.\\nScaling Hardware\\nSAP HANA is offered in a number of ways – in the form of an on-premise appliance, delivered\\nin a number of different configurations and \"sizes\" by certified hardware partners or by using\\nthe tailored data center integration model, and as part of a cloud-based service. This creates\\ndifferent system design options with respect to scale-up and scale-out variations. To\\nmaximize performance and throughput, SAP recommends that you scale up as far as\\npossible (acquire the configuration with the highest processor and memory specification for\\nthe application workload), before scaling out (for deployments with even greater data volume\\nrequirements).\\nNote:\\nSAP HANA hardware partners have different building blocks for their scale-out\\nimplementations. Therefore, you should always consult with your hardware\\npartner when planning your scale-out strategy.\\nIntroducing High-Availability in an SAP HANA system\\nIn the figure Scale-up vs Scale-out, the SAP HANA systems are only increased in size from\\n1TB to 12TB. In both scenarios, scale-up and scale-out, no high availability is introduced. High\\navailability can only be introduced in a scale-out setup with inclusion of standby nodes. A\\nscale-out configuration with high availability is shown in the figure High Availability and Scale-\\nout. One or more SAP HANA nodes can be configured as standby nodes. A standby node\\nautomatically takes over the operations of a failed host using the host auto-failover feature\\nfrom SAP HANA.\\nFigure 23: High Availability and Scale-out\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n36'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 42}, page_content='As soon as you introduce standby nodes in an SAP HANA scale-out configuration, you reserve\\nresources for the event of a failure. These resources cannot be used in the active system. In\\nthe figure High Availability and Scale-out, one host is defined as the standby node. This means\\nthat our system now has only 11 nodes active nodes, and the total database size is reduced\\nfrom 12TB to 11TB.\\nA scale-up configuration, by default, has no high availability capabilities. This is due to the fact\\nthat a scale-up system consists of one server. A scale-up system can be made high availability\\nby adding an additional standby host to the SAP HANA system, or by setting up a\\nconfiguration using storage replication or system replication.\\nMultiple-host (Distributed) Systems\\nAn SAP HANA system can comprise multiple isolated databases and may consist of a cluster\\nof several hosts. This is referred to as a multiple-host, distributed system, or scale-out\\nsystem, and supports scalability and availability.\\nAn SAP HANA system is identified by a single system ID (SID) and contains one or more\\ntenant databases and one system database. Databases are identified by an SID and a\\ndatabase name. From the administration perspective, there is a distinction between tasks\\nperformed at the system level and those performed at the database level. Database clients,\\nsuch as the SAP HANA cockpit, connect to specific databases.\\nFigure 24: High Available Scale-out System\\nA host is a machine that runs parts of the SAP HANA system. The machine is comprised of\\nCPU, memory, storage, network, and an operating system.\\nAn SAP HANA instance is the set of components of a distributed system that are installed on\\none host. The figure High Available Scale-out System shows a distributed system that runs on\\nfour hosts. In this example, each instance has an index server and a name server.\\nOne or more hosts can be configured to work in standby mode, so that if an active host fails, a\\nstandby host automatically takes its place. The index servers on standby hosts do not contain\\nany data and do not receive any requests.\\nThe index server contains all the database and processing components. Each index server is a\\nseparate operating system process and it also has its own disk volumes. When processing\\ndatabase operations, index servers may need to forward the execution of some operations to\\nother servers that own the data involved in the operation.\\nLesson: Explaining SAP HANA Scale-Out\\n© Copyright. All rights reserved.\\n37'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 43}, page_content='In each SAP HANA system, there is one master index server. It stores the meta-data and it\\ncontains the master transaction manager that coordinates distributed transactions involving\\nmultiple index servers.\\nDatabase clients can send their requests to any index server. If the contacted index server\\ndoes not own all the data involved, it delegates the execution of some operations to other\\nindex servers, collects the result, and returns it to the database client.\\nIn a distributed system, a central component is required that knows the topology and how\\ndata is distributed. This component is the name server. The name server knows which tables,\\ntable replicas, or partitions of tables are located on which index server.\\nWhen processing a query, the index servers ask the name server about the locations of the\\ninvolved data. To prevent a negative impact on performance, the topology and distribution\\ninformation is replicated and cached on each host. In each SAP HANA system, there is one\\nmaster name server that owns the topology and distribution data. This data is replicated to all\\nother name servers, called slave name servers. The slave name servers write the replicated\\ndata to a cache in shared memory from where the index servers of the same instance can\\nread it.\\nThe master name server has its own persistence where it stores name server data (topology\\nand distribution data). The slave name servers have no persistence because they are only\\nholding replicated data.\\nLESSON SUMMARY\\nYou should now be able to:\\nIntroducing SAP HANA scale-out systems\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n38'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 44}, page_content='Unit 2\\nLesson 3\\nPartitioning Tables\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nPerform table partitioning tasks\\nTable Partitioning\\nData Distribution in SAP HANA\\nIn a multiple-host system, each index server is usually assigned to its own host for maximum\\nperformance. SAP HANA supports the following different ways of distributing data across the\\nhosts:\\nA partitioned table splits its data in several blocks (partitions), and these partitions can be\\nstored on different index servers.\\nDifferent tables can be assigned to different index servers.\\nA table can be replicated to multiple index servers, for better query and join performance.\\nWhen you create new tables, or partitions, they are distributed to the available hosts by the\\nsystem. By default, a “round-robin” distribution method is used, but tables can also be\\npositioned by using the table placement rules or by specifying a host and port number with\\nthe SQL CREATE TABLE statement in the location clause. This gives the developer complete\\ncontrol over the positioning of individual tables.\\nSpecific applications may have predefined table distribution rules, and in some cases,\\nconfiguration files and documentation are available in SAP Notes to help you to set up the\\nnecessary partitioning and table placement rules.\\nIntroduction to Table Partitioning\\nThe partitioning feature of the SAP HANA database splits column-store tables horizontally\\ninto disjunctive sub-tables or partitions. In this way, large tables can be broken down into\\nsmaller, more manageable parts.\\nPartitioning is only available for tables located in the column store. The row store does not\\nsupport partitioning.\\nHint:\\nPartitioning is typically used in multiple-host systems, but it may also be\\nbeneficial in single-host systems.\\nTable partitioning is transparent for the application in a way that applications work properly\\nwith all partitioning strategies. Nevertheless, partitioning can have an impact on performance,\\nso it can make a difference for the end user and the system load, both in a positive and\\n© Copyright. All rights reserved.\\n39'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 45}, page_content='negative way. To minimize the risk of performance regressions, it is important to implement a\\ngood partitioning strategy.\\nPartitioning is transparent for SQL queries and data manipulation language (DML)\\nstatements. The following additional data definition statements (DDL) for partitioning are\\navailable:\\nPerform the delta merge operation on certain partitions\\nCreate table partitions\\nRe-partition tables\\nMerge partitions to one table\\nAdd or delete partitions\\nMove partitions to other hosts\\nNote:\\nAfter adding or removing hosts, it is recommended that you execute a\\nredistribution operation. Based on its configuration, the redistribution operation\\nsuggests a new placement for tables and partitions in the system. If you confirm\\nthe redistribution plan, the redistribution operation redistributes the tables and\\npartitions accordingly.\\nFigure 25: Table Partitioning\\nWhen a table is partitioned, the split is done in such a way that each partition contains a\\ndifferent set of rows of the table. There are several alternatives available for specifying how\\nthe rows are assigned to the partitions of a table, for example, hash partitioning, round-robin\\npartitioning, or partitioning by range.\\nHash Partitioning\\nHash partitioning is used to distribute rows to partitions equally for load balancing and to\\novercome the 2 billion row limitation. The number of the assigned partition is computed by\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n40'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 46}, page_content=\"applying a hash function to the value of a specified column. Hash partitioning does not require\\nan in-depth knowledge of the actual content of the table.\\nFor each hash partitioning specification, columns must be specified as partitioning columns.\\nThe actual values of these columns are used when the hash value is determined. If the table\\nhas a primary key, these partitioning columns must be part of the key. The advantage of this\\nrestriction is that a uniqueness check of the key can be performed on the local server. You can\\nuse as many partitioning columns as required to achieve a good variety of values for an equal\\ndistribution.\\nFor more information about the SQL syntax for partitioning, see SAP HANA SQL and System\\nViews Reference.\\nRound-Robin Partitioning\\nRound-robin partitioning is used to achieve an equal distribution of rows to partitions.\\nHowever, unlike hash partitioning, you do not have to specify partitioning columns. With\\nround-robin partitioning, new rows are assigned to partitions on a rotation basis. The table\\nmust not have primary keys.\\nHash partitioning is usually more beneficial than round-robin partitioning for the following\\nreasons:\\nThe partitioning columns cannot be evaluated in a pruning step. Therefore, all partitions\\nare considered in searches and other database operations.\\nDepending on the scenario, it is possible that the data in semantically-related tables\\nresides on the same server. Some internal operations may then operate locally instead of\\nretrieving data from a different server.\\nRange Partitioning\\nRange partitioning creates dedicated partitions for certain values or value ranges in a table.\\nFor example, a range partitioning scheme can be chosen to create a partition for each\\ncalendar month. Partitioning requires an in-depth knowledge of the values that are used or\\nare valid for the chosen partitioning column.\\nPartitions may be created or dropped as needed and applications may choose to use range\\npartitioning to manage data at a fine level of detail, for example, an application may create a\\npartition for an upcoming month so that new data is inserted into that new partition.\\nNote:\\nRange partitioning is not well suited for load distribution. Multi-level partitioning\\nspecifications address this issue.\\nWhen rows are inserted or modified, the target partition is determined by the defined ranges.\\nIf a value does not fit into one of these ranges, an error is raised. To prevent this, you can also\\ndefine an 'others' partition for any values that do not match any of the defined ranges. The\\n'others' partitions can be created or dropped on-the-fly as required.\\nRange partitioning is similar to hash partitioning in that the partitioning column must be part\\nof the primary key. Many data types are supported for range partitioning. See the list of data\\ntypes in Partitioning Limits for the complete list.\\nMulti-Level Partitioning\\nMulti-level partitioning can be used to overcome the limitation of single-level hash partitioning\\nand range partitioning, that is, the limitation of only being able to use key columns as\\nLesson: Partitioning Tables\\n© Copyright. All rights reserved.\\n41\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 47}, page_content='partitioning columns. Multi-level partitioning makes it possible to partition by a column that is\\nnot part of the primary key.\\nExplicit Partition Handling for Range Partitioning\\nFor all partitioning specifications involving range, it is possible to have additional ranges\\nadded and removed as necessary. This means that partitions are created and dropped as\\nrequired by the ranges in use. In the case of multi-level partitioning, the desired operation is\\napplied to all relevant nodes.\\nNote:\\nIf a partition is created and an others partition exists, the rows in the others\\npartition that match the newly-added range are moved to the new partition. If the\\nothers partition is large, this operation may take a long time. If an others partition\\ndoes not exist, this operation is fast as only a new partition is added to the\\ncatalog.\\nRange partitioning requires at least one range to be specified regardless of\\nwhether or not there is an others partition. When partitions are dropped, the last\\npartition created cannot be dropped even if an others partition exists.\\nFor range-range partitioning you have to specify whether a partition must be added or\\ndropped on the first or second level by specifying the partitioning column.\\nCaution:\\nThe DROP PARTITION command deletes data. It does not move data to the\\nothers partition.\\nTime Selection Partitioning (Aging)\\nThe SAP HANA database offers a special time selection partitioning scheme, also called\\n\"aging\". Time selection or aging allows SAP Business Suite application data to be horizontally\\npartitioned into different temperatures like hot and cold.\\nSAP Business Suite ABAP applications can use aging, which must not be used for customer or\\npartner applications, to separate hot (current) data from cold (old) data by using time\\nselection partitioning to:\\nCreate partitions and re-partition\\nAdd partitions\\nAllocate rows to partitions\\nSet the scope of Data Manipulation Language (DML) and Data Query Language (DQL)\\nstatements\\nSetting the DML and DQL scope is the most important aspect of time selection partitioning. It\\nuses a date to control how many partitions are considered during SELECT, CALL, UPDATE,\\nUPSERT, and DELETE. This date may be provided by the application with a syntax clause and\\nit restricts the number of partitions that are considered.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n42'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 48}, page_content='Caution:\\nTables with time selection partitioning cannot be converted into any other kind of\\ntables using ALTER TABLE .\\nPartitioning Advantages\\nFigure 26: Advantages of Table Partitioning\\nLoad balancing in a distributed system\\nIndividual partitions can be distributed across multiple hosts. This means that a query on a\\ntable is not necessarily processed by a single server, but may be processed by all the\\nservers that hold one or more partitions of that table.\\nOvercoming the size limitation of column-store tables\\nA non-partitioned table cannot store more than 2 billion rows. It is possible to overcome\\nthis limitation by distributing the rows across several partitions. Each partition can not\\ncontain more than 2 billion rows.\\nParallelization\\nPartitioning allows operations to be parallelized by using several execution threads for\\neach table.\\nPartition pruning\\nQueries are analyzed to determine whether or not they match the given partitioning\\nspecification of a table (static partition pruning) or match the content of specific columns\\nin aging tables (dynamic partition pruning). If a match is found, it is possible to determine\\nthe specific partition that holds the data being requested, and accordingly avoiding the\\naccess and loading of partitions that are not required into memory.\\nImproved performance of the delta merge operation\\nDuring a delta merge operation of an unpartitioned table, the entire table must be\\nduplicated during the merge operation. This requires a large amount of RAM.\\nLesson: Partitioning Tables\\n© Copyright. All rights reserved.\\n43'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 49}, page_content='During the delta merge operation of a partitioned table, only modified partitions are\\nsubject to the merge operation. This requires less RAM because not every partition has\\nbeen changed.\\nCaution:\\nBefore a table is partitioned or re-partitioned, a delta merge operation is\\nexecuted. Therefore, in the case of huge tables, you must partition them in\\ngood time so as not to run out of memory during the merge operation.\\nExplicit partition handling\\nIn some cases, it can be useful that the application controls the creation and existence of\\npartitions based on specific criteria, for example, by adding partitions to store the data for\\nan upcoming month.\\nExamples of Using Table Partitioning with SQL\\nFigure 27: Table Partitioning Examples\\nIn the figure, Table Partitioning Examples, the table HA201_DEMO_TABLE is created with\\nthree partitions. The single-level partitioning specification is \\nHASH on column Hay.\\nThe above example creates a new table that is partitioned during creation. In real life, it will\\nalso happen that you need to merge one or more partitioned tables, or partition an existing\\ntable. The use cases may be that the table is nearing the 2 billion records limit, or the query\\nperformance is not optimal. Using the mentioned SQL statements, you can merge partitioned\\ntables, or partition existing tables in the SAP HANA database.\\nRepartitioning\\nThere is no automatic repartitioning when threshold values are exceeded. Instead, this is\\nproposed the next time the redistribution process is executed.\\nThe values entered for partitioning must be consistent with the physical landscape, especially\\nthe number of server nodes available.\\nIf repartitioning is necessary, tables are only repartitioned by doubling the number of existing\\n(initial) partitions. This is done for performance reasons. The maximum number of (first-level)\\npartitions reached by that process is defined by parameter \\nglobal.ini >\\n[table_placement] > max_partitions\\n (default: 12).\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n44'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 50}, page_content='By default, the system does not create more partitions than the number of available hosts (or\\nmore specifically, possible locations). For example, if INITIAL_PARTITIONS is set to 3, but the\\ndistributed SAP HANA database has five possible locations, repartitioning from three to six\\npartitions does not take place. A table can have more than one partition per host if the\\nparameter global.ini > [table_placement] >\\nmax_partitions_limited_by_locations\\n is set to false\\n (default: true). This rule is\\ndisregarded if a higher number of first level partitions is required to partition groups with\\nmore than 2 billion records ( global.ini > [table_placement] >\\nmax_rows_per_partition\\n, default = 2,000,000,000).\\nNote:\\nSAP Note: 2044468 - “FAQ: SAP HANA Partitioning” provides detailed\\ninformation on SAP HANA partitioning.\\nTable Distribution Editor: Additional Actions\\nIf a table is distributed to several partitions, it displays the host that stores each of these\\npartitions. Existing partitions can be moved to different hosts by generating a specific\\nredistribution plan. You can also balance table distribution after adding new hosts to the\\nsystem. Check, optimize, compress, defrag, load table, delta merge, and evaluate\\nrepartitioning of tables that are not partitioned to other hosts as well.\\nFigure 28: Generate Redistribution Plan\\nLesson: Partitioning Tables\\n© Copyright. All rights reserved.\\n45'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 51}, page_content='Note:\\nBefore moving tables or partitions, the system checks that the host has sufficient\\nmemory.\\nChanging how tables are distributed across hosts is a critical operation. Back up\\nthe landscape before executing a redistribution operation.\\nBest Practices for Table Partitioning\\nTo create an optimal partitioning plan, you should try to follow the table partitioning best\\npractices in the following figure.\\nFigure 29: Best Practices Table Partitioning\\nKeep the number of partitioned tables low\\nOnly partition tables if you see a clear benefit without significant regressions.\\nKeep the number of partitions per table low\\nAn unnecessarily high amount of partitions result in overhead because some queries may\\nhave to access all partitions to find the data:\\n-\\nA high amount of network channels are opened and so the system is at risk of reaching\\nthe max channels limitation (SAP Note: 2222200) and running into network-related\\nterminations.\\n-\\nCertain operations like the determination of column statistics (SAP Note: 2114710) have\\nto be performed individually for each partition.\\nSo, consider the following general rules before defining a certain number of partitions:\\n-\\nIf you partition tables due to the 2 billion limit, it is usually acceptable if individual\\npartitions contain up to 1.5 billion records (less if you expect a significant future\\ngrowth).\\n-\\nIf you partition by date, you should avoid using granular ranges (such as days or weeks)\\nresulting in a high amount of partitions.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n46'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 52}, page_content='-\\nIf you use a RANGE partition on columns with data that is not evenly distributed (such\\nas a number range column with multiple different number ranges), you should check\\nthe actual value distribution and define the range limits accordingly.\\nKeep the number of key columns low\\nAs few partition key columns as possible. It is useful to keep the number of partition key\\ncolumns to a minimum for the following reasons:\\n-\\nPartition pruning of hash partitions can only be used if all underlying partitioning\\ncolumns are specified with \"=\" or \"IN\" in the WHERE clause.\\n-\\nDetermining partition pruning can be quite time consuming if many partition keys are\\ninvolved.\\nFor more information, see SAP Note: 2000002 \"What are typical approaches to tune\\nexpensive SQL statements?\" and \"Execution time higher than expected, negative\\nimpact by existing partitioning\".\\nIn the case of hash partitioning, it is often useful to use only the most selective primary key\\ncolumn as the partition key column.\\nFor SAP Suite on HANA, keep all partitions on same host\\nIn scale-out SAP Suite on HANA environments, it is advantageous to keep all partitions of a\\ntable on the same host. As of SPS08, this can achieved with an appropriate table\\nplacement configuration.\\nAs a fallback option, you can use a dummy first-level partitioning (for example, on MANDT)\\nand perform the actual partitioning at the second level. In this case, all partitions are\\nlocated on the same host.\\nRepartitioning rules\\nWhen repartitioning, choose the new number of partitions as a multiple or divider of\\ncurrent number of partitions.\\nIf a table is already partitioned, it is most efficient to choose a new number of partitions\\nthat is a factor 2 multiple or divider of the current number of partitions (such as 4 -> 8 or 6\\n-> 3 partitions). Only in this case can the repartitioning happen in parallel on different\\npartition groups and hosts (“parallel split/merge”).\\nAvoid unique constraints\\nWhen creating partitions, try to avoid creating additional unique constraints. Avoid\\npartitioning tables with additional unique constraints (such as a unique secondary index),\\nas the uniqueness checks impose significant overhead.\\nNote:\\nSAP Note: 2000002 gives insight into SAP HANA SQL optimization, and describes\\nsymptoms that can be introduced by inadequate partitioning.\\nLesson: Partitioning Tables\\n© Copyright. All rights reserved.\\n47'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 53}, page_content='Table Partitioning Monitoring Views\\nFigure 30: SQL Editor: Show Partitioned Table Information\\nThe M_CS_PARTITIONS system view provides partition information of column tables.\\nselect * from \"M_CS_PARTITIONS\" where \"TABLE_NAME\" = \\n\\'sap.hana.democontent.epm.data::PO.Item\\';\\nResults in:\\nThe output shows the number of partitions. In the above example, we have three partitions.\\nThe M_CS_TABLES system view provides run time data for column tables or partitions of\\ncolumn tables.\\nselect * from \"M_CS_PARTITIONS\" where \"TABLE_NAME\" = \\n\\'sap.hana.democontent.epm.data::PO.Item\\';\\nThe output shows which host the partition is located on, and how much memory is consumed\\nby the table.\\nThe M_EFFECTIVE_TABLE_PLACEMENT\\n system view provides information on the table\\nplacement location. This view also contains information about the partitioning thresholds. You\\ncan see the valid location(s) according to the configuration, the actual values for each\\npartitioning parameter, and in the corresponding _MATCH columns, the reason (matching\\nrule) for those.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n48'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 54}, page_content='Figure 31: HANA Cockpit: Show Partitioned Table Information\\nThe table information is also available in SAP HANA Cockpit. In the View Current Table\\nDistribution  application, search for the required table and select it. In the pop-up, select the\\nShow Runtime Data option. On the Runtime Data screen, the table definition is shown by\\ndefault. Select the Partitions  button to get an overview of how the table is partitioned and\\nwhere the partitions are located. The partition range is also displayed.\\nTable Consistency Checks\\nTo ensure consistency for partitioned tables, execute checks and repair statements, if\\nrequired.\\nYou can call general and data consistency checks for partitioned tables to check, for example,\\nthat the partition specification, metadata, and topology are correct.\\nFigure 32: Partitioning Consistency Check and Repair\\nLesson: Partitioning Tables\\n© Copyright. All rights reserved.\\n49'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 55}, page_content='Note:\\nThe data checks can take a long time to run, depending on the data volume.\\nLESSON SUMMARY\\nYou should now be able to:\\nPerform table partitioning tasks\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n50'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 56}, page_content='Unit 2\\nLesson 4\\nTable Placement\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nPerform Table Placement Tasks\\nTable Placement\\nTable Placement\\nTable classification and table placement configuration, enhanced by partitioning, build the\\nfoundation for controlling the data distribution in an SAP HANA scale-out environment.\\nFigure 33: Table Distribution\\nAssociated tables can be classified by a common table group.\\nThe SQL interface of SAP HANA provides three possible kinds of classifications: group name,\\ngroup type, and subtype. Tables that have been classified with group information are included\\nin the SYS.TABLE_GROUPS table, and you can review classification details in the monitoring\\nview SYS.TABLE_GROUPS (see details following). Tables with the same group name are kept\\non the same host, or, in the case of partitioned tables that are distributed over several hosts,\\ncorresponding first-level partitions are distributed for all tables the same way.\\nOne table in the group is defined as the leading table and its table placement settings are\\napplied to all other tables in the group. This can be, for example, the location, or in the case of\\npartitioned tables (if SAME_PARTITION_COUNT is set in SYS.TABLE_PLACEMENT, see\\nbelow), the number of first-level partitions.\\n© Copyright. All rights reserved.\\n51'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 57}, page_content='Note:\\nSpecific applications, such as SAP BW, classify objects automatically as they are\\ncreated. These classifications must not be changed manually.\\nFor native applications, the application developer can define a grouping manually, for\\nexample, by grouping tables together that are often joined. The following statements show\\nexamples of setting table group attributes using CREATE and ALTER statements:\\nCREATE COLUMN TABLE \"HA201_DEMO\".\"HA201_TABLE\"(\\n  HAY INT,\\n  GEORG INT,\\n  HAKAN INT,\\n  PRIMARY KEY (HAY, GEORG))\\n GROUP NAME DEMO GROUP TYPE EXAMPLE GROUP SUBTYPE TEST GROUP LEAD;\\n \\nThis create table statement creates a table named HA201_TABLE, sets the group name to\\nDEMO, the group type to EXAMPLE, the group subtype to TEST, and makes this the lead table in\\nthe group DEMO.\\nALTER TABLE \"HA201_DEMO\".\"HA201_TABLE\" SET\\n  GROUP NAME DEMO\\n  GROUP TYPE EXAMPLE\\n   GROUP SUBTYPE TEST\\n  GROUP LEAD;\\n \\nThis alter table statement sets the group name to DEMO, the group type to EXAMPLE, the\\ngroup subtype to TEST, and makes this the lead table in the group DEMO, for an existing table.\\nThis can also be performed dynamically based on the information available in the SQL Plan\\nCache, with the Join Path Analysis tool within the Data Distribution Optimizer, or with the\\nABAP grouping report (SHDBSO_TABLE_GROUPING) for SAP S/4HANA scale-out. See SAP\\nNote: 2447004 - “Table Grouping Report for S/4 HANA in scale-out systems”.\\nThe SAP HANA Cockpit Table Redistribution tools also include an optional preparation step to\\nintegrate the Group Advisor tool into the plan generation process to create table groups\\ndynamically.\\nTable Classification and Placement\\nApplication data is usually stored in a multitude of database tables, and data from several of\\nthese tables is combined using SQL operations, such as join or union, when it is queried. As\\nthese relations between different tables are defined in the application code, this information is\\nnot available in SAP HANA. The table classification feature provides a possibility to push down\\nthis semantic information in the database by allowing administrators to define groups of\\ntables. This information can be used, for example, when determining the number of partitions\\nto be created, or, in the case of a scale-out landscape, the node on which to locate the tables\\nor partitions.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n52'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 58}, page_content='Figure 34: Table Placement Information\\nThe classification is performed by providing each table with a group name, group type, and\\nsubtype. Based on combinations of these elements, as well as the table names and schema\\nnames, a set of configuration values can be defined as table placement rules. These rules are\\nused to control, for example, the placement of partitions or the number of partitions during\\noperations like table creation or redistribution. By doing this, associated or strongly-related\\ntables are placed in such a way that the required cross-node communication is minimized for\\nSQL operations on tables within the group.\\nTable placement rules are applied during system migration or table creation, but it may also\\nbe necessary to adjust the location or the number of partitions on an ongoing basis for\\nhandling data growth. Therefore, table redistribution can also be run on demand to optimize\\nthe landscape as the system evolves. Repartitioning is always necessary, for example, for any\\ntable or partition in the database that reaches the maximum count of 2 billion rows.\\nThe following tools are available to perform table repartitioning and redistribution. These tools\\nevaluate the current landscape and determine an optimized distribution:\\nSAP HANA Table Redistribution\\nData Distribution Optimizer (part of SAP HANA Data Warehousing Foundation)\\nBalancing an SAP HANA scale-out landscape with these tools is done in two stages:\\n1. Generation of a plan based on table placement rules (described in detail in a later section).\\nAfter generating the plan, you can review it and adjust the definition of the rules if\\nrequired.\\n2. Execution of the plan that implements the partitioning and distribution changes.\\nBecause split table and move table are operations that require table locks, the execution of\\nthe plan should not be performed during a period where there is heavy load on the database.\\nLesson: Table Placement\\n© Copyright. All rights reserved.\\n53'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 59}, page_content='Table Classification and Table Placement Rules\\nTable placement rules are defined in the table SYS.TABLE_PLACEMENT. The system privilege\\nTABLE ADMIN is required to maintain these settings. Placement rules basically address the\\nfollowing areas:\\nClassification, that is, related tables that must be located together are organized in groups\\nConfiguration settings to manage partitioning (number of initial partitions, split threshold,\\nand so on)\\nPhysical distribution or location of tables or partitions in the server landscape\\nWhen creating a table, if the defined rules match with a table or a table group, SAP HANA\\nconsiders them while creating the table. Keep in mind that partition specifications must still\\nbe defined by the application.\\nTable Placement Rules\\nThe TABLE_PLACEMENT table provides a customizing interface that can be used for the\\ndynamic management of partitions and locations.\\nThe partitioning parameters are used to define how a table or a group of tables is partitioned if\\nthe table has a first-level partitioning specification of hash or round-robin. Range partitioning\\nis not handled in this way.\\nIf the number of rows is lower than MIN_ROWS_FOR_PARTITIONING, the table consists of\\nonly one partition. If this minimum row limit is exceeded, the table is partitioned in as many\\nparts as fulfills the following constraints:\\nThe number of partitions is larger or equal to the value of (row count of the table) /\\nREPARTITIONING_THRESHOLD.\\nThe number of partitions is a multiple of INITIAL_PARTITIONS.\\nThe number of partitions is smaller or equal to the number of hosts if the parameter\\nmax_partitions_limited_by_locations is not set to false and the number of partitions is less\\nthan the value of the parameter max_partitions (see details below).\\nTherefore, if the table has more than one partition, there are at least INITIAL_PARTITIONS\\npartitions, and each partition has less than REPARTITIONING_THRESHOLD records. In this\\ncontext, partitions refer to first-level partitions (of type HASH or ROUNDROBIN).\\nNote that when a partitioned table is created without an estimated row count (default\\nbehavior), a partitioned table is created with INITIAL_PARTITIONS first-level partitions.\\nWhereas in a redistribution, it is targeted to have a single first-level partition (assuming\\nMIN_ROWS_FOR_PARTITIONING > 0). In specific applications, creation is performed with an\\nestimated row count, for example, BW with 1 million, and therefore it is created with only one\\nfirst level-partition (assuming MIN_ROWS_FOR_PARTITIONING > 1,000,000).\\nRepartitioning\\nThere is no automatic repartitioning when threshold values are exceeded. Instead, this is\\nproposed the next time the redistribution process is executed.\\nThe values entered for partitioning must be consistent with the physical landscape, especially\\nthe number of server nodes available:\\nIf repartitioning is necessary, tables are only repartitioned by doubling the number of\\nexisting (initial) partitions. This is done for performance reasons. The maximum number of\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n54'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 60}, page_content=\"(first-level) partitions reached by that process is defined by parameter global.ini >\\n[table_placement] > max_partitions (default: 12).\\nBy default, the system does not create more partitions than the number of available hosts\\n(or more specifically possible locations). For example, if INITIAL_PARTITIONS is set to 3,\\nbut the distributed SAP HANA database has five possible locations, repartitioning from\\nthree to six partitions would not take place. A table can have more than one partition per\\nhost if the parameter global.ini > [table_placement] > max_partitions_limited_by_locations\\nis set to false (default: true). This rule is disregarded if a higher number of first level\\npartitions is required to partition groups with more than 2 billion records (global.ini >\\n[table_placement] > max_rows_per_partition, default: 2,000,000,000).\\nLocation\\nThere are predefined values for possible locations:\\nmaster: represents the master node\\nslave (or slaves): represents all slave nodes that belong to the worker group ‘default’\\nall: represents all nodes that belong to the worker group ‘default’, that is, the master node\\nand the slave nodes\\nThe worker group assignment can be found in the WORKER_ACTUAL_GROUPS entry of the\\nM_LANDSCAPE_HOST_CONFIGURATION view, and can be accessed by executing the\\nfollowing procedure:\\ncall SYS.UPDATE_LANDSCAPE_CONFIGURATION('GET \\nWORKERGROUPS','<hostname>')\\nIn addition, it is also possible to create custom location definitions by using the following\\nprocedure to assign worker groups to a host:\\ncall SYS.UPDATE_LANDSCAPE_CONFIGURATION('SET \\nWORKERGROUPS','<hostname>','<name1> <name2> <name3>')\\nNote:\\nIf a host is assigned to several worker groups, they must be separated by a space.\\nHow Rules are Applied\\nThe TABLE_PLACEMENT table is read in such a way that a more specific rule supersedes a\\nmore generic one. A complete matrix of priorities is available in SAP Note: 1908082 — “Table\\nPlacement Priorities”.\\nFor example, an entry with only one schema applies to all tables of that schema; additional\\nentries for that schema and specific group types overrule the more general rule.\\nMonitoring View\\nYou can see the actual table placement settings per table by querying the\\nM_EFFECTIVE_TABLE_PLACEMENT system view. You can see the valid location(s) according\\nto the configuration, and for each partitioning parameter the actual values, and in the\\ncorresponding _MATCH columns the reason (matching rule) for those.\\nThe information how a table is classified, can be reviewed in the SYS.TABLE_GROUPS\\nmonitoring view.\\nLesson: Table Placement\\n© Copyright. All rights reserved.\\n55\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 61}, page_content='Redistributing Tables in a Multi-host SAP HANA System\\nIn a distributed SAP HANA system, tables and table partitions are assigned to an index server\\non a particular host at their time of creation, but this assignment can be changed. In certain\\nsituations, it is even necessary. You can use the SAP HANA cockpit or the SQL Editor to\\nexecute automatic redistribution operations.\\nThere are several occasions when tables or partitions of a table need to be moved to other\\nservers. For example, if you plan to remove a host from your system, then you first need to\\nmove all the data on that host first to the other hosts in the system. Redistributing tables may\\nalso be useful if you suspect that the current distribution is no longer optimal.\\nRedistribution operations are available to support the following situations:\\nYou are planning to remove a host from your system.\\nYou have added a new host to your system.\\nYou want to optimize current table distribution.\\nYou want to optimize table partitioning.\\nAlthough it is possible to move tables and table partitions manually from one host to another,\\nthis is neither practical nor feasible for a large-scale redistribution of data.\\nTable Distribution\\nIn SAP HANA cockpit, search for the Table Distribution card. From this card, select View\\nCurrent Table Distribution. The Table Distribution application outlines partitioning and\\ndistribution information of tables in a distributed system. You can reduce the number of\\ndisplayed tables, by using the filter function.\\nFigure 35: Table Distribution in SAP HANA Cockpit\\nFurthermore you can choose additional actions in the Table Distribution application.\\nAvailable operations are:\\nView table distribution\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n56'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 62}, page_content='Generate table redistribution plan\\nSave current table distribution\\nRestore saved tabled distribution plan\\nRerun table distribution plan\\nTable Redistribution with SAP HANA Cockpit\\nFigure 36: SAP HANA Cockpit Table Distribution\\nSAP HANA supports several redistribution operations that use complex algorithms, as well as\\nconfigurable table placement rules and redistribution parameters, to evaluate the current\\ndistribution and determine a better distribution depending on the situation. Administrators\\ncan use the table redistribution feature in the SAP HANA cockpit to create a plan for\\nredistributing and repartitioning tables. The administrator can review the plan and execute it.\\nBalance table distribution\\nThe load on a scale-out system changes over time with the usage of the system. This\\noption generates a plan to move tables and partitions to their proper hosts if they are\\ncurrently on invalid hosts according to the rules specified in the TABLE_PLACEMENT\\ntable. The plan checks whether a split or merge is necessary and calculates optimal\\npositions for the parts and tables. All types of tables and parts can be moved. However,\\nonly the tables that you have permission to view as catalog objects are affected.\\nCheck the number of partitions\\nIn a scale-out system, partitioned tables are distributed across different index servers.\\nThe location of the different partitions can be specified manually or determined by the\\ndatabase when the table is initially partitioned. Over time, this initial partitioning may no\\nlonger be optimal, for example, if a partition has grown significantly.\\nThis option evaluates whether or not partitioned tables need to be repartitioned. The plan\\nspecifies how partitioned tables are repartitioned (split or merged) and how newly-\\ncreated partitions are distributed. Note that this is only relevant for column-store tables.\\nSystem tables, temporary tables, and row-store tables are not considered.\\nRedistribute tables after adding host(s)\\nLesson: Table Placement\\n© Copyright. All rights reserved.\\n57'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 63}, page_content='After adding one or more worker hosts to a scale-out system, you may need to\\nredistribute the tables across the active index servers. This option checks whether new\\npartitions can be created and generates a plan to move the tables and table partitions as\\nnecessary.\\nCheck the correct location of tables and partitions\\nThis option generates a plan to move tables and partitions to their proper hosts if they\\nare on invalid hosts according to the rules specified in the TABLE_PLACEMENT table.\\nOnly the tables that you have permission to view as catalog objects are affected.\\nHousekeeping\\nSome regular operations need to be done from time to time. This option allows you to\\nperform various operations in the system, such as, optimize compressions, defrag, load\\ntable, and merge delta. Only the tables that you have permission to view as catalog\\nobjects are affected. Also, you must have the appropriate privileges to perform specific\\nhousekeeping operations, such as delta merge.\\nTable Redistribution using SQL Editor\\nFigure 37: SAP HANA SQL Editor Table Distribution\\nTable redistribution can also be performed using the SQL commands. You can create an SQL\\nscript that executes all the required steps, or you can use the SQL Editor provided by the SAP\\nHANA Database Explorer.\\nTable redistribution is based on the table placement rules defined in the TABLE_PLACEMENT\\ntable. These rules determine, for example, table sizes, partitioning threshold values, and\\npreferred partition locations. Redistribution is a two-stage process: firstly, to generate the\\nplan and secondly, to execute the plan. Separate commands are used in each stage:\\n1. The plan generation command is a multi-purpose tool that requires an algorithm number\\nas a parameter to determine which actions are executed. Depending on the algorithm\\nselected, additional optional parameter values may also be available to give more control\\nover the execution.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n58'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 64}, page_content='2. The plan execution command takes a single parameter which is the numeric plan ID value.\\nYou can retrieve this value (REORG_ID) from the REORG_OVERVIEW system view (see\\nSystem Views following).\\nThe syntax for these commands is:\\nCALL REORG_GENERATE(<algorithm integer>, <optional parameter\\nstring>);\\nCALL REORG_EXECUTE(<plan_id>);\\n:\\nResource admin privilege is required to call REORG_GENERATE(). The command only\\noperates on tables and partitions that the executing user is allowed to see as catalog objects.\\nGenerating the Plan: Algorithms and Options\\nThe following list gives an overview of the most commonly-required algorithms.\\nAdd server: Algorithm number: 1\\nRun this check after adding one or more index servers to the landscape. If new partitions\\ncan be created, a plan is generated to split the tables and move the new partitions to the\\nnewly added index servers.\\nOptions: SCHEMA_NAME | TABLE_NAME | GROUP_NAME | GROUP_TYPE |\\nGROUP_SUBTYPE | RECALC | NO_PLAN\\nClear server: Algorithm number: 2\\nMoves all partitions from a named server to other servers in the landscape.\\nOptions: USE_GROUP_ADVISOR\\nSave Algorithm number: 4\\nSave the current landscape setup.\\nRestore Algorithm number: 5\\nRestore a saved landscape setup. Enter the plan ID value as the optional parameter value.\\nBalance landscape: Algorithm number: 6\\nThis function checks if tables in the landscape are placed on invalid severs according to the\\ntable placement rules, and checks if a split or merge is necessary to achieve optimal\\npositions for the partitions and tables, and to evenly distribute tables across the index\\nserver hosts.\\nOptions: SCHEMA_NAME | TABLE_NAME | GROUP_NAME | GROUP_TYPE |\\nGROUP_SUBTYPE | RECALC | NO_PLAN | NO_SPLIT | SCOPE\\nCheck number of partitions Algorithm number: 7\\nThis function checks if partitioned tables need to be repartitioned and creates a plan to\\nsplit tables if the partitions exceed a configured row count threshold. No optional\\nparameter.\\nExecute Group Advisor Algorithm number: 12\\nCalls the Group Advisor and creates an executable plan from its output.\\nLesson: Table Placement\\n© Copyright. All rights reserved.\\n59'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 65}, page_content='The Group Advisor identifies tables which are often used together so that during\\nredistribution they can be located together on the same node to avoid cross-node\\ncommunication in the landscape.\\nCheck table placement Algorithm number: 14\\nCheck current landscape against table placement rules and (if necessary) provide a plan to\\nmove tables and partitions to the correct hosts.\\nOptions: LEAVE_UNCHANGED_UNTOUCHED | KEEP_VALID | NO_SPLIT\\nRerun plan Algorithm number: 15\\nRerun failed items from previously executed plans.\\nOption: RERUN_ALL\\nHousekeeping Algorithm number: 16\\nPerform housekeeping tasks. Additional privileges may be required for specific actions.\\nOptions: OPTIMIZE_COMPRESSION | DEFRAG | LOAD_TABLE | MERGE_DELTA |\\nALLOptional\\nPre-defined Table Placement Scenarios\\nFor specific applications, SAP provides recommendations regarding partitioning and table\\ndistribution configurations.\\nSAP BW powered by SAP HANA\\nAll required steps and recommended settings for SAP BW on HANA 2 are described in SAP\\nNote: 1908075 — “BW on SAP HANA: Table placement and landscape redistribution”. This\\nincludes a zip file with documentation and SQL code to configure various scenarios covering a\\nrange of TABLE_PLACEMENT settings depending on the node size (TB per node) and the\\nnumber of master and slave nodes.\\nSAP Business Suite Powered by SAP HANA\\nSAP Note: 1899817 — “SAP Business Suite on SAP HANA database: Table Placement”\\nincludes configuration scripts to set up partitioning and distribution for Suite and S/4HANA\\nfor various support package stack releases.\\nSAP S/4HANA\\nStarting with SAP S/4HANA 1610 FPS1, scale-out is supported and can be applied in special\\nscenarios. Application data tables are grouped together according to application area and can\\nbe placed as a table group on a specific server. In this way, it is possible to use scale-out in\\nSAP S/4HANA.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n60'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 66}, page_content='Figure 38: Use Case Scale-out SAP S/4HANA (1 of 2)\\nFor details of scale-out options for SAP S/4HANA, refer to SAP Note: 2408419 — “SAP S/\\n4HANA - Multi-Node Support”. This note includes scripts and configuration settings, as well\\nas detailed documentation about table groups and migration.\\nFigure 39: Use Case Scale-out SAP S/4HANA (2 of 2)\\nWith the mixed workload on an S/4HANA system, it still makes sense to first scale-up as far\\nas possible, before going into scale-out. So if the first node is bigger than 6 TB and 8 CPU\\nsockets, then scale-out is allowed. See the previous figure for an example.\\nSAP BW/4 HANA\\nAll the required steps and recommended settings for SAP BW/4 on HANA 2 are described in\\nSAP Note: 2334091 — “BW/4HANA: Table Placement and Landscape Redistribution”. This\\nincludes a zip file with documentation and SQL code to configure various scenarios covering a\\nrange of TABLE_PLACEMENT settings depending on the node size (TB per node) and the\\nnumber of master and slave nodes.\\nLesson: Table Placement\\n© Copyright. All rights reserved.\\n61'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 67}, page_content='Figure 40: Use Case Scale-out SAP BW/4HANA\\nSAP provides recommendations regarding table distribution configurations. For these\\nscenarios, SQL implementation scripts and detailed documentation is provided in SAP Notes.\\nFigure 41: Pre-defined Table Placement Scenarios\\nLESSON SUMMARY\\nYou should now be able to:\\nPerform Table Placement Tasks\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n62'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 68}, page_content='Unit 2\\nLesson 5\\nReconfiguring a Scale-Out SAP HANA System\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nReconfigure a scale-out SAP HANA system\\nReconfiguration of a Scale-Out SAP HANA System\\nBusiness Example\\nAs an SAP HANA database administrator, you must be able to reconfigure your company’s\\nhigh availability scale-out SAP HANA systems. You require hands-on experience with\\nreconfiguring multi-host SAP HANA systems.\\nReconfigure a Scale-out SAP HANA System\\nThe SAP HANA database supports high availability in a distributed system by providing for\\nhost auto-failover. If an active host fails, for example, because of a hardware failure, standby\\nhosts can take over and ensure the continued availability of the database.\\nIn SAP HANA cockpit 2.0, you can monitor the status of individual hosts in the Host Failover\\napplication. To start the Host Failover application, open SAP HANA cockpit 2.0 and navigate\\nto the Aggregate Health Monitor application. In the Aggregate Health Monitor, select the\\nSYSTEMDB@<SID> link to open the SAP HANA Cockpit Overview screen.\\nOn the SAP HANA Cockpit Overview screen, search for the Configure Host Failover\\napplication, and select the Configure host failover  link. The same application is also available\\nfrom the tenant database, <SID>@<SID>, but this task is normally something you perform\\nfrom SYSTEMDB.\\n© Copyright. All rights reserved.\\n63'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 69}, page_content=\"Figure 42: SAP HANA Cockpit Host Failover\\nHost roles for failover are normally configured during installation. Using the SAP HANA\\ncockpit, you can monitor the status of individual hosts and switch the configured roles of\\nhosts. You cannot increase or decrease the number of worker hosts and standby hosts with\\nrespect to each other.\\nThe primary reason for changing the configured roles is to prepare for the removal of a host.\\nIn this case, change the configured role of the name server host to SLAVE and the configured\\nrole of the index server host to STANDBY before stopping the database instance on the host\\nand removing the host.\\nThe reconfiguration is done by setting the master parameter in the landscape section of the\\nnameserver.ini file.\\nWith the following SQL command, you specify which three hosts are master candidates:\\nALTER SYSTEM ALTER CONFIGURATION ( 'nameserver.ini' , 'SYSTEM' ) \\n  SET ('landscape', 'master') = 'wdflbmt7346:30001 wdflbmt7347:30001 \\nwdflbmt7348:30001' WITH RECONFIGURE;\\nWith the following SQL command, you specify which host is the master:\\nALTER SYSTEM ALTER CONFIGURATION ( 'nameserver.ini' , 'SYSTEM' ) \\n  SET ('landscape', 'active_master') = 'wdflbmt7347:30001' WITH \\nRECONFIGURE;\\nIn the SAP HANA Cockpit - Host Failover, you can add or remove columns in the display by\\nchoosing the gear button in the top-right corner. When adding or removing hosts from a\\nmulti-host SAP HANA system, the remove status column indicates the status of the table\\nredistribution operation used to move data off the index server of a host that you plan to\\nremove.\\nBefore you can remove an active host from a single-container system, you must move the\\ntables on the index server of this host to the index servers on the remaining hosts in the\\nsystem. Once the value in the removal status column changes to REORG FINISHED or REORG\\nNOT REQUIRED, you can physically remove the host using the SAP HANA lifecycle\\nmanagement tool, hdblcm(gui).\\nIf your system is configured as a multiple-container system, you must remove tenant-specific\\nservices first and then remove the host using the SAP HANA database lifecycle manager.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n64\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 70}, page_content='Figure 43: Host Removal Status\\nThe following statuses are possible:\\n<Empty>: The host has not been marked for removal.\\nREORG PENDING: A redistribution operation is required to move tables to other hosts.\\nREORG ACTIVE: A redistribution operation is in progress. For more information, you can\\nquery the system tables SYS.REORG_OVERVIEW and SYS.REORG_STEPS.\\nREORG FAILED: A redistribution operation was executed and failed. For more information,\\nquery the system table SYS.REORG_STEPS.\\nREORG FINISHED: A redistribution operation has completed. The host can be uninstalled.\\nREORG NOT REQUIRED: A redistribution operation is not required. The host can be\\nuninstalled.\\nFigure 44: Installation Scale-out Master Assignment Rules\\nDuring the SAP HANA installation of a multi-host system, the optimal auto-failover\\nconfiguration is set up.\\nThe optimal configuration is described in the following setup:\\nMaster 1: Assigned to the node where the installation is performed.\\nMaster 2: Assigned to the first additional node that is assigned to the multi-host system.\\nLesson: Reconfiguring a Scale-Out SAP HANA System\\n© Copyright. All rights reserved.\\n65'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 71}, page_content='Master 3: Assigned to the first standby node assigned to the multi-host system. If there is\\nno standby host configured, the second additional node that is assigned to the multi-host\\nsystem is used. A setup without at least one standby node will not be a useful high-\\navailability scenario.\\nIn our training class environment, the SAP HANA installation that we performed in the\\nexercise “Install a High Availability SAP HANA System” has set up the optimal auto-failover\\nconfiguration, as shown in the previous figure. For educational purposes, the next exercise\\n“Reconfigure a Scale-out SAP HANA System” shows you how to reconfigure the auto-failover\\nconfiguration using the Host Failover application in SAP HANA cockpit 2.0.\\nFigure 45: Reconfigure Host Failover Setup\\nIn the next three exercises, the failover behavior is shown. This changed configuration\\nbehavior clearly shows us what happens when a slave node or the master 1 node fails. In the\\nlast exercise, we return to the optimal auto-failover configuration and demonstrate what\\nhappens when the master 1 node fails, but the master 3 node is assigned to the standby\\nserver.\\nHost Auto-failover Required Authorizations\\nFigure 46: Host Auto-failover Required Authorizations\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n66'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 72}, page_content='LESSON SUMMARY\\nYou should now be able to:\\nReconfigure a scale-out SAP HANA system\\nLesson: Reconfiguring a Scale-Out SAP HANA System\\n© Copyright. All rights reserved.\\n67'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 73}, page_content='Unit 2\\nLesson 6\\nUnderstanding Failure of an SAP HANA Slave\\nNode\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nUnderstand what happens during a failure of a slave node\\nFailure of an SAP HANA Slave Node\\nBusiness Example\\nAs an SAP HANA database administrator, you need to understand the SAP HANA host auto-\\nfailover concept. To better understand this feature, you need to have hands-on experience\\nwith a slave node failing in a multi-host SAP HANA system.\\nFailure of an SAP HANA Node\\nHost auto-failover is a local fault recovery solution that can be used in addition to, or as an\\nalternative measure to, system replication. One (or more) standby hosts are added to an SAP\\nHANA system and configured to work in standby mode. If they are in standby mode, the\\ndatabases on these hosts do not contain any data and do not accept requests or queries. This\\nmeans that they cannot be used for other purposes, such as quality or test systems.\\nWhen a primary (worker) host fails, a standby host automatically takes its place. If neither the\\nname server process hdbnameserver, nor hdbdaemon respond to network requests (because\\nthe instance is stopped or the OS has been shut down or powered off), a host is marked as\\ninactive and an auto-failover is triggered. Since the standby host may take over operation\\nfrom any of the primary hosts, it needs shared access to all the database volumes. This can\\nbe accomplished by a shared, networked storage server, by using a distributed file system, or\\nwith vendor-specific solutions that use an SAP HANA programmatic interface, the Storage\\nConnector API, to dynamically detach and attach (mount) networked storage upon failover.\\n© Copyright. All rights reserved.\\n68'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 74}, page_content='Figure 47: How Host Auto-failover Works\\nAs implied by the name, the host auto-failover capability of SAP HANA is characterized as\\nfollows:\\nFailover is performed at the host level. All services of a host are moved to another host.\\nThe failure of a single process (service) does not trigger a failover.\\nThe failover happens automatically as an integral feature of SAP HANA. No external cluster\\nmanager is required.\\nData consistency is a key requirement. Data might be corrupted if a failed host (like the\\noriginal host 2 in the previous figure) is allowed to restart and write data to disk in parallel\\nto the failover host (the new slave host 3 in the previous figure).\\nTo ensure data consistency at all times, it must be guaranteed that a failover does not happen\\n(or at least does not succeed and may not cause corrupt data) if the failed host can potentially\\nstill write data. To achieve this, the SAP HANA host auto-failover uses a combination of\\nheartbeat and fencing.\\nHeartbeat\\nThe following types of heartbeat are used to check if another host is active as the master\\nbefore starting the current host as the master or performing a failover:\\nTCP communication-based heartbeats:\\n-\\nPing from nameserver to nameserver with SAP HANA internal communication protocol\\n-\\nPing from nameserver to hdbdaemon with SAP HANA internal communication protocol\\nStorage-based heartbeats:\\nThe current master nameserver periodically updates heartbeat files located on different\\nstorage partitions:\\n-\\nShared storage for the SAP HANA binaries\\n-\\nStorage partition 1 for the master node’s data\\nThese types of storage are typically connected with networks other than the inter-node\\nnetwork used for service-to-service communication (such as fiber channel for SAN or\\ndedicated Ethernet for NFS) and therefore these heartbeats provide additional value.\\nLesson: Understanding Failure of an SAP HANA Slave Node\\n© Copyright. All rights reserved.\\n69'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 75}, page_content='Fencing\\nIn rare cases, the heartbeats cannot detect if another host is alive, for example in split-brain\\nsituations where no communication is possible between hosts. I/O fencing ensures that the\\nother side does not access the data or log storage any more.\\nThe SAP HANA Storage Connector API, together with a specific Storage Connector, allows\\nusage of different types of storage and network architecture to ensure proper I/O fencing:\\nSAN storage: the SAP HANA Fiber Channel Storage Connector [2] using SCSI-3 persistent\\nreservations (SCSI-3 PGR).\\nNFSv3: used without file locking, but with a Storage Connector provided by certified\\nstorage vendors. This type of Storage Connector implements a Shoot The Other Node In\\nThe Head (STONITH) call to reboot a failed host.\\nIf an NFSv3 client dies (that is, the SAP HANA server), the file locks are not released on the\\nNFS server side resulting in a deadlock for any host that wants to access these files. Using\\nthe nolock mount option solves the locking problem, but with this option, data is not\\nprotected against parallel reading and writing from different hosts. To solve this, STONITH\\nmust be implemented.\\nNFSv4 or cluster file systems like GPFS: using file locks. A Storage Connector is not\\nrequired here as these file locks reliably prevent false access. However, a STONITH type\\nStorage Connector is provided by some storage vendors to speed up failover.\\nReview the SAP HANA Multi-Host Configuration from the Command Line\\nFigure 48: The Python landscapeHostConfiguration.py Script\\nThe SAP HANA multi-host configuration can also be viewed at the operating system level.\\nThere is a Python script called landscapeHostConfiguration.py\\n in the\\n$DIR_INSTANCE/exe/python_support\\n folder. Running the script as shown in the previous\\nfigure provides an overview of the configuration.\\nThe following host columns are shown in addition to the SAP HANA cockpit 2.0 view by this\\nscript:\\nSTORAGE_CONFIG_PARTITION / Storage Partition (Configured - new in SPS 12): The\\nstable sub-path to reassign the same storage partition after failovers.\\nWORKER_CONFIG_GROUPS / Worker Groups (Configured – new in HANA 2 SPS 00): The\\nstable classification values to assign hosts to logical worker groups.\\nWORKER_ACTUAL_GROUPS / Worker Groups (Actual – new in HANA 2 SPS 00): The\\ncurrent classification values to assign hosts to logical worker groups.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n70'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 76}, page_content='The return code may be consumed by cluster managers (for example, for SAP HANA system\\nreplication) to come to a decision on the system health state, as follows:\\n0 = Fatal. For example, database offline.\\n1 = Error. For example, a failover did not happen, because there was no standby host\\navailable.\\n2 = Warning. For example, a failover is possible.\\n4 = OK\\n5 = Ignore. For example, the system has switched roles (failover), but is fully functional.\\nA return code >= 4 indicates normal system operation. When the system is stopped, this\\nscript can also be used, but fills only a subset of the columns.\\nHost Failure Detection\\nFigure 49: Host Failure Detection Rules\\nA host failure is any dysfunctional state of a host that affects the communication between the\\nhosts of a distributed SAP HANA system. To check the functional state of a host, the name\\nservers regularly send a ping on the internal network communication layer to name servers on\\nother hosts. An additional ping to the hdbdaemon process is executed in the case where the\\nremote name server does not reply repeatedly. Only when both services do not reply in time,\\nis the host considered to have failed.\\nA crash of a single service does not trigger failover, because services are normally restarted\\nby the hdbdaemon. If a service is not able to restart for any reason, it is assumed that it is not\\nbe able to start on another host either.\\nAn exception is if the name server aborts itself during startup if the storage connector returns\\nan error. It then instructs hdbdaemon to shut down the whole database instance on the host\\nincluding the hdbdaemon itself, which allows failure detection and failover processing by\\nother hosts.\\nLesson: Understanding Failure of an SAP HANA Slave Node\\n© Copyright. All rights reserved.\\n71'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 77}, page_content='Checking Slave Hosts\\nThe name server communication heartbeat: The current master name server pings all\\nother name servers every 10 seconds. If a name server was active and five pings have\\nfailed (either immediately or after a 60 second ping timeout), the name server is\\nconsidered inactive. By pinging multiple times, SAP HANA can recover from short network\\noutages without triggering a failover.\\nThe hdbdaemon communication heartbeat: If a slave name server was considered inactive\\n(or had set itself to inactive), the master name server pings the slave hdbdaemon process.\\nIf the hdbdaemon ping fails (either immediately or after a 60 second ping timeout), the\\nhost is considered as inactive and a failover is initiated.\\nChecking the Master Host\\nThe name server communication heartbeat: Name server candidates, which are not\\ncurrently the master, ping other candidates with lower priority every 10 seconds. Together\\nwith the slave name server heartbeat described earlier (current master name server pings\\nall other name servers), normally MASTER1 pings MASTER2 and MASTER3, and MASTER2\\npings MASTER3. If a master candidate does not receive any ping within 30 seconds, it\\npings the master name server itself.\\nThe hdbdaemon communication heartbeat: If the ping to the master name server fails, the\\nhdbdaemon process on the master host is pinged. If the hdbdaemon does not answer\\nwithin 60 seconds, the current master host is considered inactive.\\nThe name server storage heartbeat: The name server candidate host checks the heartbeat\\nfiles for changes for a period of 60 seconds. Those files are updated by the current master\\nname server every 10 seconds with the hostname and a random string. A failover begins\\nonly if all files do not show any sign of changes for 60 seconds.\\nSlave Host Failover to a Standby Host\\nWhen a failure is detected and a replacement host is determined, the actual failover process\\nstarts.\\nFigure 50: Host Auto-failover Slave Failure\\nThe previous figure is a visualization of a slave host failover to a standby host. On the left, the\\noriginal state of the system is shown. On the right, the second host fails and its role is moved\\nto the fourth host.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n72'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 78}, page_content='Failover step-by-step:\\n1. Target host selection\\nIf there is a standby host with an exact match of corresponding actual host roles, it is\\nused.\\nIf there is a standby host with one of the roles that corresponds to the failing host, it is\\nused.\\nIf the failing host has an SAP HANA worker role, any unassigned standby is used.\\n2. The master name server calls the stonith() method of all installed HA/DR provider hooks\\nand the Storage Connector stonith() method. Typically the stonith() method is only\\nimplemented in NFSv3-related storage connectors and reboots the failed host.\\nNote:\\nIf STONITH fails, failover is aborted and all hosts remain in their old roles.\\n3. Swap actual services, host roles, storage partition number, and volume IDs of all services\\nbetween both hosts in the topology and inform all other hosts.\\n4. The master name server (which selected a replacement host), calls the name server on\\nthe target host to perform the failover.\\n5. The host that was promoted to a new role calls the Storage Connectors attach() method\\nto acquire the correct storage partition (if applicable) and calls the failover() method of all\\ninstalled HA/DR provider hooks.\\nNote:\\nIf this fails, the host stops. If there are still standby hosts available, another\\nfailover is triggered and this host is set to ERROR.\\n6. Reconfigure running standby services to load their newly assigned volume.\\nNote:\\nIf this fails, this is like a service failure and does not initiate a further failover.\\n7. Reconfigure hdbdaemon to start/stop services that should run on only one of the two\\nhosts.\\nNote:\\nIf this fails, this is like a service failure and does not initiated a further failover.\\nThe master name server is the only entity in the whole system that is able to make a failover\\ntarget host selection. Since the master has mechanisms to avoid split brain situations, there\\nis conceptually no split brain situation possible for slave hosts. If a slave loses its connection\\nto the master name server, it waits and is notified by the new master. If a slave cannot\\nconnect to a master during startup, it terminates itself.\\nLesson: Understanding Failure of an SAP HANA Slave Node\\n© Copyright. All rights reserved.\\n73'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 79}, page_content='Exercise “Failing SAP HANA Slave Node” Explained\\nFigure 51: Monitor the Host Auto-failover\\nIn this exercise, all admins monitor their SAP HANA node with the tools HDBAdmin and\\nsapcontrol. HDBAdmin is a graphical SAP Support tool that can be used to monitor the SAP\\nHANA system in real time. With sapcontrol, the SAP HANA admin can request the SAP HANA\\ninstance list from the command line.\\nFigure 52: Exercise Host Auto-Failover Slave Failure\\nThe admin on wdflbmt7347 simulates a slave node failure, by executing an <sid>adm a HDB\\nkill command. Due to this failure, the auto host-failover steps can be monitored in the\\nHDBadmin tool and by using sapcontrol at the command line.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n74'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 80}, page_content='LESSON SUMMARY\\nYou should now be able to:\\nUnderstand what happens during a failure of a slave node\\nLesson: Understanding Failure of an SAP HANA Slave Node\\n© Copyright. All rights reserved.\\n75'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 81}, page_content='Unit 2\\nLesson 7\\nUnderstanding Failure of the SAP HANA\\nMaster Node\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nUnderstand what happens during a failure of the master node\\nFailure of the SAP HANA Master Node\\nBusiness Example\\nAs an SAP HANA database administrator, you need to understand the SAP HANA host auto-\\nfailover concept. To better understand this feature, you need to have hands-on experience of\\na master node failing in a multi-host SAP HANA system.\\nFailover Algorithm Explained\\nIn contrast to other high availability solutions, SAP HANA does not use a quorum consisting of\\nmultiple SAP HANA hosts to decide which host can become master at initial startup or master\\nfailover. With heartbeats and fencing, a single host can reliably decide initial startup or master\\nfailover.\\nMaster Host Failover with Standby Host but All Master Candidates in Use (Double\\nFailover)\\nFigure 53: Master Failure With Double Failover\\nThe previous figure shows a master host failover to a slave host. On the left, the original state\\nof the system is shown. On the right, the first host fails and its master role is moved to the\\nsecond host. The original slave role of the second host is failed over to the standby host.\\n© Copyright. All rights reserved.\\n76'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 82}, page_content='Failover step-by-step:\\n1. If no master name server candidate with standby as an actual index server role is\\navailable, one of the master candidates currently used as index server slave is chosen as\\nthe new master.\\n2. The failover steps for the master host are like the scenario described in the figure, Master\\nHost Failover Without Available Standby Hosts.\\n3. The previously assigned slave is marked as failed and enters the failover queue. Because a\\nstandby host is available, slave failover starts shortly after master failover.\\n4. Both failovers are executed in parallel.\\nMaster Host Failover to a Standby Host\\nFigure 54: Master Failure To Standby Host\\nThe previous figure shows a master host failover to a standby host. On the left, the original\\nstate of the system is shown. On the right, the first host fails and its role is moved to the\\nfourth host.\\nFailover step-by-step:\\n1. The name server master candidate with the highest priority (= smallest number in the\\nconfigured name server role) detects the failure condition and initiates the failover.\\n2. If a name server candidate is available that is currently a standby host, the failover is\\nforwarded to this host. This avoids a double failover (see the second example following).\\n3. The failover includes the same steps as in the slave host failover scenario described\\nearlier.\\n4. The name server reloads its persistence from disk.\\nTarget Host Selection\\nThis section describes the selection process of the replacement host. Beginning with SPS11,\\nthe actual host roles (HOST_ACTUAL_ROLES) are considered.\\nFor SAP HANA 1.0 SPS11 and newer:\\nIf there is a standby host with an exact match of corresponding actual host roles, it is used.\\nLesson: Understanding Failure of the SAP HANA Master Node\\n© Copyright. All rights reserved.\\n77'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 83}, page_content='If there is a standby host with one of the roles that corresponds to the failing host, it is\\nused.\\nIf the failing host has an SAP HANA worker role, any unassigned standby is used.\\nFor SAP HANA 1.0 SPS10 and older:\\nIf there is a standby host, it is used.\\nIf there are multiple equivalent options available, the first host is used.\\nThe search steps are restricted to the same failover group, unless global.ini/[failover]/\\ncross_failover_groups=false was configured.\\nIf no host is available, no failover happens and HOST_STATUS shows ERROR.\\nMaster Host Failover Without Available Standby Hosts\\nDistributed landscapes without standby hosts may also perform a failover to ensure that the\\nmaster host is always available. Of course, a slave host (and all tables located there) is\\ninaccessible after failover.\\nThis failover mechanism can be disabled by removing the name server roles MASTER 2 and\\nMASTER 3 in the SAP HANA cockpit. Disabling is required if you use (not recommended) local\\nstorage on each host or the landscape is controlled by an external cluster manager.\\nThe wait timeout of a name server slave (non-master candidate) on a system restart is\\ndifferent than that of a master candidate. The number of retries to reach the master name\\nserver before aborting the startup is controlled with the following parameter:\\nnameserver.ini/[failover]/slave_to_master_startup_retries=10\\n.\\nBecause the wait interval after one unsuccessful retry is 5 seconds, the default parameter\\nvalue of 10 leads to a maximum wait time of 50 seconds.\\nFigure 55: Master Failure With No Standby Available\\nThe previous figure shows a master host failover to a slave host. On the left, the original state\\nof the system is shown. On the right, the first host fails and its role is moved to the second\\nhost. The original role of the second host is not available until a standby host is added to the\\nsystem or the failed first host is re-activated.\\nFailover step-by-step:\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n78'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 84}, page_content='1. The name server master candidate with the highest priority detects the failure conditions\\nand executes the failover steps itself.\\n2. The new master name server calls the stonith() method of all installed HA/DR provider\\nhooks and the Storage Connector stonith() method (if applicable) to reboot the failed\\nhost.\\na. If STONITH fails, the failover is aborted and the new master shuts itself down.\\nb. The (possibly) remaining third master candidate then retries the failover.\\nc. If this also fails, no master is available throughout the whole landscape and the slave\\nhosts eventually shut themselves down.\\n3. The new master stops all its services (except hdbdaemon and nameserver).\\n4. The new master calls the Storage Connector’s detach() method for the old storage\\npartition, the attach() method for the storage partition 1 (mnt00001 directory) and calls\\nthe failover() method of all installed failover hooks:\\na. If this fails, failover is aborted, and the new master shuts itself down.\\nb. The (possibly) remaining third master candidate then retries the failover.\\nc. If this also fails, no master is available throughout the whole landscape, and the slave\\nhosts shut themselves down.\\n5. The new master name server loads its persistence from disk.\\n6. Currently existing services, host roles, storage partition number, volume IDs of all services\\nare swaped between both hosts in the topology and all name servers are informed.\\n7. The hdbdaemon process is reconfigured, which starts all the required services.\\n8. The role of the displaced slave host remains inactive; the system is only partially available.\\nHost Auto-Failover vs External Cluster Manager\\nInstead of using the built-in SAP HANA host auto-failover, you could monitor and (re)start\\nvirtualized hosts on different hardware with an external cluster manager. With multiple SAP\\nHANA instances, this would have the advantage that fewer standby hosts would be needed,\\nbut on the other hand, all failure detection and fencing logic would have to be implemented\\nexternally. To avoid unnecessary SAP HANA-controlled master failovers, the name server\\nMASTER 2 and MASTER 3 roles can be removed as described previously.\\nAutomatic Host Shutdown by Service Failures\\nFor every service, a fixed number of restarts can be defined after which the daemon stops\\nitself. The relevant parameters are set for each service type in daemon.ini:\\n# If set to true the daemon will shut down all services on the host if \\n# this service cannot start \\nstartup_error_shutdown_instance=true\\n# Number of retries if a service fails in startup procedure \\nstartup_error_restart_retries=4\\nThe name server is the only service that has the latter parameter set to true by default. This\\nmeans that any problem involving a constant name server crash, stops the daemon\\neventually. For instance, the presented settings may be used for the index server if recurring\\nstart-up problems of that service should stop the affected database instance.\\nLesson: Understanding Failure of the SAP HANA Master Node\\n© Copyright. All rights reserved.\\n79'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 85}, page_content='SAP HANA and Split Brain\\nIn SAP HANA’s master/slave/standby failover solution, there is only one entity in the whole\\nsystem that can make failover decisions, that is, the master name server. A slave or standby\\nhost never executes a failover by itself. Therefore, only the master host must be considered\\nfor split brain situations.\\nSAP HANA would run into a split-brain situation if multiple hosts try to become master name\\nserver/index server and access the same set of data (persistence) from disk. This would\\nirreparably destroy the data. To overcome this problem, SAP HANA uses I/O fencing to\\nprevent the other host from accessing the storage, as follows:\\nSAN storage: The storage devices are locked by the current active host with SCSI-3\\npersistent reservations. If another host tries to mount those devices, the old host\\nautomatically loses write permissions and the services abort themselves.\\nNFSv3 shared storage: The NFSv3 file lock implementation cannot be used as locks would\\nnot be released if an NFSv3 client dies, so a STONITH procedure must be provided by the\\nstorage vendor, which reboots a failed host.\\nNFSv4 shared storage or cluster file systems like GPFS: The file locking implementation\\nworks reliably across hosts. Non-availability of a host, and thus lock release, is handled by\\nthe file system. A host that tries to open a persistence that is already open fails and aborts\\nitself.\\nCommunication network and storage network based heartbeats are used to detect activeness\\nof other hosts and prevent unnecessary failover attempts. If the target master host detects\\nthat another master is still active, it terminates itself to let the other master continue. Without\\nthis, different hosts could try to become master and would fence each other repeatedly.\\nIn a split brain situation, a quorum is sometimes used to decide, which side should ‘survive’.\\nThis makes sense in stateless compute clusters to have the bigger parts of resources\\nremaining active. However, in SAP HANA, tables are bound to specific storage partitions and\\nservice instances. Tables in the other partition would not be accessible and applications\\ntypically cannot continue with some tables inaccessible. Therefore, SAP HANA lets the initial\\nmaster continue.\\nhdbnsutil\\nSome actions, supported by the hdbnsutil executable, access the persistence while the\\nsystem is stopped. To avoid data corruption caused by unexpected active or reviving services,\\nthis program also checks for active name servers with network and storage based heartbeats\\nand uses fencing to set the SCSI-3 persistent reservation.\\nSAN storages: After stopping hdbnsutil (or the name server), the SCSI-3 persistent\\nreservations are intentionally not released. This ensures that no other service unintentionally\\naccesses a persistence, such as still-running services on other hosts after a split-brain\\nsituation\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n80'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 86}, page_content='Host Auto-failover Duration\\nFigure 56: SAP HANA Failover Duration\\nThe failover phase can be split into the following steps:\\n1. Failure detection\\nSeveral watchdogs, retries, and timeouts are involved. Based on the failure condition, the\\ndetection time can vary, for example as follows:\\nSAP HANA instance terminated or host shut down\\nThe checking host immediately gets errors from the OS layer and typically detects the\\nfailure in less than one minute.\\nNetwork split\\nThe checking host must wait until the network times out, so failure detection typically\\ntakes three to six minutes. The timeouts could be reduced, but this is not\\nrecommended, as it would not allow recovery from short network outages, or could\\nlead to a false failover decision in the case of heavy system load, where pings can take\\nlonger.\\n2. Failover execution\\nThe failover time is comparable to the time required for SAP HANA startup, because the\\nservices on a standby host are initially started, but run idle. During failover, they do the\\nsame initialization and persistence load as in regular service startups.\\nHost Start Order/Landscape Restart\\nAll hosts can be started concurrently. The master name server candidates have different\\npriorities as indicated by the role name MASTER 1, 2, and 3. The first master candidate\\nbecomes the active master. The index server roles, host roles, and storage partitions are\\nreset, meaning that all configured worker hosts are used as worker again, even if the\\nlandscape was in a failed over state before shutdown.\\nLesson: Understanding Failure of the SAP HANA Master Node\\n© Copyright. All rights reserved.\\n81'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 87}, page_content=\"Up to SPS11, if a host was previously used as a worker, its storage partition is kept as is, to\\navoid inefficient access patterns in clustered file systems. So over time, the storage partitions\\nmay have different sorting compared to their initial state after installation.\\nAs of SPS12, a landscape restart considers the configured storage partitions, bringing the\\nsystem back to its original state. As a prerequisite, the master name server must be on its\\noriginal host (with a configured storage partition of 1). In an SAP HANA system replication\\nsetup, only the primary system performs this failback operation.\\nFailback\\nWhen a failover was performed and the failed host is available again, no automatic failback\\nhappens; the host starts as a standby. A controlled failback can be performed by stopping or\\nrestarting the configured standby host which, after a previous failover, is actually a worker.\\nAutomatic failback only happens when the complete landscape is restarted.\\nMaster Nameserver Candidates\\nThe initial host is a master candidate and the first two hosts added to a landscape become\\nmaster candidates. When a standby host is added and none of the master candidates is a\\nstandby host, the last master candidate is moved to the new standby host. Having a standby\\nhost in the master candidate list allows faster master host failover because it avoids the\\npreviously-mentioned double failover.\\nFailover Groups\\nDuring installation and with SAP HANA Studio, a failover group can be configured per host. If a\\nfailover target host is available in the same group, it is preferred over hosts from other groups.\\nThis can be used to achieve better 'locality' in large systems, to use network/storage\\nconnections with less latency. When the parameter \\nnameserver.ini/[failover]/\\ncross_failover_group\\n is set to false, failover is restricted to hosts in the same group. This\\ncan be used to separate differently sized hardware or separate storage entities.\\nApplication Configuration\\nIn the connection information for SAP HANA SQL client libraries (for example, hdbuserstore),\\nyou can configure multiple host names. All master name server candidates should be\\nconfigured there. The master candidates can be found using the following SQL statement:\\nselect HOST from SYS.M_LANDSCAPE_HOST_CONFIGURATION where \\nNAMESERVER_CONFIG_ROLE like 'MASTER%' order by NAMESERVER_CONFIG_ROLE\\nApplication Error Handling\\nFailover is not seamless. Errors during a failure phase are returned to the clients. Neither\\nserver nor client libraries have built-in 'retry' logic. Applications must be prepared and should\\ntry to reconnect.\\nMaster host failure: The client typically gets error -11312 (Connection to database server\\nlost; check server and network status [System error: ...])\\nSlave host failure: Basically, any error code can happen, because the master connection is\\nstill available, but some tables are no longer accessible and statements can fail at various\\nsteps.\\nLESSON SUMMARY\\nYou should now be able to:\\nUnderstand what happens during a failure of the master node\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n82\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 88}, page_content='Unit 2\\nLesson 8\\nRemoving a Host from a Scale-Out System\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nRemove a host from a scale-out system\\nRemoval of a Host from a Scale-Out System\\nBusiness Example\\nAs a SAP HANA database administrator you need to understand how to change the SAP\\nHANA multi-host configuration. To better understand this feature, you remove the standby\\nnode from the SAP HANA system.\\nRemove a Host in a Multi-Host SAP HANA System\\nIn a distributed SAP HANA system, tables and table partitions are assigned to an index server\\non a specific host at their time of creation, but this assignment can be changed. In certain\\nsituations, it is even necessary. You can use SAP HANA cockpit 2.0 together with the SAP\\nHANA Database Explorer to execute automatic redistribution operations.\\nThere are several occasions when tables or partitions of tables need to be moved to other\\nservers. For example, if you plan to remove a host from your system, then you first need to\\nmove all the data on that host to the other hosts in the system. Redistributing tables may also\\nbe useful if you suspect that the current distribution is no longer optimal.\\nAlthough it is possible to move tables and table partitions manually from one host to another,\\nthis is neither practical nor feasible for a large-scale redistribution of data.\\nRedistribute Tables Before Removing a Host\\nFigure 57: Move All Tables to Free up a Host\\n© Copyright. All rights reserved.\\n83'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 89}, page_content=\"Before you can remove a host from your SAP HANA system, you must move the tables on the\\nindex server of the host in question to the index servers on the remaining hosts in the system.\\nPrerequisites\\nTo redistribute tables across the hosts in your system, you must have the system privilege\\nRESOURCE ADMIN and at least the object privilege ALTER for all schemas involved. As\\nredistributing data is a critical operation, it is also recommended that you have saved the\\ncurrent distribution so you can restore it if necessary.\\nProcedure\\n1. From the SAP HANA Cockpit 2.0 – Database Directory  screen, choose the Open SQL\\nConsole link.\\n2. In the Database Explorer, select your <Tenant>@< SID > and click on the Open SQL\\nConsole icon in the top-left corner.\\n3. In the SQL Console, execute the following commands:\\ncall SYS.UPDATE_LANDSCAPE_CONFIGURATION( 'SET REMOVE','<host>' );\\ncall REORG_GENERATE(2,'');\\nselect * from SYS.REORG_STEPS;\\ncall REORG_EXECUTE(?);\\n4. In the Host Failover screen, check the status of the host in the column Remove Status. If\\nthere is no column Remove Status, then add it using the Settings options.\\n5. If the column Remove Status has the value REORG FINISHED or REORG NOT REQUIR, the\\nhost can be removed from the system.\\n6. Use the resident hdblcm, hdblcmgui, or the web-based hdblcm tool to remove the host\\nfrom the multi-host SAP HANA system.\\nFigure 58: Tools to Remove a Host\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n84\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 90}, page_content='Caution:\\nRemoving a host breaks the backup history of the database. To ensure that the\\ndatabase is fully recoverable, perform a full backup (data backup or storage\\nsnapshot) immediately after adding a service.\\nRemove Hosts Using the Graphical User Interface or the Command-line Interface\\nYou can remove hosts from an SAP HANA system using the SAP HANA database lifecycle\\nmanager (HDBLCM) in the graphical user interface or the command-line interface.\\nGeneral Prerequisites\\nYou have the credentials of the root user and the <sid>adm user.\\nThe SAP HANA system has been installed with the SAP HANA database lifecycle manager.\\nThe <sid>adm user has read and execute permissions for the directory that contains the\\ninstallation medium.\\nIf you want to remove a host that runs the master name server, another host that will take\\nover the role of the master name server must be up and running.\\nRemove Hosts Using the Web User Interface\\nYou can remove hosts from an SAP HANA system using the SAP HANA database lifecycle\\nmanager web user interface.\\nGeneral Prerequisites:\\nYou require the credentials of the root user and the <sid>adm user.\\nThe SAP HANA system has been installed with the SAP HANA database lifecycle manager.\\nThe <sid>adm user has read and execute permissions for the directory that contains the\\ninstallation medium.\\nCommunication port 1129 is open for SSL communication with the SAP Host Agent.\\nIf you want to remove a host that runs the master name server, another host that will take\\nover the role of the master name server must be up and running.\\nWeb Browser Prerequisites:\\nOn Microsoft Windows:\\nInternet Explorer - Version 9 or higher\\nIf you are running Internet Explorer version 9, ensure that your browser is not running in\\ncompatibility mode with your SAP HANA host. You can check this in your browser by\\nchoosing Tools   \\nCompatibility   \\nView Settings.\\nMicrosoft Edge\\nMozilla Firefox - Latest version and Extended Support Release\\nGoogle Chrome - Latest version\\nOn SUSE Linux:\\nMozilla Firefox with XULRunner 10.0.4 ESR\\nLesson: Removing a Host from a Scale-Out System\\n© Copyright. All rights reserved.\\n85'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 91}, page_content='On Mac OS:\\nSafari 5.1 or higher\\nNote:\\nFor more information about supported web browsers for the SAP HANA database\\nlifecycle manager web interface, see the browser support for the sap.m library in\\nthe SAPUI5 Developer Guide.\\nThe Exercise Remove Host Explained\\nIn the exercise for this lesson, the standby host is removed from the multi-host SAP HANA\\nsystem. This action is performed by participant 03. In the next exercise we add the host again\\nas a slave node.\\nFigure 59: Exercise Remove Host Explained\\nDuring the exercises, in the Unit “Scale-out and Multitenant Database Containers”, this fourth\\nserver is used as an additional slave node.\\nLESSON SUMMARY\\nYou should now be able to:\\nRemove a host from a scale-out system\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n86'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 92}, page_content='Unit 2\\nLesson 9\\nAdding a Host to a Scale-Out System\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nAdd a host to a scale-out system\\nAdding a Host to a Scale-Out System\\nBusiness Example\\nAs an SAP HANA database administrator, you need to understand how to extend an SAP\\nHANA multi-host system with additional hosts. To better understand this feature, you add a\\nnew slave node to the existing SAP HANA scale-out system.\\nAdding Hosts to an SAP HANA System\\nYou can add hosts to an SAP HANA system using the SAP HANA database lifecycle manager\\n(HDBLCM) resident program or the SAP HANA database lifecycle manager web user\\ninterface.\\nIf you want to configure a new multiple-host (distributed) system during installation, see the\\nmultiple-host system installation information in the SAP HANA Server Installation and Update\\nGuide.\\nBefore adding a host to an SAP HANA system, you need to consider the following:\\nIf you are adding hosts from a host that is already integrated in the SAP HANA system\\nIf the system is a single-host or multiple-host system\\nThe number of hosts you want to add to the system at one time\\nIf you are adding a host to a single-host system, the listen interface is automatically\\nconfigured to global during the host addition. After the host is added to the system, the\\ninternal network address can be defined and the inter-service communication can be\\nreconfigured to a different setting, if required.\\n© Copyright. All rights reserved.\\n87'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 93}, page_content='Figure 60: Tools to Add a Host\\nAdd Hosts Using the Graphical User Interface or the Command-line Interface\\nYou can add hosts to an SAP HANA system using the SAP HANA database lifecycle manager\\nresident program in the graphical user interface.\\nPrerequisites:\\nThe SAP HANA system has been installed with its server software on a shared file system\\n(export options: rw, no_root_squash).\\nThe host has access to the installation directories <sapmnt> and <sapmnt>/<SID>.\\nThe SAP HANA system has been installed with the SAP HANA database lifecycle manager.\\nThe SAP HANA database server is up and running.\\nYou are logged on as root user or as the system administrator user <sid>adm.\\nThe difference between the system time set on the installation host and the additional host\\nis not greater than 180 seconds.\\nThe operating system administrator (<sid>adm) user may exist on the additional host.\\nEnsure that you have the password of the existing <sid>adm user, and that the user\\nattributes and group assignments are correct. The SAP HANA database lifecycle manager\\nresident program does not modify the properties of any existing user or group.\\nAdd Hosts Using the Web User Interface\\nYou can add hosts to an SAP HANA system using the SAP HANA database lifecycle manager\\nweb user interface.\\nPrerequisites:\\nOn the host that is to be added, the SAP Host Agent is installed with SSL configured. The\\nSAP Host Agent creates the <sapsys> group, if it does not exist prior to installation. Ensure\\nthat the group ID of the <sapsys> group is the same on all hosts.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n88'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 94}, page_content='The difference between the system time set on the installation host and the additional host\\nis not greater than 180 seconds.\\nThe operating system administrator (<SID>adm) user may exist on the additional host.\\nEnsure that you have the password of the existing <SID>adm user, and that the user\\nattributes and group assignments are correct. The SAP HANA database lifecycle manager\\n(HDBLCM) does not modify the properties of any existing user or group.\\nThe SAP HANA system has been installed with its server software on a shared file system\\n(export options: rw, no_root_squash).\\nThe host has access to the installation directories <sapmnt> and <sapmnt>/<SID>.\\nThe SAP HANA system has been installed with the SAP HANA database lifecycle manager\\n(HDBLCM).\\nThe SAP HANA database server is up and running.\\nCommunication port 1129 is open.\\nPort 1129 is required for the SSL communication with the SAP Host Agent in a standalone\\nbrowser using HTTPS.\\nWeb Browser Prerequisites:\\nOn Microsoft Windows:\\nInternet Explorer - Version 9 or higher\\nIf you are running Internet Explorer version 9, ensure that your browser is not running in\\ncompatibility mode with your SAP HANA host. You can check this in your browser by\\nchoosing Tools   \\n Compatibility   \\n View Settings.\\nMicrosoft Edge\\nMozilla Firefox - Latest version and Extended Support Release\\nGoogle Chrome - Latest version\\nOn SUSE Linux:\\nMozilla Firefox with XULRunner 10.0.4 ESR\\nOn Mac OS:\\nSafari 5.1 or higher\\nNote:\\nFor more information about supported web browsers for the SAP HANA database\\nlifecycle manager web interface, see the browser support for the sap.m library in\\nthe SAPUI5 Developer Guide.\\nRedistribute Tables After Adding a Host\\nAfter you have added a new worker host to your SAP HANA system, you need to redistribute\\nthe tables in the system to balance the memory footprint of the tables and to improve\\nperformance (load balancing).\\nLesson: Adding a Host to a Scale-Out System\\n© Copyright. All rights reserved.\\n89'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 95}, page_content='You can run table redistribution from the command line. This approach offers additional\\nfunctionality including the option to modify, at runtime, some of the configuration parameters\\nthat control redistribution.\\nFigure 61: Redistribute Tables After Adding a Host\\nTable redistribution is based on the table placement rules defined in the table\\nTABLE_PLACEMENT. These determine, for example, table sizes, partitioning threshold\\nvalues, and preferred partition locations. Redistribution is a two-stage process: the first is to\\ngenerate the plan, and the second is to execute the plan. Separate commands are used for\\neach stage:\\n1. The plan generation command is a multi-purpose tool that requires an algorithm number\\nas a parameter to determine which actions are executed. Depending on the algorithm\\nselected, additional optional parameter values may also be available to give more control\\nover the execution.\\n2. The plan execution command takes a single parameter which is the numeric plan ID value.\\nYou can retrieve this value (REORG_ID) from the REORG_OVERVIEW system view. Refer\\nto the System Views section following.\\nThe syntax for these commands is:\\nCALL REORG_GENERATE(< algorithm integer>, < optional parameter string>);\\nCALL REORG_EXECUTE(< plan_id>)\\nResource admin privilege is required to call REORG_GENERATE(). The command only\\noperates on tables and partitions that the executing user is allowed to see as catalog objects.\\nGenerating the Plan: Algorithms and Options\\nThe following table gives an overview of the most commonly-required algorithms and a\\nsummary of the options available for each one. See the examples and details of the options\\nthat follow.\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n90'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 96}, page_content='Algori\\nthm\\nNum\\nber\\nAlgorithm Name\\nDescription\\n6\\nBalance\\nlandscape\\nThis function checks if tables in the landscape are placed on\\ninvalid severs according to the table placement rules, and checks\\nif a split or merge is necessary to achieve optimal positions for the\\npartitions and tables and to evenly distribute tables across the\\nindex server hosts.\\nOptions: SCHEMA_NAME | TABLE_NAME | GROUP_NAME |\\nGROUP_TYPE | GROUP_SUBTYPE | RECALC | NO_PLAN |\\nNO_SPLIT | SCOPE\\n1\\nAdd server\\nRun this check after adding one or more index servers to the\\nlandscape. If new partitions can be created, a plan is generated to\\nsplit the tables and move the new partitions to the newly added\\nindex servers.\\nOptions: SCHEMA_NAME | TABLE_NAME | GROUP_NAME |\\nGROUP_TYPE | GROUP_SUBTYPE | RECALC | NO_PLAN\\n4\\nSave\\nSave the current landscape setup. No optional parameters.\\n5\\nRestore\\nRestore a saved landscape setup. Enter the plan ID value as the\\noptional parameter value.\\n7\\nCheck number of\\npartitions\\nThis function checks if partitioned tables need to be re-partitioned\\nand creates a plan to split tables if the partitions exceed a\\nconfigured row count threshold. No optional parameters.\\n14\\nCheck table\\nplacement\\nCheck the current landscape against table placement rules and (if\\nnecessary) provide a plan to move tables and partitions to the\\ncorrect hosts.\\nOptions: LEAVE_UNCHANGED_UNTOUCHED | KEEP_VALID |\\nNO_SPLIT\\n15\\nRerun plan\\nRerun failed items from previously executed plans.\\nOption: RERUN_ALL\\n16\\nHousekeeping\\nPerform housekeeping tasks. Additional privileges may be\\nrequired for specific actions.\\nOptions: OPTIMIZE_COMPRESSION | DEFRAG | LOAD_TABLE |\\nMERGE_DELTA | ALL\\nOptional Parameters\\nThe following table gives more details of the optional parameters that are available.\\nLesson: Adding a Host to a Scale-Out System\\n© Copyright. All rights reserved.\\n91'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 97}, page_content=\"Option\\nType\\nDetail\\nSCHEMA_N\\nAME\\nString\\nRestrict redistribution to the named schema(s) - comma-separated\\nlist.\\nTABLE_NA\\nME\\nString\\nRestrict redistribution to the named table(s) - comma-separated\\nlist.\\nGROUP_NA\\nME\\nString\\nRestrict redistribution to the named group(s) - comma-separated\\nlist.\\nGROUP_TY\\nPE\\nString\\nRestrict redistribution to the named group types(s) - comma-\\nseparated list.\\nGROUP_SU\\nBTYPE\\nString\\nRestrict redistribution to the named group sub types(s) - comma-\\nseparated list.\\nRECALC\\nTrue /\\nFalse\\nIf true, recalculate the landscape data of the last\\nREORG_GENERATE run. This option works only if\\nREORG_GENERATE has been called previously within the same\\nconnection session. This parameter can be used to speed up plan\\ngeneration with different parameters.\\nNO_PLAN\\nTrue /\\nFalse\\nIf true, the planning stage of generating the plan is skipped. This can\\nbe used with external tools when landscape data needs to be\\ncollected and a distribution must be calculated, but may be\\nmodified.\\nSCOPE\\nKeyword\\nScope the redistribution to include only the named items specified\\nby the following keywords. The default value is 'ALL' so that all\\ntables visible to the user are included in the redistribution.\\nLOADED - Tables that are loaded or partially loaded\\nUNLOADED - Tables that are not loaded\\nFILLED - Tables with a record count greater than 10\\nEMPTY - Tables with a record count less than or equal to 10\\nUSED - Tables with a total execution count greater than 10\\nUNUSED - Tables with a total execution count of less than or\\nequal to 10\\nLOB - Tables with LOB columns\\nNOLOB - Tables without LOB columns\\nExamples\\nAdd server (algorithm 1):\\nWith this algorithm, you can use the optional filter parameters to, for example, restrict\\nredistribution to specified schemas, tables, table groups, and so on. The following example\\nuses the SCHEMA_NAME option to generate a plan for all tables in schema SAPBWP:\\nCALL REORG_GENERATE(1, 'SCHEMA_NAME => SAPBWP')\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n92\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 98}, page_content=\"Balance Landscape / Table (algorithm 6):\\nThe following examples show the usage of optional parameters with this balancing algorithm.\\nIf the options parameter string is left blank, a plan is generated for all visible tables:\\nCALL REORG_GENERATE(6,'');\\nThis example uses the GROUP_NAME option to generate a plan for all tables in the three\\nspecified groups:\\nCALL REORG_GENERATE(6,'GROUP_NAME=>TABLEGROUP1, TABLEGROUP2, \\nTABLEGROUP3');\\nThis example uses the SCHEMA_NAME option to generate a plan for all tables in the schema\\nSAPBWP:\\nCALL REORG_GENERATE(6,'SCHEMA_NAME => SAPBWP');\\nThis example shows usage of the SCOPE option. The plan is restricted to only tables with a\\nrecord count greater than 10 and that have no LOB columns:\\nCALL REORG_GENERATE(6, 'SCOPE=>FILLED,NOLOB');\\nSystem Views\\nThe following system views show details of table redistribution. The last two views in the list\\nshow information about the most recent distribution operation. The details are deleted when\\nthe current connection to the database is closed.\\nREORG_OVERVIEW – Provides an overview of landscape redistributions.\\nREORG_STEPS – Shows details of the individual steps (items) of each plan.\\nREORG_PLAN – Contains details of the last table redistribution plan generated with this\\ndatabase connection.\\nREORG_PLAN_INFOS – Shows details (as key-value pairs) of the last executed\\nredistribution (algorithm value and parameters used).\\nExercise Add a Host Explained\\nIn the exercise of this lesson, the empty host is added to the multi-host SAP HANA system as\\na slave node. This action is performed by participant 02.\\nLesson: Adding a Host to a Scale-Out System\\n© Copyright. All rights reserved.\\n93\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 99}, page_content='Figure 62: Exercise Add a Host Explained\\nDuring the exercises in the Unit “Scale-out and Multitenant Database Containers”, this\\nadditional slave node is used to store some of the created tenants.\\nLESSON SUMMARY\\nYou should now be able to:\\nAdd a host to a scale-out system\\nUnit 2: SAP HANA Fault Tolerance\\n© Copyright. All rights reserved.\\n94'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 100}, page_content='Unit 2\\nLearning Assessment\\n1. Additional hosts can be added to a single-host SAP HANA database using the resident\\nHDBLCM tools.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n2. Which of the following role types can be selected during the installation of an SAP HANA\\nscale-out system?\\nChoose the correct answers.\\nX\\nA Worker\\nX\\nB Master\\nX\\nC Slave\\nX\\nD Standby\\n3. Scale-up can be used to improve SAP HANA high availability.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n4. Which partitioning best practices should you use to create an optimal partitioning plan?\\nChoose the correct answers.\\nX\\nA As few partition key columns as possible.\\nX\\nB SAP BW/4HANA: All partitions on same host.\\nX\\nC As many partitioned tables as possible.\\nX\\nD No additional unique constraints.\\n© Copyright. All rights reserved.\\n95'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 101}, page_content='5. Which SAP HANA system views provide details of table redistribution?\\nChoose the correct answers.\\nX\\nA M_REORG_ALGORITHMS\\nX\\nB EXPLAIN_PLAN_TABLE\\nX\\nC REORG_PLAN\\nX\\nD REORG_OVERVIEW\\n6. The Master 1 role is fixed after installation, and cannot be reconfigured to a different host.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n7. Which of the following are valid role types that you can assign to the name server and\\nindex server when you reconfigure the system in the Host Failover application?\\nChoose the correct answers.\\nX\\nA Name server - Worker\\nX\\nB Name server - Master 1\\nX\\nC Index server - Master\\nX\\nD Index server - Standby\\n8. SAP HANA host auto-failover only handles slave node failures. Master node failures need\\nto be handled by SAP HANA system replication.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n9. Which of the following are capabilities of SAP HANA host auto-failover?\\nChoose the correct answers.\\nX\\nA STONITH is activated at the host level.\\nX\\nB Failover is performed at the SAP HANA services level.\\nX\\nC The failover happens automatically as an integral feature of SAP HANA.\\nX\\nD Data consistency is a key requirement.\\nUnit 2: Learning Assessment\\n© Copyright. All rights reserved.\\n96'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 102}, page_content='10. When an SAP HANA master node fails, there is always a double failover.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n11. What configuration setting needs to be set up to avoid a double failover?\\nChoose the correct answer.\\nX\\nA Set the third node to the Standby role.\\nX\\nB Have a standby host in the master candidate list.\\nX\\nC Have a worker host in the master candidate list.\\nX\\nD Assign the Worker role to the Master 3 nameserver node.\\n12. When removing a host from a multi-host SAP HANA system, you need to redistribute the\\ntables first.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n13. Which of the following tools can you use to remove a host from a multi-host SAP HANA\\nsystem?\\nChoose the correct answers.\\nX\\nA Resident hdblcm\\nX\\nB hdblcmgui\\nX\\nC SAP HANA cockpit\\nX\\nD Web-based hdblcm\\n14. When a new host is added to an SAP HANA database system, the existing tables are\\nautomatically redistributed over the available nodes.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nUnit 2: Learning Assessment\\n© Copyright. All rights reserved.\\n97'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 103}, page_content='Unit 2\\nLearning Assessment - Answers\\n1. Additional hosts can be added to a single-host SAP HANA database using the resident\\nHDBLCM tools.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! You can use the resident HDBLCM tools to add additional hosts to a SAP\\nHANA database.\\n2. Which of the following role types can be selected during the installation of an SAP HANA\\nscale-out system?\\nChoose the correct answers.\\nX\\nA Worker\\nX\\nB Master\\nX\\nC Slave\\nX\\nD Standby\\nYou are correct! The roles Worker and Standby can be selected during the installation of\\nan SAP HANA scale-out system.\\n3. Scale-up can be used to improve SAP HANA high availability.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! Scale-up means increasing the size of one physical machine by increasing\\nthe amount of RAM available for processing. It does not improve SAP HANA high\\navailability. Read more about this in the lesson \"Explaining the SAP HANA High Availability\\nFeatures” of the course HA201.\\n© Copyright. All rights reserved.\\n98'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 104}, page_content='4. Which partitioning best practices should you use to create an optimal partitioning plan?\\nChoose the correct answers.\\nX\\nA As few partition key columns as possible.\\nX\\nB SAP BW/4HANA: All partitions on same host.\\nX\\nC As many partitioned tables as possible.\\nX\\nD No additional unique constraints.\\nYou are correct! As few as possible partition key columns and no additional unique\\nconstraints are partitioning best practices. Read more about this in the lesson\\n\"Partitioning Tables\" of the course HA201.\\n5. Which SAP HANA system views provide details of table redistribution?\\nChoose the correct answers.\\nX\\nA M_REORG_ALGORITHMS\\nX\\nB EXPLAIN_PLAN_TABLE\\nX\\nC REORG_PLAN\\nX\\nD REORG_OVERVIEW\\nYou are correct! The SAP HANA system views REORG_PLAN and REORG_OVERVIEW\\nprovide details of table redistribution.\\n6. The Master 1 role is fixed after installation, and cannot be reconfigured to a different host.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! Even the Master 1 role can be assigned to a different server.\\nUnit 2: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n99'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 105}, page_content='7. Which of the following are valid role types that you can assign to the name server and\\nindex server when you reconfigure the system in the Host Failover application?\\nChoose the correct answers.\\nX\\nA Name server - Worker\\nX\\nB Name server - Master 1\\nX\\nC Index server - Master\\nX\\nD Index server - Standby\\nYou are correct! Name server - Master 1 and Index server - Standby are valid role types\\nthat you can assign to the name server and index server when you reconfigure the system.\\n8. SAP HANA host auto-failover only handles slave node failures. Master node failures need\\nto be handled by SAP HANA system replication.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! SAP HANA host auto-failover handles failures of master and slave nodes.\\n9. Which of the following are capabilities of SAP HANA host auto-failover?\\nChoose the correct answers.\\nX\\nA STONITH is activated at the host level.\\nX\\nB Failover is performed at the SAP HANA services level.\\nX\\nC The failover happens automatically as an integral feature of SAP HANA.\\nX\\nD Data consistency is a key requirement.\\nYou are correct! Automatic failover and data consistency are capabilities of SAP HANA\\nhost auto-failover.\\n10. When an SAP HANA master node fails, there is always a double failover.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! There is no double failover if one of the master candidates is located on a\\nstandby server.\\nUnit 2: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n100'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 106}, page_content='11. What configuration setting needs to be set up to avoid a double failover?\\nChoose the correct answer.\\nX\\nA Set the third node to the Standby role.\\nX\\nB Have a standby host in the master candidate list.\\nX\\nC Have a worker host in the master candidate list.\\nX\\nD Assign the Worker role to the Master 3 nameserver node.\\nYou are correct! Having a standby host in the master candidate list avoids a double\\nfailover.\\n12. When removing a host from a multi-host SAP HANA system, you need to redistribute the\\ntables first.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! Before a host can be removed from an SAP HANA system, all the tables\\nassigned to that host need to be redistributed to the other nodes.\\n13. Which of the following tools can you use to remove a host from a multi-host SAP HANA\\nsystem?\\nChoose the correct answers.\\nX\\nA Resident hdblcm\\nX\\nB hdblcmgui\\nX\\nC SAP HANA cockpit\\nX\\nD Web-based hdblcm\\nYou are correct! You can use the Resident hdblcm and the Web-based hdblcm tools to\\nremove a host from a multi-host SAP HANA system.\\n14. When a new host is added to an SAP HANA database system, the existing tables are\\nautomatically redistributed over the available nodes.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! After adding an additional host, you must manually start the table\\nredistribution. Load balancing is only done automatically for new tables.\\nUnit 2: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n101'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 107}, page_content='UNIT 3\\nSAP HANA Disaster\\nTolerance\\nLesson 1\\nExplaining SAP HANA Storage Replication\\n104\\nLesson 2\\nExplaining SAP HANA System Replication\\n108\\nLesson 3\\nSetting up SAP HANA System Replication\\n117\\nLesson 4\\nCreating Tenant Databases in a System Replication Scenario\\n133\\nLesson 5\\nPerforming a Takeover on the Secondary System\\n135\\nLesson 6\\nSetting up Active/Active System Replication\\n146\\nLesson 7\\nSetting up SAP HANA System Replication with Secondary Time Travel\\n150\\nLesson 8\\nExplaining Zero Downtime Maintenance\\n156\\nLesson 9\\nIntroducing Multitier and Multitarget System Replication\\n159\\nUNIT OBJECTIVES\\nExplain SAP HANA storage replication\\nExplain SAP HANA system replication\\n© Copyright. All rights reserved.\\n102'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 108}, page_content='Set up SAP HANA system replication\\nCreate tenant databases in a system replication scenario\\nPerform a takeover on the secondary system\\nSet up Active/Active SAP HANA system replication\\nSet up SAP HANA system replication with Secondary Time Travel\\nExplain Zero Downtime Maintenance\\nExplain Multitier and Multitarget System Replication\\n© Copyright. All rights reserved.\\n103'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 109}, page_content='Unit 3\\nLesson 1\\nExplaining SAP HANA Storage Replication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nExplain SAP HANA storage replication\\nStorage Replication\\nSAP HANA supports disaster tolerance solutions on the basis of replication using the hard\\ndisk I/O subsystem. The disaster tolerance solution is based on replication mechanisms of\\nthe hard disk I/O subsystem. All the data that is written to the persistence (data volume and\\nlog volume) by the primary SAP HANA system is replicated to a second location (secondary).\\nThe SAP HANA instance of the second location is not active (cold standby).\\nThe mirroring is offered at the storage system level. It is offered together with the appliance\\nas a special offering by our partners. The hardware partner defines how this concept is finally\\nrealized with their operation possibilities.\\nGenerally, write requests are replicated to the hard disk I/O subsystem synchronously. When\\nthere are long distances between locations, the latency times for writing the redo log may\\nincrease. This means that the synchronous replication can be used up to certain distances\\nonly. The maximum distance depends on the performance requirements of the SAP HANA\\nsystem, the respective solution of the hardware partner, and the network configuration in the\\ncustomer environment.\\nSome hardware partners support an asynchronous transfer of the write requests, while the\\nconsistency of the data and transactions within the SAP HANA database is ensured. During a\\ntakeover in this case, the changes that were made last may be lost. In some application\\nscenarios, this loss can be accepted, but in other cases, it cannot.\\nFor example, in an SAP HANA data mart solution, data is replicated from a source system to\\nthe SAP HANA database using SLT. If the SAP HANA database loses the data that was\\ninserted last due to a failover, SLT does not transfer the missing data again. As a result, the\\ndata has to be reloaded to the tables of the SAP HANA database. In this environment, only a\\nsynchronous replication between the primary SAP HANA system and the secondary SAP\\nHANA system is useful.\\nSolutions with asynchronous replication can be used for longer distances between the\\nlocations because the latency times are not significantly affected when writing the redo log.\\nYou can expect an impact on performance for data changing operations as soon as the\\nsynchronous mirroring is activated. The impact depends heavily on various external factors\\nlike distance, connection between data centers, and so on. The synchronous writing of the log\\nwith the concluding COMMITs is crucial.\\nIn an emergency situation, the primary data center is no longer available and you must initiate\\na process for the takeover. So far, many customers have requested a manual process here,\\nbut an automated process can also be implemented. This take-over process then ends the\\nmirroring officially, mounts the disks to the already installed SAP HANA software and\\n© Copyright. All rights reserved.\\n104'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 110}, page_content='instances, and starts the secondary database side of the cluster. If the host names and\\ninstance names on both sides of the cluster are identical, no further steps with HDBRENAME\\nare necessary.\\nFigure 63: Storage Replication\\nUsing Secondary Servers for Non-Production Systems\\nWith SAP HANA storage replication, you can use the servers on the secondary system for\\nnon-production SAP HANA systems.\\nDepending on the hardware solution, you can use the servers of the secondary system for\\nother SAP HANA systems (such as test systems) until the takeover. During a takeover, other\\nrunning systems are switched off, the replication between the locations is interrupted, the\\nmount points of the replicate are made available for the secondary servers, and the SAP\\nHANA system is started. When using servers of the secondary system for other SAP HANA\\nsystems, these do not use the hard disk storage system that contains the replicate of the\\nprimary system.\\nYou can run a development or QA instance of the three-tier installation on this secondary\\ncluster hardware, simply to use it until the takeover is executed. The take-over then stops\\nthese development or QA instances and mounts the production disks to the hosts. It requires\\nan additional set of disks for the development and QA instance.\\nThe same applies to asynchronous mirroring solutions for distant data centers (> 100 km).\\nSome hardware partners have concepts available to offer this asynchronous storage\\nreplication. For more information, see SAP Note: 1755396.\\nLesson: Explaining SAP HANA Storage Replication\\n© Copyright. All rights reserved.\\n105'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 111}, page_content='Figure 64: Storage Replication with QA and Development System on a Second Site\\nSupported Storage Solutions\\nDirect support by hardware vendor or partners are as follows:\\nExisting storage replication solution certifications for all SAP HANA appliances continue\\ntheir validity (solutions reported in SAP Note: 1755396).\\nAll newer solutions are supported directly by corresponding vendors (hardware or storage\\npartners).\\nNo further certification of these storage replication solutions from SAP is required for use\\nwith SAP HANA.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n106'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 112}, page_content='Figure 65: Supported Storage Solutions\\nLESSON SUMMARY\\nYou should now be able to:\\nExplain SAP HANA storage replication\\nLesson: Explaining SAP HANA Storage Replication\\n© Copyright. All rights reserved.\\n107'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 113}, page_content='Unit 3\\nLesson 2\\nExplaining SAP HANA System Replication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nExplain SAP HANA system replication\\nSystem Replication\\nUsually system replication is set up so that a secondary standby system is configured as an\\nexact copy of the active primary system, with the same number of active hosts in each\\nsystem. The number of standby hosts do not need to be identical.\\nWith multitier system replication, you have one primary system and can have multiple\\nsecondary systems. Each service instance of the primary SAP HANA system communicates\\nwith a counterpart in the secondary system.\\nFigure 66: System Replication\\nThe secondary system can be located near the primary system to serve as a rapid failover\\nsolution for planned downtime, or to handle storage corruption or other local faults.\\nAlternatively, it can be installed in a remote site to be used in a disaster recovery scenario.\\nBoth approaches can be linked together with multitier system replication. Like storage\\nreplication, this disaster recovery option requires a reliable connection channel between the\\nprimary and secondary sites. The instances in the secondary system operate in recovery\\n© Copyright. All rights reserved.\\n108'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 114}, page_content='mode. In this mode, all secondary system services constantly communicate with their\\nprimary counterparts.\\nA cluster across data centers with database controlled transfer is realized by system\\nreplication.\\nSystem replication has the following advantages:\\nMemory is continuously loaded on a secondary site in preparation for the possible\\ntakeover and occupies resources.\\nSwitch-over is faster than with storage replication or mirroring (2-5 minutes).\\nThere is a very short performance ramp (only minutes, not hours, without preparation).\\nSystem replication has the following disadvantages:\\nThe hardware (memory and CPU) is actively used on the secondary site for the standby or\\nshadow processes.\\nReplication Modes\\nFigure 67: Replication Modes\\nWhen the secondary system is started in recovery mode, each service component establishes\\na connection with its counterpart, and requests a snapshot of the data in the primary system.\\nFrom then on, all logged changes in the primary system are replicated. Whenever logs are\\npersisted in the primary system, they are also sent to the secondary system. A transaction in\\nthe primary system is not committed until the logs are replicated. What this means can be\\nconfigured by choosing one of the log replication modes:\\nAsynchronous: The primary system sends redo log buffers to the secondary system\\nasynchronously. The primary system commits a transaction when it has been written to\\nthe log file of the primary system and sent to the secondary system through the network. It\\ndoes not wait for confirmation from the secondary system.\\nThis option provides better performance because it is not necessary to wait for log I/O on\\nthe secondary system. Database consistency across all services on the secondary system\\nLesson: Explaining SAP HANA System Replication\\n© Copyright. All rights reserved.\\n109'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 115}, page_content='is guaranteed. However, it is more vulnerable to data loss. Data changes may be lost on\\ntakeover.\\nSynchronous in-memory (default): The primary system commits the transaction after it\\nreceives a reply that the log was received by the secondary system, but before it has been\\npersisted. The transaction delay in the primary system is shorter, because it only includes\\nthe data transmission time.\\nSynchronous: The primary system does not commit a transaction until it receives\\nconfirmation that the log has been persisted in the secondary system. This mode\\nguarantees immediate consistency between both systems. However, the transaction is\\ndelayed by the time it takes to transmit the data to and persist it in the secondary system.\\nSynchronous with full sync: The log write is successful when the log buffer has been\\nwritten to the log file of the primary and the secondary instance. In addition, when the\\nsecondary system is disconnected (for example, because of network failure), the primary\\nsystems suspend transaction processing until the connection to the secondary system is\\nre-established. No data loss occurs in this scenario.\\nIf the connection to the secondary system is lost, or the secondary system crashes, the\\nprimary system resumes replication after a brief, configurable, timeout. The secondary\\nsystem persists, but does not immediately replay the received log. To avoid a growing list of\\nlogs, incremental data snapshots are transmitted asynchronously from time to time from the\\nprimary system to the secondary system. If the secondary system has to take over, only the\\npart of the log needs to be replayed that represents changes that were made after the most\\nrecent data snapshot. In addition to snapshots, the primary system also transfers status\\ninformation regarding which table columns are currently loaded into memory. The secondary\\nsystem correspondingly preloads these columns. In the event of a failure that justifies full\\nsystem takeover, an administrator instructs the secondary system to switch from recovery\\nmode to full operation. The secondary system, which already preloaded the same column\\ndata as the primary system, becomes the primary system by replaying the last transaction\\nlogs, and then starts to accept queries.\\nNote the following for synchronous and asynchronous setups:\\nIn a synchronous state, no committed transaction is lost. The open transaction is restarted\\nand clients reconnect to SAP HANA for this. Synchronous setups are required for\\ndistances in the range 50-100 km.\\nIn case of an asynchronous setup, there is some loss. This depends on the time period\\nwhere the secondary site was not reachable or the line was too weak to cope with the data\\ntransfer quickly enough. These setups are used for longer distances, where the distance\\nbetween data centers is 100 km or more. However, they also occur if the impact of the\\nstandby process is not allowed to feedback into daily operation (change performance).\\nMinimal Setup for System Replication\\nThe minimal setup for system replication in one data center for fast takeovers is shown in the\\nfigure, Minimal Setup for System Replication.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n110'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 116}, page_content='Figure 68: Minimal Setup for System Replication\\nOperation Modes for System Replication\\nThere are three different operation modes for the configuration of system replication.\\nFigure 69: Operation Modes\\nNote:\\nA comparison between delta_datashipping\\n and logreplay\\n with regard to\\nnetwork traffic shows significantly reduced network traffic. Delta data shipping\\ndisplays a peak every 10 minutes when delta data shipping is triggered, whereas\\nlogreplay shows continuously shipped log buffers.\\nLesson: Explaining SAP HANA System Replication\\n© Copyright. All rights reserved.\\n111'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 117}, page_content='System Replication with Operation Mode Delta Data Shipping\\nFigure 70: System Replication with Operation Mode Delta Data Shipping\\nThe events for the start of a transport are as follows:\\n1. The primary system creates an internal data package similar to a full data backup and\\ntransfers this initially to the secondary site. The transport happens asynchronously.\\n2. Log information is transferred in parallel to the initial data transfer. The log is transported\\nasynchronously until the commit of the finished transaction occurs. With the commit, all\\nother log information that is not yet transferred or written, as well as the final commit,\\nmust also be written synchronously. This must occur before the primary productively-\\nused database can continue transactional work.\\n3. All load and unload operations of the main indexes and table columns are monitored and\\noffered with the incremental data transfer to the secondary system. These main indexes\\nand table columns are then loaded or unloaded equivalently to memory in preparation for\\nthe takeover.\\nThe events during incremental transport are as follows:\\n1. With the help of the shadow memory concept operation of SAP HANA, small incremental\\nbackups are transferred to the delta data package every 10 minutes at the secondary site.\\nThe default parameter setting is 600 seconds.\\n2. With this delta data information, information from the loaded main indexes into SAP\\nHANA on the primary site are also transferred to the secondary site. This is to prepare the\\nmain memory with these main indexes on the secondary site too.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n112'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 118}, page_content='System Replication with Operation Mode Log Replay\\nSince the first version of system replication, the delta_datashipping operation mode has been\\nthe default replication method. With the logreplay operation mode, delta data shippings are\\nno longer necessary. The takeover time has been reduced and more components are already\\ninitialized at replication time.\\nFigure 71: System Replication with Operation Mode Log Replay\\nIn the logreplay operation mode, the system replication uses an initial data shipping to\\ninitialize the secondary site. After that, only log shipping is complete and log buffers received\\nby the secondary are replayed there. Savepoints are executed individually for each service\\nand column table merges are executed on the secondary site.\\nIn the logreplay mode of operation, log segments can be marked as retained so that they can\\nsync a secondary system after a disconnect.\\nWith continuous log replay, delta data shipping cannot be used to sync a secondary site. This\\nis because although the primary and secondary persistence are logically compatible, they are\\nno longer physically compatible. This means that the data contained in the persistence is the\\nsame, but the layout of the data on pages can be different on the secondary site. Therefore, a\\nsecondary site can sync only using delta log shipping. This is relevant for the following\\nsituations:\\nThe secondary site has been disconnected for some time (for example, because of a\\nnetwork problem or temporary shutdown of the secondary site).\\nA former primary site has been registered for failback.\\nThe secondary site only uses the log in the online log area of the primary SAP HANA system\\nfor syncing. To sync the secondary site, the log must be retained for a longer time period than\\npreviously. If syncing using delta log shipping does not work, for example because the log has\\nbeen reused, a full data shipping is necessary. To avoid this, the concept of log retention has\\nbeen introduced.\\nLesson: Explaining SAP HANA System Replication\\n© Copyright. All rights reserved.\\n113'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 119}, page_content='System Replication with QA and Development System on the Secondary Site\\nIt is possible to make use of the secondary site for running QA and development systems\\nwhile the primary system is in production.\\nPrerequisites for System Replication with QA and Development System on the Secondary\\nSite\\nThe following prerequisites must be taken into account:\\nAdditional independent disk volume is needed for Development/QA systems. Because the\\nsecondary site requires the same I/O capacity as the primary site, the additional systems\\nmust not have a negative impact on the secondary’s I/O. Therefore, it is recommended to\\nhave a separate storage infrastructure for each system.\\nThe SIDs and instance numbers have to be different for Development/QA. The \\n<instance\\nnumber>+1  of the productive system must not be used, but must be free on both sites,\\nbecause this port range is used for system replication communication.\\nPreload of tables must be switched off on the secondary site, using:\\nglobal.ini/[system_replication]-> preload_column_tables=false\\nThe takeover process takes longer because no data is preloaded in memory at the\\nsecondary site (could still meet SLAs for disaster recovery).\\nDevelopment/QA systems need to be shut down in the case of a takeover.\\nThe global allocation limit on the secondary must be set in a way that the available memory\\ncovers the memory needed by the secondary system as well as the Development/QA\\nsystems, using:\\nglobal.ini/[memorymanager]-> global_allocation_limit\\nThe configured operation mode influences the memory size required on the secondary site as\\nfollows:\\nOperation Mode\\nMemory Needed on Secondary Site\\ndelta_datashipping\\nrow store size + 20 GB (minimum 64 GB)\\nlogreplay\\nrow store size + size of column tables loaded\\nin memory + 50 GB\\nIf the row store size grows during operation of the primary, it might become necessary to\\nincrease the global_allocation_limit on the secondary site. It is possible to change the\\nglobal.ini on the secondary site accordingly and then activate the change with \\n\"hdbnsutil –\\nreconfig\"\\n (because SQL is not possible in this state).\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n114'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 120}, page_content='Figure 72: System Replication with QA and Development Systems on a Secondary Site\\nThe advantages of system replication with a Development/QA system on a secondary site\\ninclude the following:\\nDevelopment/QA operated on the secondary site (mixed cost calculation).\\nSynchronous and asynchronous solution available.\\nImpact of synchronous solution on the primary site is at about 10% (in contrast to about\\n25% with storage replication).\\nThe transfer process from primary to secondary is optimized and a lesser transfer amount\\nis necessary compared to storage replication.\\nDuring the takeover to the secondary site, only a roll forward is necessary because the\\nlatest data synchronization point is necessary.\\nThe disadvantages of system replication with a Development/QA system on a secondary site\\ninclude the following:\\nTable and column data cannot be loaded continuously into memory on the secondary site.\\nHardware (memory and CPU) is actively used for Development/QA and partly for the\\nstandby or shadow processes.\\nTakeover is similar to storage mirroring (20 to 30 minutes at best).\\nPerformance ramp is similar to storage mirroring (1 to 3 hours).\\nQA and Development need their own disk infrastructure carefully separated so as not to\\nhave influencing effects on each other.\\nLesson: Explaining SAP HANA System Replication\\n© Copyright. All rights reserved.\\n115'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 121}, page_content='Figure 73: System Replication – Additional Information\\nSetup for the Exercises\\nIn the following exercises, you set up the SAP HANA system replication. As a prerequisite, all\\nparticipants have to install an SAP HANA system. In the next exercises, two participants work\\ntogether as a team to enable system replication between their systems.\\nParticipant 1 and 2 form a team named system replication group AB. Participant 3 and 4 form\\na team named system replication group BC.\\nThere are two exercises to enable system replication. In the exercise “Set Up SAP HANA\\nSystem Replication”, the main part is done by participant 1 and 3. In the other exercise “Set\\nup Active/Active SAP HANA System Replication”, the main part is done by participant 2 and\\n4.\\nFigure 74: Setup System Replication\\nLESSON SUMMARY\\nYou should now be able to:\\nExplain SAP HANA system replication\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n116'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 122}, page_content='Unit 3\\nLesson 3\\nSetting up SAP HANA System Replication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nSet up SAP HANA system replication\\nOverview of Configuration Steps\\nConfiguration Steps to Set up SAP HANA System Replication\\n1. Start the primary system.\\n2. Create an initial data backup or a storage snapshot on the primary system.\\n3. Enable system replication on the primary system.\\n4. Prepare the secondary system for authentication by copying the system PKI SSFS .key\\nand the .dat file from the primary system to the secondary system.\\n5. Register the secondary system and establish a connection between the secondary and\\nprimary systems.\\nThe configuration tasks on the primary and secondary systems to set up system replication\\nare shown in the figure Setup of System Replication. With this configuration, you can recover\\nfrom a data center outage by switching to a secondary site. The primary system stays online\\nduring this procedure.\\n© Copyright. All rights reserved.\\n117'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 123}, page_content='Figure 75: Setup of System Replication\\nThe following steps are performed during the setup of system replication:\\n1. The primary system is informed to enable system replication.\\n2. The secondary database is stopped. Content is wiped out during the initial load, with a full\\ndata backup later during the initial start of replication.\\n3. The secondary system is advised to connect to the primary system, and communicates\\nabout the attempt to start the system replication standby process.\\nThis process is secured with certificates and so on.\\nOnly one command is needed: HDBNSUTIL.\\nBoth sides must have the same number of active and standby hosts with the same\\nsizing (memory and CPU).\\nSAP HANA itself handles the relationships of, for example, scale-out setups on both\\nsides (primary to secondary) and how communication is established with each\\ncounterpart.\\nCommunication takes place internally between sites on TREXnet.\\nNote:\\nIf the primary connection between data centers is too weak for an initial data load\\n(usually TBs), then use snapshot data backups for setting up SAP HANA system\\nreplication initialization.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n118'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 124}, page_content='Additional Configuration Steps to Enable SAP HANA System Replication\\nStarting with SAP HANA 2.0, additional configuration steps are required to set up SAP HANA\\nsystem replication, because replication connections now use certificate-based\\nauthentication.\\nSystem replication with SAP HANA 2.0 requires authentication for the data and log shipping\\nchannels. The authentication is done using the certificates in the system PKI SSFS store. An\\nadditional manual setup step is required to exchange certificates in the system PKI SSFS\\nstore between primary and secondary sites. For more information, see SAP Note: 2369981.\\nAdditional Configuration Steps to Enable SAP HANA System Replication\\nCopy the system PKI SSFS KEY and DAT files from the primary site to the secondary site.\\nThe files can be found at the following locations:\\n-\\n/usr/sap/<SID>/SYS/global/security/rsecssfs/data/SSFS_<SID>.DAT\\n-\\n/usr/sap/<SID>/SYS/global/security/rsecssfs/key/SSFS_<SID>.KEY\\nFor more information, see SAP Note 2369981 - Required configuration steps for\\nauthentication with HANA System Replication.\\nNote:\\nIf you installed XS advanced, you must also copy the XSA SSFS .key and the .dat\\nfile from the primary system to the secondary system in the following directories:\\n/usr/sap/<SID>/SYS/global/xsa/security/ssfs/data/\\nSSFS_<SID>.DAT\\n/usr/sap/<SID>/SYS/global/xsa/security/ssfs/key/\\nSSFS_<SID>.KEY\\nFor more information, see SAP Note 2300936 - Host Auto-Failover & System\\nReplication Setup with SAP HANA extended application services, advanced\\nmodel.\\nThe copied files become active during system restart. Therefore, it is recommended to copy\\nthe files when the secondary SAP HANA system is offline, for example, before registration.\\nEnablement of SAP HANA System Replication\\nSystem replication can be set up or managed on the command line with hdbnsutil, using the\\nSAP HANA cockpit, SAP HANA studio, or with SAP Landscape Management.\\nThe following administration activities are possible with hdbnsutil, using the SAP HANA\\ncockpit, or SAP HANA studio:\\nPerforming the initial setup, that is, enabling system replication and establishing the\\nconnection between two identical systems.\\nMonitoring the status of system replication to ensure that both systems are in sync.\\nTriggering takeover by the secondary system in the event of a disaster and failback once\\nthe original system is available again.\\nDisabling system replication.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n119'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 125}, page_content='Enable SAP HANA System Replication Using SAP HANA Cockpit\\nThere are two ways to set up SAP HANA system replication in the SAP HANA cockpit:\\nEnable the primary system and then register the secondary system from the primary\\nsystem in one configuration step.\\nEnable system replication on the primary system and then register the secondary system\\nin a second step.\\nThe steps to configure the primary and the secondary system using SAP HANA cockpit are\\noutlined in the figure, Enable System Replication.\\nFigure 76: Enable System Replication\\nYou have enabled system replication and registered the secondary system with the primary\\nsystem. The secondary system operates in recovery mode. All secondary system services\\nconstantly communicate with their primary counterparts, replicate and persist data and logs,\\nand load data to memory. However, the secondary system does not accept SQL connections.\\nTo set up SAP HANA system replication between two identical SAP HANA systems, you must\\nfirst enable system replication on the primary system and then register the secondary\\nsystem.\\nEnable SAP HANA System Replication with hdbnsutil\\nIt is also possible to configure SAP HANA system replication with the command line tool\\nhdbnsutil as <sid>adm at the OS level. The command line tool can be a part of a script, which\\nexecutes further steps beyond system replication.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n120'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 126}, page_content='Enable SAP HANA System Replication with hdbnsutil\\n1. Create a data backup of the primary system.\\n2. Enable the primary system and give the primary system a logical name:\\nhdbnsutil -sr_enable --name=PRIMARY\\n3. Stop the secondary system:\\nsapcontrol –nr <instance_number> -function StopSystem HDB\\n4. Register the secondary system (choose replication mode and operation mode):\\nhdbnsutil -sr_register --remoteHost=<primary hostname> \\n--remoteInstance=<instance number> \\n--replicationMode=<sync|syncmem|async> \\n--operationMode=<delta_datashipping|logreplay> \\n--name=SECONDARY\\n5. Start the secondary system to start replication:\\nsapcontrol –nr <instance_number> -function StartSystem HDB\\nOnce the secondary system is started, the replication process starts automatically.\\nEnable the Full Sync Option for SAP HANA System Replication\\nWhen activated, the full sync option for SAP HANA system replication ensures that a log\\nbuffer is shipped to the secondary system before a commit takes place on the local primary\\nsystem.\\nFull Sync Option for SAP HANA System Replication\\nThe full sync option can be enabled for SYNC replication (that is, not for SYNCMEM). With the\\nfull sync option activated, transaction processing occurs on the primary blocks. If the\\nsecondary system is not currently connected, the newly created log buffers cannot be\\nshipped to the secondary site. This behavior ensures that no transaction can be locally\\ncommitted without shipping the log buffers to the secondary site. The full sync option can be\\nswitched on and off using the command: hdbnsutil -sr_fullsync --enable|--\\ndisable\\nThis command changes the setting of the enable_full_sync parameter in the\\nsystem_replication section of the global.ini\\n file accordingly. However, in a running system,\\nfull sync does not become active immediately. This is done to prevent the system from\\nblocking transactions immediately when setting the parameter to true. Instead, full sync has\\nto first be enabled by the administrator. In a second step, it is internally activated when the\\nsecondary is connected and becomes ACTIVE.\\nIn the M_SERVICE_REPLICATION system view, the setting of the full sync option can be\\nviewed in using SQL.\\nThe full sync option can have the following values:\\nDISABLED: Full sync is not configured at all. The parameter enable_full_sync = false in the\\nsystem_replication section of the global.ini\\n file.\\nENABLED: Full sync is configured, but it is not yet active, so transactions do not block in\\nthis state. To become active, the secondary has to connect and REPLICATION_STATUS\\nmust be ACTIVE.\\nACTIVE: Full sync mode is configured and active. If the network connection to a connected\\nsecondary is closed, transactions on the primary side block in this state.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n121'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 127}, page_content='If full sync is enabled when an active secondary is currently connected, FULL_SYNC is\\nimmediately set to ACTIVE.\\nCaution:\\nIf the secondary is stopped, disable FULL_SYNC. Otherwise, the primary blocks\\nand it is not possible to stop it.\\nNote:\\nResolving a blocking situation of the primary caused by the enabled full sync\\noption must be done with the hdbnsutil command, because a configuration\\nchanging command could also block in this state. This is also necessary if you\\nwant to shut down the currently blocking primary. Otherwise, it is not possible to\\nstop it.\\nCompression Methods for Log and Data Shipping\\nSAP HANA system replication supports a number of compression methods for log and data\\nshipping.\\nThe following types of compression for log and data shipping are supported:\\nLog\\n-\\nLog buffer tail compression (by default)\\n-\\nLog buffer content compression\\nData\\n-\\nData page compression\\nLog buffer tail compression is turned on by default. All log buffers are aligned to 4 KB\\nboundaries by a filler entry. With log buffer tail compression, the filler entry is cut off from the\\nbuffer before sending it over the network and added again when the buffer has reached the\\nsecondary site. So only the net buffer size is transferred to the secondary site.\\nThe size of the filler entry is less than 4 KB. This is the maximum size reduction per sent log\\nbuffer. If the log buffers size is quite large, the compression ratio is quite limited.\\nLog buffer and page content compression can be activated by parameter settings.\\nLog buffers and data pages shipped to the secondary site can be compressed using a lossless\\ncompression algorithm (LZ4). By default, content compression is turned off. You can turn it\\non by setting the following configuration parameters on the secondary site in the\\nsystem_replication\\n section of the global.ini\\n file.\\nConfiguration Parameters to Activate Compression\\nEnable compression of a log when it is sent to the secondary site:\\nenable_log_compression = true\\nEnable compression of data when it is sent to the secondary site:\\nenable_data_compression = true\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n122'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 128}, page_content='Note:\\nAfter changing these parameters, the secondary site needs to be reconnected to\\nthe primary site.\\nLog and data compression is especially useful when system replication is used over long\\ndistances, for example, using the ASYNC replication mode.\\nThe open source compression algorithm LZ4 has been selected because of its speed and\\ncompression ratios, and the relatively low time overhead introduced for compression/\\ndecompression. Log buffer content compression also works in combination with log buffer tail\\ncompression. Therefore, only the content part of the log buffer is compressed, without\\nconsidering the filler entry.\\nThe activation of the compression reduces the required network bandwidth, but at the same\\ntime there is some CPU overhead for compressing and decompressing the information. Using\\ncompression is particularly useful in the case of long distances between primary and\\nsecondary sites or in the case of bandwidth limitations.\\nChecking and Monitoring of SAP HANA System Replication\\nAfter setting up the secondary system for system replication, you can monitor the status of\\nthe replication between the primary and the secondary system using the following tools:\\nSAP HANA Cockpit\\nSAP HANA Studio\\nhdbnsutil\\nThe current status of system replication can be checked with all of these tools.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n123'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 129}, page_content='Figure 77: System Replication Status\\nMonitoring System Replication with SAP HANA Cockpit\\nTo monitor SAP HANA system replication, you can use the System Replication  tile in the SAP\\nHANA Cockpit.\\nIf system replication is configured, the System Replication  tile provides information about the\\ntype of landscape (2-tier or 3-tier), the replication mode between the primary and the tier-2\\nsecondary, the operation mode, and the overall replication status.\\nThe System Replication  tile displays the following states at a glance:\\nNot configured (meaning system replication is not configured)\\nAll services are active and in sync\\nAll services are active, but not yet in sync\\nErrors in replication\\nTo check the status of replication in detail, choose the \\nSystem Replication  tile. The System\\nReplication overview screen displays a graphical representation of the system replication\\nlandscape, configuration, and status. At the top, the “chain” of systems with their replication\\nmodes is shown, containing further information about the sites and the network connections\\nbetween them.\\nThe System Replication  screen provides the following information:\\nThe name and role of the system, as well as the selected operation mode.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n124'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 130}, page_content='For the operation modes logreplay\\n and logreplay_readaccess\\n, a retention time\\nestimation is also displayed. This is an estimation of the time left before the primary\\nsystem starts to overwrite the RetainedFree marked log segments, and a full data shipping\\nbecomes necessary to get the primary and secondary systems back in sync after a\\ndisconnect situation. The estimated log full time is an estimation of the time left before the\\nprimary system runs into a log full. The value shown in the header shows the situation into\\nwhich the system could run first: log retention or log full.\\nIf the SQL ports of the secondary system are open for read access.\\nThe replication mode used between the systems.\\nThe current average redo log shipping time and the average size of shipped redo log\\nbuffers.\\nThis describes how long it took on average to send redo log buffers to the secondary site,\\nbased on measurements over the last 24 hours.\\nFigure 78: Check and Monitor SAP HANA System Replication\\nIn addition, detailed information on system replication is provided in the tabs shown in the\\nfollowing figure.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n125'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 131}, page_content='Figure 79: System Replication Overview Tabs\\nSelecting one row in the Replicated Services tab shows the details for the corresponding\\nservice grouped thematically, as in the following example for the index server. Because this\\ninformation is context-sensitive, you only see the information required for this system.\\nTherefore, because this example system is running in the logreplay operation mode, no\\ninformation on delta data shipping is shown here. However, the context-sensitive information\\nabout the log replay delay is displayed. The delta between Last Log Position and Replayed Log\\nPosition  indicates how far the log replay is behind on the secondary.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n126'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 132}, page_content='Figure 80: Details for the Status of a Specific Service\\nSAP HANA Cockpit for Secondary Management\\nThe SAP HANA Cockpit distinguishes between a primary and a secondary system. On the\\nSAP HANA Cockpit of the secondary system, the System Replication  tile provides an initial\\noverview of this site’s state. From the System Replication Overview, you can initiate a\\ntakeover.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n127'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 133}, page_content='Figure 81: Management of Secondary Site\\nMonitoring System Replication with Command Line Tools and Scripts\\nCommand Line Tools and Scripts to Monitor System Replication\\nhdbnsutil -sr_state\\nChecks if the primary and the secondary sites have been successfully enabled for system\\nreplication.\\nlandscapeHostConfiguration.py\\nChecks the overall status of the primary system.\\nsystemReplicationStatus.py\\nChecks the overall status of the system replication.\\nNote:\\nThe Python scripts are located in the directory $DIR_INSTANCE/exe/\\npython_support\\n.\\nCommand: hdbnsutil -sr_state\\nPrimary Site:\\nh10adm@wdflbmt7346:/> hdbnsutil -sr_state\\nchecking for active or inactive nameserver ...\\nSystem Replication State\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n128'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 134}, page_content='~~~~~~~~~~~~~~~~~~~~~~~~\\nonline: true\\nmode: primary\\noperation mode: primary\\nsite id: 1\\nsite name: PrimarySite\\nis source system: true\\nis secondary/consumer system: false\\nhas secondaries/consumers attached: true\\nis a takeover active: false\\nHost Mappings:\\n~~~~~~~~~~~~~~\\nwdflbmt7346 -> [SecondarySite] wdflbmt7347\\nwdflbmt7346 -> [PrimarySite] wdflbmt7346\\ndone.\\nSecondary Site:\\nh10adm@wdflbmt7347:/>  hdbnsutil -sr_state\\nchecking for active or inactive nameserver ...\\nSystem Replication State\\n~~~~~~~~~~~~~~~~~~~~~~~~\\nonline: true\\nmode: syncmem\\noperation mode: logreplay\\nsite id: 2\\nsite name: SecondarySite\\nis source system: false\\nis secondary/consumer system: true\\nhas secondaries/consumers attached: false\\nis a takeover active: false\\nactive primary site: 1\\nHost Mappings:\\n~~~~~~~~~~~~~~\\nwdflbmt7347 -> [SecondarySite] wdflbmt7347\\nwdflbmt7347 -> [PrimarySite] wdflbmt7346\\nprimary masters:wdflbmt7346\\ndone.\\nScript: landscapeHostConfiguration.py\\nYou can also gather information about the overall status of the sites and the system\\nreplication using Python scripts.\\nThe landcapeHostConfiguration.py\\n script shows the status of the primary system:\\nSAP HANA is OK.\\nSAP HANA will be OK after a host auto-failover, for example.\\nNot enough instances are started and a takeover would be useful.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n129'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 135}, page_content='Note:\\nThe script does not tell you if the secondary system is ready for a takeover.\\nThe script provides an overall status and a return code to match the overall host status.\\nA takeover is only recommended when the return code from the script is 1 (error).\\nExample:\\n<sid>adm># python $DIR_INSTANCE/exe/python_support/\\nlandscapeHostConfiguration.py\\n| Host  | Host   | Host   |    ...    | NameServer | NameServer  | ...\\n|       | Active | Status |           | Config Role| Actual Role |\\n| ----- | ------ | ------ | --------- | ---------- | ----------- | \\n------\\n| host1 | yes    | ok     |    ...    | master 1   | master      | ...\\n| host2 | yes    | ok     |    ...    | master 2   | slave       | ...\\noverall host status: ok\\nThe following host states are possible:\\nOK: System is OK.\\nWARNING: A host auto-failover to a standby host is taking place.\\nINFORMATION: The landscape is completely functional, but the current (actual) role of the\\nhost differs from the configured role.\\nERROR: There are not enough active hosts.\\nScript: systemReplicationStatus.py\\nThe systemReplicationStatus.py\\n script shows the status of system replication.\\nUsing systemReplicationStatus.py\\n has the advantage of showing whether the\\nsecondary systems are in sync or not. This provides more confidence if a takeover is justified\\nbecause if system replication was never in sync or is outdated, unexpected loss of data might\\noccur.\\nExample:\\nh10adm@wdflbmt7346:/> python $DIR_INSTANCE/exe/python_support/\\nsystemReplicationStatus.py\\n| Database | Host        | Service Name | Site Name   | Secondary   | \\nSecondary     | Replication |\\n|          |             |              |             | Host        | \\nSite Name     | Status      |\\n| -------- | ----------- | ------------ | ----------- | ----------- | \\n------------- | ----------- |\\n| SYSTEMDB | wdflbmt7346 | nameserver   | PrimarySite | wdflbmt7347 | \\nSecondarySite | ACTIVE      |\\n| H10      | wdflbmt7346 | xsengine     | PrimarySite | wdflbmt7347 | \\nSecondarySite | ACTIVE      |\\n| H10      | wdflbmt7346 | indexserver  | PrimarySite | wdflbmt7347 | \\nSecondarySite | ACTIVE      |\\nstatus system replication site \"2\": ACTIVE\\noverall system replication status: ACTIVE\\nLocal System Replication State\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nmode: PRIMARY\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n130'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 136}, page_content='site id: 1\\nsite name: PrimarySite\\nThe additional parameter systemReplicationStatus.py --localhost\\n restricts the\\nexecution of the python script to the host on which is it executed.\\nThe script provides the following return codes:\\n10: No System Replication\\n11: Error\\n12: Unknown\\n13: Initializing\\n14: Syncing\\n15: Active\\nMonitoring System Replication Using SQL Statements\\nYou can also get system replication-specific information directly from system views.\\nSystem Views Providing Information About System Replication\\nM_SERVICE_REPLICATION\\nCollects the history of data and log replication every hour.\\nM_SYSTEM_REPLICATION\\nProvides general system replication-relevant information about the whole system.\\nNote:\\nA set of complex SQL statements is available in SAP Note: 1969700 - SQL\\nStatement Collection for SAP HANA. The section Replication  \\n System\\nReplication includes some system replication-relevant statements. The \\nOverview\\nscript provides information about the system replication landscape and the\\nreplication state for each service.\\nMonitoring System Replication Alerts\\nSpecific alerts are issued by the primary system to warn you of potential problems.\\nSystem Replication Alerts\\nSystem Replication Connection Closed (Alert ID 78)\\nSystem Replication Configuration Parameter Mismatch  (Alert ID 79)\\nSystem Replication Logreplay Backlog  (Alert ID 94)\\nSystem Replication Increased Log Shipping Backlog (Alert ID 104)\\nThe Connection Closed and Configuration Parameter Mismatch  alerts are raised when a\\nsystem replication connection is closed, or when there is a system replication configuration\\nparameter mismatch.\\nLesson: Setting up SAP HANA System Replication\\n© Copyright. All rights reserved.\\n131'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 137}, page_content='The Logreplay Backlog  alert is raised when the system replication logreplay backlog is\\nincreased. In this case, logreplay is delayed on the secondary site, causing a longer takeover\\ntime.\\nTo identify the reason for the increased system replication logreplay backlog, check the state\\nof the services on the secondary system. To get more information, monitor the secondary\\nsite. Possible causes for the increased system replication logreplay backlog can be, for\\nexample, a slow or non-functioning log replay, or a non-running service on the secondary\\nsystem.\\nThe Increased Log Shipping Backlog alert is raised when the system replication log shipping\\nbacklog is increased. In this case, the log shipping to the secondary system is delayed or does\\nnot work properly causing data loss on the secondary system in the case where a takeover is\\nexecuted.\\nTo identify the reason for the increased system replication log shipping backlog, check the\\nstatus of the secondary system. Possible causes for the increased system replication log\\nshipping backlog can be a slow network performance, connection problems, or other internal\\nissues (for example, in the sync or syncmem replication modes).\\nMonitoring INI File Parameter Changes\\nDatabase parameters should be the same in the primary and secondary systems and are\\nchecked automatically. The configuration parameter checker reports on any differences\\nbetween primary, secondary, and tier 3 secondary systems. In such a case, the parameter\\nchecker generates an alert.\\nWith parameter replication activated, any changes made on the primary are automatically\\nreplicated to the secondary sites. Without this parameter replication activated, changes\\nshould be manually duplicated on the other system.\\nParameter replication is off by default. It can be enabled and disabled on the primary site by\\nusing:\\n[inifile_checker]/replicate = true | false\\nThe parameter checker is on by default. It can be enabled and disabled on the primary site by\\nusing:\\n[inifile_checker]/enable = true | false\\nSome parameters may have different settings on the primary and the secondary sites on\\npurpose. One example is the global_allocation_limit\\n parameter, where the secondary\\nis used for other systems. By adding these parameters to the exclusion list, you can exclude\\nthem from checking.\\nLESSON SUMMARY\\nYou should now be able to:\\nSet up SAP HANA system replication\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n132'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 138}, page_content='Unit 3\\nLesson 4\\nCreating Tenant Databases in a System\\nReplication Scenario\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nCreate tenant databases in a system replication scenario\\nOverview of SAP HANA System Replication with Tenant Databases\\nThe usual SAP HANA system replication principles apply for tenant database systems.\\nBefore you begin preparing a replication strategy for a SAP HANA system, you should be\\naware of the following important points:\\nSAP HANA systems can only be replicated as the whole system.\\nThis means that the system database and all tenant databases are part of the system\\nreplication. A takeover can only be performed as a whole system. A takeover on the level of\\na single tenant database is not possible.\\nIf a new tenant database is created in a configured SAP HANA system replication, it must\\nbe backed up to participate in the replication.\\nThereafter, the initial data shipping is started automatically for this tenant database. If a\\ntakeover is done while the initial data shipping is running and not finished, this new tenant\\ndatabase is not operational after takeover and must be recovered with backup and\\nrecovery.\\nIf an active tenant database is stopped in a running SAP HANA system replication, it is\\nstopped on the secondary site as well.\\nIf a takeover is done while tenant databases, which were part of the system replication, are\\nstopped, they are in the same state after takeover as they were on the primary site when\\nthey were stopped. The tenant databases must be started to complete the takeover.\\nIt is possible to copy or move tenant databases between SAP HANA systems using system\\nreplication technology.\\nHowever, you can only use this feature if system replication is not enabled for high\\navailability purposes on either the source or target system for the entire duration of the\\ncopy or move process.\\n© Copyright. All rights reserved.\\n133'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 139}, page_content='Figure 82: System Replication with Tenant Databases\\nLESSON SUMMARY\\nYou should now be able to:\\nCreate tenant databases in a system replication scenario\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n134'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 140}, page_content='Unit 3\\nLesson 5\\nPerforming a Takeover on the Secondary\\nSystem\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nPerform a takeover on the secondary system\\nPerform Takeover\\nDuring a takeover, you switch your active system from the current primary system to the\\nsecondary system.\\nIf your primary data center is not available, due to a disaster or for planned downtime for\\nexample, and a decision has been made to fail over to the secondary data center, you can\\nperform a takeover on your secondary system.\\nIn addition to the tools that may be used to monitor the overall system status when system\\nreplication is enabled, a script is provided with SAP HANA that helps you decide when a\\ntakeover should be performed.\\nWe recommend that you use third-party, external tools to check if hosts, the network, and the\\ndata center are still available.\\nIn addition, a script called landscapeHostConfiguration.py\\n is provided so that SAP\\nHANA itself can communicate the status of the primary system. It can communicate the\\nfollowing statuses:\\nSAP HANA is OK.\\nSAP HANA will be OK after a host auto-failover, for example.\\nNot enough instances are started and a takeover would be useful.\\nA takeover is only recommended when the return code from the script is 1 (error).\\nNote:\\nThe script does not tell you if the secondary system is ready for a takeover.\\nIf a takeover occurs, the secondary site finds the latest savepoint in the data disk area. This is\\nthe starting point for a usual database restart, but many large data packages (main indexes)\\nare preloaded in-memory, as on the primary data center before takeover. This supports the\\nrestart considerably. Based on this initial savepoint on the secondary data center, the log\\nreplay can start and roll the database forward to the latest point in time.\\n© Copyright. All rights reserved.\\n135'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 141}, page_content='Figure 83: System Replication Takeover\\nThe following decision guideline can help you decide if a takeover is advisable.\\nTakeover Decision Guideline\\nThere are three main questions involved in deciding whether or not a takeover will improve\\nthe situation.\\n1. Can a takeover help at all?\\nNo: Do not perform a takeover.\\nYes: Proceed to question 2.\\n2. Can a takeover reduce the downtime duration?\\nNo: Do not perform a takeover.\\nYes: Proceed to question 3.\\n3. Can it be guaranteed that no data loss will result from the takeover?\\nNo: Evaluate the risk of data loss in the case of a takeover against that of data loss in case\\nof no takeover, and against the impact of a longer downtime to bring back the primary site\\ninstead.\\nYes: Perform a takeover.\\nNote:\\nFor more information on how to answer these questions, see SAP Note: 2063657.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n136'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 142}, page_content='You can use the getTakeoverRecommendation.py\\n script to get takeover\\nrecommendations.\\nTakeover Recommendations are Given by the Script\\ngetTakeoverRecommendation.py\\nEvaluates the status returned by the Python scripts:\\n-\\nlandscapeHostConfiguration.py\\n-\\nsystemReplicationStatus.py\\nThese three possible states are returned:\\n-\\nTakeover required\\n-\\nNot decidable\\n-\\nPossible\\nWhen the getTakeoverRecommendation\\n script is called, it shows the takeover\\nrecommendation based on the current system state. However, when the primary system\\nfaces any error situation, the system replication status can no longer be determined.\\nTherefore, the previous state should be saved and compared against the current state.\\nExample:\\nPrimary Site:\\nThis is a sample implementation of a python script that uses \\ngetTakeoverRecommendation\\nto act as a minimalist cluster manager:\\nimport time\\nimport subprocess\\nfrom getTakeoverRecommendation import TakeoverDecision\\ndef main():\\n    wasInSync = False\\n    while True:\\n        recommendation = \\nsubprocess.call([\"python\",\"getTakeoverRecommendation.py\",\"--\\nsapcontrol=1\"])\\n        if not wasInSync and recommendation is \\nTakeoverDecision.Required:\\n            print \"Primary defect & no sync => NO TAKEOVER\"\\n        if wasInSync and recommendation is TakeoverDecision.Required:\\n            print \"Primary defect & sync => TAKEOVER\"\\n        nowInSync = recommendation is TakeoverDecision.Possible\\n        wasInSync = nowInSync\\nThe output depends on the previous state with the result of the current call of\\ngetTakeoverRecommendation\\n. If no sync state is reached, a takeover is not advised. But\\nonce the systems are in sync, the next error of the primary system will suggest a takeover.\\nAny subsequent negative return value will reset the sync state, as it is no longer ensured that\\nthe replicated data is current.\\nTools for Performing a Takeover\\nThe takeover can be triggered using the following tools:\\nThe SAP HANA Cockpit\\nSAP HANA Studio\\nLesson: Performing a Takeover on the Secondary System\\n© Copyright. All rights reserved.\\n137'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 143}, page_content='hdbnsutil\\nThe following steps are performed:\\n1. Trigger a takeover to the secondary system in the event of a disaster.\\n2. Register the former primary system as a new secondary when it becomes available again.\\nFigure 84: System Replication Takeover\\nCommand Line Tool hdbnsutil\\n1. Perform a takeover on the secondary site:\\nhdbnsutil –sr_takeover\\n2. When the former primary site is available again it can be registered as the new secondary\\nsite:\\nhdbnsutil -sr_register --remoteHost=<new primary hostname>\\n--remoteInstance=<instance number>\\n--replicationMode=<sync/syncmem/async>\\n--operationMode=<delta_datashipping|logreplay>\\n--name=<siteName>\\nNote:\\nExternal cluster management software can be used to perform the client\\nreconnect after takeover. Some of SAP’s hardware partners offer an integration of\\nSAP HANA high availability in their cluster management solutions.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n138'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 144}, page_content='Client Connection Recovery\\nTo perform the takeover only on the SAP HANA system in most cases is not enough.\\nSomehow, the client or application server needs to be able to continuously reach the SAP\\nHANA system, no matter which site is currently the primary.\\nMethods for Client Connection Recovery\\nIP redirection\\nA virtual IP address is assigned to the virtual host name. In the case of a takeover, the\\nvirtual IP unbinds from the network adapter of the primary system and binds to the\\nnetwork adapter of the secondary system.\\nDNS redirection\\nIn this scenario, the IP for the host name in the DNS is changed from the address of the\\nprimary system to the address of the secondary system.\\nBoth methods have their advantages, but the method is mostly decided by IT policies and the\\nexisting configuration. If there are no existing constraints, IP redirection has the clear benefit\\nof being faster to process in a script rather than synchronizing changes of DNS entries over a\\nglobal network.\\nSAP HANA offers the so-called ”HA/DR providers” that are capable of informing external\\nentities about activities inside SAP HANA scale-out (such as host auto-failover) and SAP\\nHANA system replication setups. In a Python script, actions can be defined that should be\\nexecuted before or after certain SAP HANA activities, such as startup, shutdown, failover,\\ntakeover, connection change, and so on. One example of these HA/DR providers, or “hooks”,\\nis moving virtual IP addresses after a takeover in SAP HANA system replication.\\nAdditionally, external cluster management software can be used to perform the client\\nreconnect after takeover.\\nTakeover History\\nMonitoring View Providing Information About Takeover History\\nM_SYSTEM_REPLICATION_TAKEOVER_HISTORY\\nThe M_SYSTEM_REPLICATION_TAKEOVER_HISTORY monitoring view provides information\\nabout take-overs in SAP HANA system replication (HSR) and when HSR was activated or\\nreactivated.\\nDuring take-over, the content of the view is also moved to the system taking over, so that the\\ncomplete take-over history is available.\\nLesson: Performing a Takeover on the Secondary System\\n© Copyright. All rights reserved.\\n139'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 145}, page_content='Figure 85: Takeover History\\nImplementing Takeover Hooks\\nTakeover Hooks\\nTakeover hooks are provided by SAP HANA in the form of a Python script template.\\nPre- and post-takeover actions are implemented in this script, which are then executed by\\nthe name server before or after the takeover.\\nTherefore, the SAP HANA name server provides a Python-based API that is called at\\nimportant points of the host auto-failover and the system replication takeover process.\\nThere are a number of pre-takeover, post-takeover, and general hooks available.\\nThese so called “hooks” can be used for arbitrary operations that need to be executed. One of\\nthe most important uses of the failover hooks is moving around a virtual IP address (in\\nconjunction with STONITH).\\nThere are other purposes like starting tools and applications on certain hosts after failover, or\\neven stopping DEV or QA SAP HANA instances on secondary sites before takeover. Multiple\\nfailover hooks can be installed and used in parallel with a defined execution order.\\nThe failover hooks are included in SAP HANA. SAP HANA comes with its own Python\\ninterpreter, which is used for interpreting the user defined failover hooks. The failover hook\\nAPI also has a version number.\\nYou can adapt Python files delivered with SAP HANA to create your own HA/DR provider. This\\nallows you to integrate, for example, SAP HANA failover mechanisms into your existing\\nscripts.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n140'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 146}, page_content='To create your own HA/DR provider, use the HADRDummy.py script (located in the\\n$DIR_SYSEXE/python_support/hdb_ha_dr\\n directory) as a template for implementing\\nSAP HANA failover mechanisms in your own scripts.\\nAfter implementation of the basic HA/DR provider, you can add the methods listed in the\\nfigure, Hook Methods, to your provider.\\nFigure 86: Hook Methods\\nAs an example, the srServiceStateChanged()\\n HA/DR Provider Hook reports changed\\nservice states. It notices that an SAP HANA service is currently stopping or crashing. This\\nknowledge can be used to reduce the takeover (detection) time, especially in systems with\\nhuge index servers.\\nNote:\\nThe procedure for creating a HA/DR provider, and the available hook methods,\\nare described in detail in the SAP HANA Administration Guide.\\nLesson: Performing a Takeover on the Secondary System\\n© Copyright. All rights reserved.\\n141'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 147}, page_content='Take-over with Handshake\\nFigure 87: Take Over with Handshake\\nThe takeover with handshake ensures that all of the sent redo log is written to disk on the\\nsecondary system.\\nDuring a planned takeover, it is important to ensure that no data gets lost (all primary updates\\nmust be available on the secondary system), and the former primary system is isolated to\\navoid a split-brain situation with multiple active primary systems.\\nThe takeover with handshake is ideal for a safe planned takeover while the primary is still\\nrunning. All new writing transactions on the primary system are suspended and the takeover\\nis only executed when the redo log is available on the secondary system. When performing a\\ntakeover with handshake, it is not required to check the replication status or to stop the old\\nprimary before the takeover.\\nIn a nutshell, a takeover with handshake avoids:\\nData loss, because the log is available on the secondary system before the takeover is\\ntriggered.\\nSplit-brain situations, because the former primary will be suspended.\\nNote:\\nThe takeover with handshake will only be performed if the two previously\\nmentioned conditions are guaranteed. Otherwise, the takeover will be aborted\\nand the primary resumed.\\nYou can trigger a takeover with handshake using hdbnsutil -sr_takeover -–\\nsuspendPrimary\\n on the secondary system.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n142'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 148}, page_content=\"If a primary service cannot be accessed or a service replication is not active or in sync, the\\ntakeover will be aborted and reported as an error. In this case, there is no impact on the\\nsystem and the replication remains as it was. The suspended primary can be unblocked using\\nthe -sr_register\\n hdnsutil command.\\nInvisible Takeover\\nDuring an invisible takeover or a restart, the session's state needs to be recovered and\\nrestored to the new primary system.\\nDuring a standard takeover you switch your active system from the current primary system to\\nthe secondary system. After a standard takeover, the primary system loses all connections to\\nthe client. Moreover, the secondary system is not aware of the previous connections, which\\nexisted between the client and the primary system. This is different in an invisible takeover.\\nYou can perform an invisible takeover to achieve an automatic recovery of your sessions after\\ntakeover to your new primary system. For dedicated client applications, this takeover is\\ninvisible. In contrast to a standard takeover, an invisible takeover ensures that the client\\nreconnects to the primary system and the sessions are restored to the secondary system.\\nAn invisible takeover has two functions:\\nKeep the physical connections between the client and the primary and secondary systems\\nRestore the sessions to the secondary system\\nThis seamless recovery is possible also when restarting the system (for example, after a\\nsystem crash).\\nThe session's state needs to be recovered and restored to the new primary system in an\\ninvisible takeover scenario, or to the new system in a restart scenario. The cross-layer\\nbetween the session and the client library makes the seamless recovery possible. This cross-\\nlayer feature called transparent session recovery recovers the current session's state and the\\nphysical connection.\\nNote:\\nAs a first step, the focus is on read SQL, while write transactions (including\\ndatabase cursors) still need to be restarted after take-over (similar to classical\\ndatabases).\\nLesson: Performing a Takeover on the Secondary System\\n© Copyright. All rights reserved.\\n143\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 149}, page_content='Figure 88: Invisible Takeover\\nNote:\\nThe transparent session recovery is supported by SQLDBC for SAP HANA 2.0.\\nUp to SAP HANA 2.0 SPS 03, the implementation needs Active/Active system\\nreplication.\\nConfiguration\\nThe enable_session_recovery\\n parameter controls the session recovery. The parameter is\\npart of the indexserver.ini configuration file: \\nindexserver.ini/session/\\nenable_session_recovery\\n. The default value is true , recovering all session variables and\\nrestoring the client connections from the primary system to the secondary system. This\\nparameter is configurable online, but the changes can be applied only to the connections\\nestablished after making the changes.\\nLimitations\\nIn SAP HANA 2.0 SPS04, almost all session variables from the current session context can be\\nrecovered, with the exception of the following limitations.\\nSessions that have created or updated a global temporary table with any DDL or DML\\ncommands will not be recovered. However, sessions which have created a local temporary\\ntable will be recovered without the table recovery.\\nOnly read transactions are supported. Ongoing write transactions will be rolled back with\\nan error, and the session can be recovered when an application restarts the failed\\ntransaction with no explicit reconnect trial from the application.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n144'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 150}, page_content='Almost all session variables from the current session context are recovered.\\nWhen a response for a request is not successfully sent from the client to the server, the\\nsession is not recovered. However, sessions are still recovered when an SQL command is\\nnot sent from the client to the server.\\nLESSON SUMMARY\\nYou should now be able to:\\nPerform a takeover on the secondary system\\nLesson: Performing a Takeover on the Secondary System\\n© Copyright. All rights reserved.\\n145'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 151}, page_content='Unit 3\\nLesson 6\\nSetting up Active/Active System Replication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nSet up Active/Active SAP HANA system replication\\nSystem Replication with a Read-Enabled Secondary Site\\nSystem replication with a read-enabled secondary site (Active/Active) enables read access\\non the secondary system.\\nActive/Active (read enabled) is integrated into the system replication solution and is\\nactivated with the logreplay_readaccess operation mode.\\nThe logreplay_readaccess operation mode is similar to the logreplay operation mode with\\nregard to the continuous log shipping, the redo log replay on the secondary system, and the\\nrequired initial full data shipping and takeover.\\nCaution:\\nFor this mode, the primary and secondary systems must have the same SAP\\nHANA version. For this reason, read-only access to the secondary is not possible\\nduring a rolling upgrade until both versions are the same again.\\nActive/Active (read-enabled) is based on the continuous log replay feature. It inherits the\\nfollowing characteristics:\\nFast takeovers\\nReduced need for bandwidth in continuous operation\\nExisting replication modes: SYNC (with or without the full sync option), SYNCMEM,\\nASYNC\\nActive/Active (read-enabled) offers integrated consistent views of data on the secondary site.\\nThese views can be delayed compared to the primary system. However, the secondary\\nsystem identifies the exact delay. During an outage, all functions concentrate on the\\nsecondary system. As such, the sizing of the secondary system is important for the right\\nperformance in disaster scenarios. The following figure visualizes an Active/Active (read-\\nenabled) system replication.\\n© Copyright. All rights reserved.\\n146'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 152}, page_content='Figure 89: System Replication with Read-enabled Secondary Site\\nNote:\\nActive/Active (read-enabled) is only supported if the processors in the primary\\nand secondary systems are both either Intel-based or IBM Power-based with the\\nsame byte ordering. A platform mixture is not supported.\\nAccess Modes for Secondary Site\\nConnecting to an Active/Active (read-enabled) system allows you to take advantage of a\\nsecondary system for better overall performance.\\nThere are two types of connections:\\nExplicit read-only connection to the secondary system\\nFor this connection type, the application opens the connection to the secondary system.\\nThere is no session property sharing.\\nImplicit hint-based statement routing\\nConnections to the primary system can use hint-based routing statement execution to the\\nsecondary system on a per-statement basis.\\nLesson: Setting up Active/Active System Replication\\n© Copyright. All rights reserved.\\n147'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 153}, page_content='Figure 90: System Replication with Read-Enabled Secondary Site Access Modes\\nUsing implicit hint-based statement routing, the SAP HANA client opens an additional\\nconnection to the secondary system according to the host information returned by the\\nprimary system.\\nThis connection type unfolds as follows:\\n1. The SAP HANA client sends the statement-prepare with hint to the primary system.\\n2. The primary system decides where to execute the statement and returns the result to the\\nSAP HANA client.\\n3. The SAP HANA client sends the statement execution call to the secondary system.\\nFurthermore, the session property changes are delivered to the secondary system by the\\nSAP HANA client. If the secondary system cannot execute the statement, it returns an\\nerror, and the SAP HANA client sends the statement to the primary system.\\nMemory Management Aspects and Support for Multiple SAP HANA Databases\\nWhen using Active/Active (read-enabled) system replication, several memory management\\naspects must be considered.\\nThe total statement memory is limited to 50% of the global allocation limit, because 50% of\\nthe storage is reserved for log replay. Log replay should not fail because of storage\\nlimitations.\\nIt is possible to use the read-enabled secondary for other SAP HANA systems, such as\\nDevelopment or QA environments. In this case, the following sizing conditions apply:\\nThe secondary hardware must offer the same CPU and memory capacities as those\\noffered by the primary, plus the resources for the additional system.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n148'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 154}, page_content='After a takeover, the system must be capable of handling both the primary’s writing load\\nand the secondary’s reporting load.\\nLESSON SUMMARY\\nYou should now be able to:\\nSet up Active/Active SAP HANA system replication\\nLesson: Setting up Active/Active System Replication\\n© Copyright. All rights reserved.\\n149'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 155}, page_content=\"Unit 3\\nLesson 7\\nSetting up SAP HANA System Replication with\\nSecondary Time Travel\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nSet up SAP HANA system replication with Secondary Time Travel\\nSystem Replication with Secondary Time Travel\\nSAP HANA system replication allows time travel for logical error mitigation. Therefore, you\\ncan start the secondary system in online mode from a previous point in time.\\nSecondary time travel can be used:\\nTo quickly access data that was deleted in the original system.\\nTo intentionally keep the secondary system's log replay delayed. This can be used to read\\nolder data from the secondary system, while the secondary keeps replicating.\\nTo prepare the secondary system for time travel, snapshots are kept on the secondary\\nsystem for a defined time travel period. These snapshots can be used later to start the system\\nat an earlier point in time. An additional log is retained on the secondary system starting from\\nthe earliest time travel snapshot. After opening the old snapshot, the additional log has to be\\nreplayed to reach the requested point in time.\\n© Copyright. All rights reserved.\\n150\"),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 156}, page_content='Figure 91: Secondary Time Travel\\nNote:\\nYou can only use secondary time travel with the following operation modes:\\nlogreplay\\n or logreplay_readaccess\\n.\\nConfiguration Parameters\\nSeveral parameters are available for configuring secondary time travel.\\nUse the following parameters to configure secondary time travel. The parameters are defined\\nin the system_replication section of the global.ini file. All parameters are set on the secondary\\nsystem.\\nLesson: Setting up SAP HANA System Replication with Secondary Time Travel\\n© Copyright. All rights reserved.\\n151'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 157}, page_content='Figure 92: Secondary Time Travel – Parameter\\nTime travel snapshots are kept until they get older than the defined\\ntimetravel_max_retention_time\\n parameter. If a takeover needs to be done from an\\nearlier point in time, the snapshot that best fits the requested point in time is opened and the\\nremaining changes are applied using logreplay.\\nEnable Secondary Time Travel\\nFigure 93: Enable Secondary Time Travel\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n152'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 158}, page_content='You can edit the secondary .ini file directly and activate using: \\nhdbnsutil -reconfig\\nNote:\\nSet the parameters carefully to avoid log full or disk full situations. For time travel\\nto work, log and snapshots are kept online in the data area. Because of this, log\\nand data grows on the secondary system when time travel is turned on. The\\nsystem workload determines how much data is needed.\\nNote:\\nTopology changes are not considered for secondary time travel, and travel\\noperation cannot be supported beyond these changes.\\nAfter setting the parameters, the secondary system begins retaining log information and\\nkeeping created snapshots. After retaining sufficient log information and data, the secondary\\nsystem is ready for time travel.\\nMonitoring Secondary Time Travel\\nYou can monitor the retaining log and the created snapshots.\\nTo monitor secondary time travel, the secondary system must be online. The current time\\ntravel range cannot be determined when the secondary system is offline.\\nMonitoring Secondary Time Travel\\nDetermine the valid range for which time travel can be executed:\\n-\\nMonitor available snapshots using\\n_SYS_DATABASES_SR_SITE_<sitename>.M_SNAPSHOTS at the primary site.\\n-\\nThe hdbnsutil -sr_timetravel --printRange\\n command provides a range for\\neach service in which time travel can be executed.\\n-\\nUse SQL on the primary system with the\\n_SYS_DATABASES_SR_SITE_<sitename>.M_SYSTEM_REPLICATION_TIMETRAVEL\\nsecondary proxy view.\\nMonitor the start time or log position of the system using:\\n_SYS_DATABASES_SR_SITE_<sitename>.M_SYSTEM_REPLICATION_TAKEOVER_HIST\\nORY\\nExecute Secondary Time Travel\\nYou can start the secondary system in online mode from a previous point in time using the\\nhdbnsutil -sr_timetravel\\n command. During execution of hdbnsutil -\\nsr_timetravel\\n, the specified time and location are stored internally in a dedicated file in the\\nSAP HANA directory. When calling hdbnsutil -sr_timetravel\\n, it can be specified\\nwhether takeover hooks should be called. If the parameter is not explicitly specified, the\\ndefault value from the configuration parameter \\ntimetravel_call_takeover_hooks\\n is\\nused.\\nThe secondary system enters online mode at the specified point in time during restart. After\\nrestart, the other services read the requested point in time and open their persistence using\\nthis information. If the requested point in time cannot be reached, then time travel is aborted.\\nLesson: Setting up SAP HANA System Replication with Secondary Time Travel\\n© Copyright. All rights reserved.\\n153'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 159}, page_content='A check ensures that there are time travel snapshots older than the start time for each\\nservice.\\nExecute Secondary Time Travel\\n1. Stop the secondary SAP HANA system.\\n2. Execute:\\nhdbnsutil -sr_timetravel --startTime=<startTime> [--\\ncallTakeoverHooks=on|off] [--comment=\"Your Comment\"]\\n.\\n3. Start the secondary SAP HANA system.\\nFor startTime\\n, use the following format specified in UTC: dd.mm.yyyy - hh.mm.ss\\nYou can specify whether takeover hooks should be called. If the\\ntimetravel_call_takeover_hooks\\n parameter is not explicitly specified, takeover hooks\\nwill not be called.\\nUse the --comment  option to add a reason for the time travel. This comment is displayed in\\nthe M_SYSTEM_REPLICATION_TAKEOVER_HISTORY monitoring view in the COMMENTS\\ncolumn.\\nThe secondary system will enter online mode at the specified point in time during restart.\\nAfter restart, the other services read the requested point in time and open their persistence\\nusing this information. If the requested point in time cannot be reached, then time travel will\\nbe aborted. A check ensures that there are time travel snapshots older than the start time for\\neach service.\\nNote:\\nThe call of hdbnsutil -sr_timetravel\\n on the secondary system is not yet\\noffered in the system replication app of the SAP HANA cockpit.\\nExecute Secondary Time Travel While Replication Continues\\nYou can start the log replay at a previous point in time to read older data from the secondary\\nsystem, while the secondary keeps replicating.\\nExecute Secondary Time Travel While Replication Continues\\n1. Stop the secondary SAP HANA system.\\n2. Execute:\\nhdbnsutil -sr_timetravel --startTime=<startTime> --\\nstartMode=replicate\\n3. Start the secondary SAP HANA system.\\n4. Optional: Trigger the log replay manually with:\\nhdbnsutil -sr_recoveruntil {--endTime=<timestamp> |max} [--nowait]\\n5. Optional: Stop the manual replay mode by setting the timetravel_logreplay_mode\\nparameter back to auto or using:\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n154'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 160}, page_content='hdbnsutil -sr_replaymode --mode={auto|manual}\\nAfter the system has started, the persistence has been opened on the specified point in time\\n(--startTime\\n). It is replicating the log, and log replay is not running.\\nIn this state, log replay can be executed manually. By executing multiple replay until calls, the\\nsecondary site can be step wise rolled forward and data can be accessed in read access mode\\nafter each replay step.\\nUse max to trigger the log replay up to the newest possible point in time. In this case, the\\ntarget timestamp is automatically determined by checking the valid time travel range for each\\nservice.\\nUse the --nowait\\n option to specify if the command should be executed asynchronously.\\nSetup for the Exercises\\nIn the following exercise, you set up the SAP HANA system replication with secondary time\\ntravel.\\nFigure 94: Secondary Time Travel Exercise Overview\\nLESSON SUMMARY\\nYou should now be able to:\\nSet up SAP HANA system replication with Secondary Time Travel\\nLesson: Setting up SAP HANA System Replication with Secondary Time Travel\\n© Copyright. All rights reserved.\\n155'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 161}, page_content='Unit 3\\nLesson 8\\nExplaining Zero Downtime Maintenance\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nExplain Zero Downtime Maintenance\\nZero Downtime Maintenance\\nYou can use SAP HANA system replication to upgrade your SAP HANA systems, as the\\nsecondary system can run with a higher software version than the primary system.\\nNear Zero Downtime Upgrade\\nSAP HANA offers zero downtime maintenance, together with SAP HANA system replication.\\nYou can use system replication to upgrade your SAP HANA systems because the secondary\\nsystem can run with a higher software version than the primary system.\\nAs a prerequisite, system replication must be configured and active between two identical\\nSAP HANA systems.\\nIf system replication is active, you can first upgrade the secondary system to a new revision\\nso that it can take over the role of the primary system. The takeover only requires a few\\nminutes and the committed transactions or data are not lost. You can then perform an\\nupgrade on the primary system, which is now in the role of secondary.\\nThe secondary system can be initially installed with the new software version, or upgraded to\\nthe new software version when replication is already configured. After you upgrade the\\nsecondary, you must replicate all data to the secondary system, which already has the new\\nsoftware version. When the secondary system is ACTIVE (all services have synced), you can\\nexecute a takeover on the secondary system. This step makes the secondary system\\nproductive with the new software version.\\nIn an Active/Active (read enabled) system replication setup, the version of the primary and\\nthe secondary systems must be identical. For the near zero downtime upgrade to work, the\\noperation mode on the secondary system is automatically set to \\nlogreplay\\n. Like this, the\\ntwo systems can get back in sync before the takeover step. To reestablish the Active/Active\\n(read enabled) landscape at the end, the logreplay_readaccess\\n operation mode must be\\nexplicitly specified during the former registration of the primary system as a new secondary\\nsystem.\\n© Copyright. All rights reserved.\\n156'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 162}, page_content='Figure 95: Zero Downtime Maintenance\\nPrerequisites\\nYou configured a user in the local userstore under the SRTAKEOVER key.\\nTherefore, create a <myrepouser> user with the necessary privileges to import the repository\\ncontent at takeover time on the primary and secondary systems.\\nSet the user store entry under the SRTAKEOVER key using the following command:\\nhdbuserstore SET SRTAKEOVER <public hostname>:<sqlport>\\n<myrepouser> <myrepousers_password>\\nSystem replication is configured and active between two identical SAP HANA systems:\\nThe primary system is the production system.\\nThe secondary system will become the production system after the upgrade.\\nThe prerequisite is to run both systems with the same endianness.\\nThe process, which is described in detail in the SAP HANA Administration Guide, looks like the\\nfollowing:\\n1. Upgrade the secondary system:\\n./hdblcm --action=update\\n2. Verify that system replication is active and that all services are in sync.\\n3. Stop the primary system.\\n4. Perform a takeover on the secondary system, including switching virtual IP addresses to\\nthe secondary system, and start using it productively:\\nLesson: Explaining Zero Downtime Maintenance\\n© Copyright. All rights reserved.\\n157'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 163}, page_content='hdbnsutil -sr_takeover\\n5. Upgrade the previous primary system without starting the system. This is necessary\\nbecause otherwise the primary has to be stopped again before it can be registered as the\\nsecondary.\\n./ hdblcm --action=update --hdbupd_server_nostart\\n6. Register the previous primary system as the secondary system:\\n./hdbnsutil –sr_register …\\n7. Start the previous primary system as the secondary system.\\nZero Downtime Maintenance Featured by SAP NetWeaver ABAP Stack\\nTo achieve a real zero downtime upgrade from the application server perspective, see SAP\\nNote: 1913302 — Connectivity suspend of Appserver during takeover.\\nBased on the connectivity suspend feature of the SAP NetWeaver ABAP stack, DBSL of the\\ndatabase interface decouples transaction management between ABAP and the SAP HANA\\ndatabase. This keeps the transaction on the ABAP layer alive and allows the change of\\ncomponents (software versions) on the layers below the secondary (shadow) SAP HANA\\ninstance.\\nHardware Exchange\\nAdditionally, as described in SAP Note: 1984882 — Using HANA system replication for\\nHardware Exchange with Minimum Downtime, hardware can be exchanged with minimal\\ndowntime using SAP HANA system replication.\\nLESSON SUMMARY\\nYou should now be able to:\\nExplain Zero Downtime Maintenance\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n158'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 164}, page_content='Unit 3\\nLesson 9\\nIntroducing Multitier and Multitarget System\\nReplication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nExplain Multitier and Multitarget System Replication\\nMultitier System Replication\\nTo offer higher levels of availability, you can link together multiple systems in a SAP HANA\\nmultitier system replication landscape.\\nWith Multitier system replication, a tier 2 system replication setup can be used as the source\\nfor replication in a chained setup of primary site, tier 2 secondary site, and tier 3 secondary\\nsite.\\nAfter setting up a basic system replication scenario, you add a third system to provide\\nanother level of redundancy. In a multitier setup, the primary system is always on tier 1, a tier\\n2 secondary has a primary system as its replication source, and a tier 3 secondary has the tier\\n2 secondary as its replication source.\\nFigure 96: Multitier System Replication: Overview\\n© Copyright. All rights reserved.\\n159'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 165}, page_content='In general, multitier system replication does not allow operation mode mixtures. However,\\nthere is one exception. If the logreplay_readaccess\\n operation mode is configured\\nbetween tier 1 and tier 2, the logreplay\\n operation mode can be configured between tier 2\\nand tier 3.\\nSet Up SAP HANA Multitier System Replication\\nYou can configure multitier system replication using the following tools:\\nThe SAP HANA Cockpit\\nhdbnsutil\\nSAP HANA Studio\\nTo set up multitier system replication, you have installed and configured three identical,\\nindependently operational SAP HANA systems: a primary system, a tier 2 secondary system,\\nand a tier 3 secondary system.\\nTo use hdbnsutil to set up multitier system replication, you must perform the following steps.\\nIn this scenario, there are three SAP HANA systems: A, B, and C, named Tier1 , Tier2, and\\nTier3 respectively. In addition, in this scenario, multitier system replication supports a tier 2\\nsecondary with sync replication mode and a tier 3 secondary with async replication mode.\\nSet up an SAP HANA Multitier System Replication Using hdbnsutil\\n1. Start SAP HANA system A and back up the system database and all tenant databases.\\n2. Enable system replication and give system A a logical name:\\nhdbnsutil -sr_enable --name=Tier1\\n3. Stop the tier 2 secondary system B.\\n4. Register system B as tier 2:\\nhdbnsutil -sr_register --replicationMode=sync --name=Tier2 \\n          --remoteInstance=<instID> --remoteHost=<hostA>\\n5. Start the tier 2 secondary system B.\\n6. Enable tier 2 as the source for a tier 3 secondary system:\\nhdbnsutil -sr_enable\\n7. Stop the tier 3 secondary system C.\\n8. Register system C as tier 3:\\nhdbnsutil -sr_register --replicationMode=async --name=Tier3 \\n          --remoteInstance=<instID> --remoteHost=<hostB>\\n9. Start the tier 3 secondary system C.\\nUsing the SAP HANA Cockpit, you can set up multitier system replication in one step. After\\nyou have entered the system details for tier 1 and tier 2, you can add the details for the tier 3\\nsystem.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n160'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 166}, page_content='Figure 97: Set up Multitier System Replication\\nFigure 98: Monitor Multitier System Replication\\nLesson: Introducing Multitier and Multitarget System Replication\\n© Copyright. All rights reserved.\\n161'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 167}, page_content='If the primary system fails, a takeover to the tier 2 secondary system is done. Once your failed\\nsite is operational again, you can attach it as a tier 3 secondary system or you can restore the\\noriginal multitier system replication configuration.\\nMultitarget System Replication\\nIn a multitarget system replication, the primary system can replicate data changes to more\\nthan one secondary system.\\nMultitarget system replication can bring advantages for several use cases:\\nUpdate scenarios\\nRearrangements of system replication multitier chains\\nReaching higher availability (before stopping existing structures, new structures can be\\nbuilt and established)\\nFigure 99: Multitarget Replication – Overview\\nPrimary system A in data center 1 replicates data changes to secondary system B in the same\\ndata center. Primary system A also replicates data changes to secondary system C in data\\ncenter 2. Secondary system C is a source system for a further secondary system D located in\\nthe same data center with system C.\\nIn a multitarget system replication, the secondary systems can be configured to automatically\\nre-register to a new source system when the original source system is unavailable.\\nIn a multitarget system replication setup, you can configure multiple secondary systems as\\nActive/Active (read enabled). Only one of these secondary systems can be accessed using\\nhint-based statement routing; the others must be accessed using a direct connection.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n162'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 168}, page_content='Figure 100: Multitarget Replication - Example\\nFigure 101: Multitarget Replication – Output of hdbnsutil\\nLesson: Introducing Multitier and Multitarget System Replication\\n© Copyright. All rights reserved.\\n163'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 169}, page_content='Multitarget Replication with Read-Enabled Secondary Site\\nIn a multitarget system replication setup, you can configure multiple secondary systems as\\nActive/Active (read enabled). Only one of these secondary systems can be accessed using\\nhint-based statement routing; the others must be accessed using a direct connection.\\nFigure 102: Use Case for Multitarget Replication with Active/Active\\nYou can configure which of the read-enabled secondary systems is allowed for hint-based\\nstatement routing using the parameter: \\nglobal.ini/[ system_replication]/\\nhint_based_routing_site_name = <site_name>\\n.\\nSo far, the feature is implemented for Tier 2 systems only – Tier 3 are not enabled for this\\nfeature. Take care that systems which are supposed to use this feature are connected directly\\nto primary system (Tier 1).\\nDisaster Recovery Scenarios for Multitarget System Replication\\nSeveral solutions are available when the systems involved in a multitarget system replication\\nconfiguration fail.\\nWe are using the setup described in the figure, Multitarget Replication Failure on Primary\\nSystem, as an example to describe the procedure. In this setup, primary system A replicates\\ndata changes to secondary system B located in the same data center. Primary system A also\\nreplicates data changes to the secondary system C located in data center 2. Secondary\\nsystem C is a source system for a further secondary system D located in the same data\\ncenter with system C.\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n164'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 170}, page_content='Figure 103: Multitarget Replication Failure on Primary System\\nWhen primary system A fails, proceed as follows:\\n1. Take over on secondary system B in data center 1.\\n2. Register secondary system C in data center 2 to the new primary system B in data center\\n1. Then, register secondary system D in data center 2 to secondary system C.\\n3. After the failure on the previous primary system A is solved, register it to the new primary\\nsystem B in data center 1.\\nAlternatively, you can set the global.ini/[system_replication]/\\nregister_secondaries_on_takeover\\n parameter to True and take over on secondary\\nsystem B in data center 1. As a result, secondary system C in data center 2 will register\\nautomatically to the new primary system B, while secondary system D in data center 2 will\\nregister automatically to secondary system C.\\nAfter the failure on the previous primary system A is solved, register it to the new primary\\nsystem B in data center 1.\\nLesson: Introducing Multitier and Multitarget System Replication\\n© Copyright. All rights reserved.\\n165'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 171}, page_content='Figure 104: Multitarget Replication Failure on Secondary System\\nWhen secondary system C fails, register secondary system D to secondary system B in data\\ncenter 1.\\nAlternatively, you can set parameters on the specific secondary so that the secondary system\\nD will register automatically secondary system D to secondary system B in data center 1:\\nglobal.ini/[system_replication]/alternative_sources\\nglobal.ini/[system_replication]/\\nretries_before_register_to_alternative_source\\nExample: alternative_sources\\n=SiteC:sync,SiteB:async\\n,..\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n166'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 172}, page_content='Figure 105: Multitarget Replication Failure of Data Center 1\\nWhen all the systems in data center 1 fail as shown in figure, Multi Target Replication Failure of\\nData Center 1, proceed as follows:\\n1. Take over on secondary system C in data center 2.\\n2. After the failure on the previous primary system is solved, register system A to the new\\nprimary system C in data center 2.\\n3. Register secondary system B as tier 3 to system A in data center 1.\\nUse Multitarget System Replication for Near Zero Downtime Upgrades\\nYou can upgrade your SAP HANA systems running in a multitarget system replication setup.\\nExample:\\nPrimary system A replicates data changes to secondary system B located in the same data\\ncenter. Primary system A also replicates data changes to the secondary system C located in\\ndata center 2. Secondary system C is a source system for a further secondary system D\\nlocated in the same data center.\\nIn this setup:\\nThe primary system is the production system.\\nThe secondary system located in the same data center as the primary system will become\\nthe production system after the upgrade. Further secondary systems are located in a\\nremote data center.\\nThere is no replication error.\\nLesson: Introducing Multitier and Multitarget System Replication\\n© Copyright. All rights reserved.\\n167'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 173}, page_content='Figure 106: MultiTarget Replication - Upgrade\\nLESSON SUMMARY\\nYou should now be able to:\\nExplain Multitier and Multitarget System Replication\\nUnit 3: SAP HANA Disaster Tolerance\\n© Copyright. All rights reserved.\\n168'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 174}, page_content='Unit 3\\nLearning Assessment\\n1. With SAP HANA storage replication, you can use the servers on the secondary system for\\nnon-production SAP HANA systems.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n2. When using the Continuous Log Replay operation mode ( logreplay\\n), the shipped redo\\nlog is continuously replayed on the secondary site and read-only access on the secondary\\nsite is allowed.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n3. Which of the following are prerequisites for System Replication with QA and Development\\nSystem on the secondary site?\\nChoose the correct answers.\\nX\\nA Preload of tables must be switched off on the secondary.\\nX\\nB The instance numbers for the replicated system and the Development/QA system\\nare identical.\\nX\\nC Development/QA systems need to be shut down in case of a takeover.\\nX\\nD Additional independent disk volume is needed for Development/QA systems.\\n4. Which tool can you use to set up SAP HANA system replication in one step?\\nChoose the correct answer.\\nX\\nA SAP HANA Studio\\nX\\nB SAP HANA Web IDE\\nX\\nC SAP HANA Cockpit\\nX\\nD hdbnsutil\\n© Copyright. All rights reserved.\\n169'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 175}, page_content='5. The system replication status Initializing\\n indicates that the initial data transfer is in\\nprogress.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n6. You create a new tenant database in a configured SAP HANA system replication. Which\\nprerequisite must be fulfilled for the new tenant database to participate in the replication?\\nChoose the correct answer.\\nX\\nA It must be stopped.\\nX\\nB It must be backed up.\\nX\\nC A fallback snapshot must be created\\nX\\nD The restart mode must be set to No auto-restart\\n7. Which tool can you use to trigger a takeover from the current primary to the secondary\\nsystem?\\nChoose the correct answers.\\nX\\nA hdblcm\\nX\\nB hdbsql\\nX\\nC SAP HANA Cockpit\\nX\\nD hdbnsutil\\n8. System replication with a read-enabled secondary site is based on the delta data shipping\\noperation mode.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nUnit 3: Learning Assessment\\n© Copyright. All rights reserved.\\n170'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 176}, page_content='9. Which replication modes are supported for system replication with a read-enabled\\nsecondary site?\\nChoose the correct answers.\\nX\\nA SYNC\\nX\\nB Full SYNC\\nX\\nC ASYNC\\nX\\nD SYNCMEM\\n10. After an invisible takeover, the client keeps the connections to the primary system and the\\nsessions are restored to the secondary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n11. Enabling SAP HANA system replication with secondary time travel has no impact on the\\nsizing and performance of the secondary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n12. You can use system replication to upgrade your SAP HANA systems because the\\nsecondary system can run with a higher software version than the primary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n13. To which use cases does multitarget system replication bring advantages?\\nChoose the correct answers.\\nX\\nA Update scenarios\\nX\\nB Reaching higher availability\\nX\\nC Necessity to perform backups\\nX\\nD Rearrangements of system replication multitier chains\\nUnit 3: Learning Assessment\\n© Copyright. All rights reserved.\\n171'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 177}, page_content='Unit 3\\nLearning Assessment - Answers\\n1. With SAP HANA storage replication, you can use the servers on the secondary system for\\nnon-production SAP HANA systems.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! Depending on the hardware solution, you can use the servers of the\\nsecondary system for other SAP HANA systems (such as test systems) until the takeover.\\n2. When using the Continuous Log Replay operation mode ( logreplay\\n), the shipped redo\\nlog is continuously replayed on the secondary site and read-only access on the secondary\\nsite is allowed.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! When using the Continuous Log Replay operation mode (\\nlogreplay\\n),\\nread-only access on the secondary site is not allowed. Therefore, you have to configure\\nthe Continuous Log Replay with Active/Active operation mode\\n(logreplay_readaccess)\\n).\\n3. Which of the following are prerequisites for System Replication with QA and Development\\nSystem on the secondary site?\\nChoose the correct answers.\\nX\\nA Preload of tables must be switched off on the secondary.\\nX\\nB The instance numbers for the replicated system and the Development/QA system\\nare identical.\\nX\\nC Development/QA systems need to be shut down in case of a takeover.\\nX\\nD Additional independent disk volume is needed for Development/QA systems.\\nYou are correct! To use the secondary site in a system replication scenario for running\\nDevelopment/QA systems, the preload of tables must be switched off on the secondary\\nsite and additional independent disk volume is needed for Development/QA systems.\\n© Copyright. All rights reserved.\\n172'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 178}, page_content='4. Which tool can you use to set up SAP HANA system replication in one step?\\nChoose the correct answer.\\nX\\nA SAP HANA Studio\\nX\\nB SAP HANA Web IDE\\nX\\nC SAP HANA Cockpit\\nX\\nD hdbnsutil\\nYou are correct! SAP HANA Cockpit allows you to enable the primary system and then\\nregister the secondary system from the primary system in one step.\\n5. The system replication status Initializing\\n indicates that the initial data transfer is in\\nprogress.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! The system replication status \\nInitializing  indicates that the initial data\\ntransfer is in progress. In this state the secondary system is not usable.\\n6. You create a new tenant database in a configured SAP HANA system replication. Which\\nprerequisite must be fulfilled for the new tenant database to participate in the replication?\\nChoose the correct answer.\\nX\\nA It must be stopped.\\nX\\nB It must be backed up.\\nX\\nC A fallback snapshot must be created\\nX\\nD The restart mode must be set to No auto-restart\\nYou are correct! If a new tenant database is created in a configured SAP HANA system\\nreplication, it must be backed up to participate in the replication.\\nUnit 3: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n173'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 179}, page_content='7. Which tool can you use to trigger a takeover from the current primary to the secondary\\nsystem?\\nChoose the correct answers.\\nX\\nA hdblcm\\nX\\nB hdbsql\\nX\\nC SAP HANA Cockpit\\nX\\nD hdbnsutil\\nYou are correct! The takeover from the current primary to the secondary system can be\\ntriggered using SAP HANA Cockpit and hdbnsutil.\\n8. System replication with a read-enabled secondary site is based on the delta data shipping\\noperation mode.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! System replication with a read-enabled secondary site is based on the\\ncontinuous log replay operation mode.\\n9. Which replication modes are supported for system replication with a read-enabled\\nsecondary site?\\nChoose the correct answers.\\nX\\nA SYNC\\nX\\nB Full SYNC\\nX\\nC ASYNC\\nX\\nD SYNCMEM\\nYou are correct! All existing replication modes are supported for system replication with a\\nread-enabled secondary site.\\n10. After an invisible takeover, the client keeps the connections to the primary system and the\\nsessions are restored to the secondary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! After an invisible takeover, the client keeps the connections to the\\nprimary system and the sessions are restored to the secondary system.\\nUnit 3: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n174'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 180}, page_content='11. Enabling SAP HANA system replication with secondary time travel has no impact on the\\nsizing and performance of the secondary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! For time travel to work, log information and snapshots are kept online in\\nthe data area. Because of this, log information and data grows on the secondary system\\nwhen time travel is turned on.\\n12. You can use system replication to upgrade your SAP HANA systems because the\\nsecondary system can run with a higher software version than the primary system.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! SAP HANA offers zero downtime maintenance, together with SAP HANA\\nsystem replication. You can use system replication to upgrade your SAP HANA systems\\nbecause the secondary system can run with a higher software version than the primary\\nsystem.\\n13. To which use cases does multitarget system replication bring advantages?\\nChoose the correct answers.\\nX\\nA Update scenarios\\nX\\nB Reaching higher availability\\nX\\nC Necessity to perform backups\\nX\\nD Rearrangements of system replication multitier chains\\nYou are correct! Multitarget system replication can bring advantages for update\\nscenarios, for reaching higher availability, and for rearrangements of system replication\\nmultitier chains.\\nUnit 3: Learning Assessment - Answers\\n© Copyright. All rights reserved.\\n175'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 181}, page_content='UNIT 4\\nSAP HANA Tenant\\nReplication\\nLesson 1\\nExplaining Tenant Replication\\n177\\nUNIT OBJECTIVES\\nUnderstand the setup of tenant replication\\n© Copyright. All rights reserved.\\n176'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 182}, page_content='Unit 4\\nLesson 1\\nExplaining Tenant Replication\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nUnderstand the setup of tenant replication\\nCopying and Moving Tenant Databases Between Systems\\nUsing SAP HANA system replication mechanisms, SAP HANA tenant databases can be\\ncopied and moved securely and conveniently from one SAP HANA system to another with\\nnear-zero downtime. This allows you to respond flexibly to changing resource requirements\\nand to manage your system landscape efficiently.\\nCopying and moving a tenant database are essentially the same processes. First, the tenant\\ndatabase is copied through the replication of all of its data to a newly created tenant database\\nin a target system. Once all data has been successfully transferred, the new tenant database\\nis started as a separate, independent database. If the aim is to move the tenant database to\\nthe new system, the original tenant database is deleted and the new tenant database takes\\nover.\\nFigure 107: Copying and Moving Tenant Databases\\nThe only difference between copying and moving a tenant database therefore, is what\\nhappens to the original tenant database after all data has been transferred to the new tenant\\ndatabase in the target system.\\n© Copyright. All rights reserved.\\n177'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 183}, page_content='In both cases, the new tenant database starts running as a fully separate, independent\\ndatabase.\\nSeveral tenant databases can be copied or moved to a system at the same time. It is also\\npossible to copy or move a tenant database to a system with a different isolation level than\\nthe source system.\\nYou can also use this mechanism to create a copy of a tenant database on the same host or to\\ncopy/move a tenant database to another host that is part of the same system.\\nUse Cases for Copying and Moving Tenants\\nLoad balancing between systems\\nFor example, a tenant database is running a more demanding workload than anticipated,\\nso you move it to a system running on a host with more CPU resources.\\nManagement of deployment environment\\nFor example, you want to copy a tenant database running in your test system to the live\\nproduction system.\\nTenant database-specific upgrades\\nFor example, you want to upgrade a single tenant database but not the entire system, so\\nyou move the tenant database to a system already running the higher version.\\nTemplate databases\\nFor example, you create a tenant database with a default configuration that you want to\\nreuse as the basis for new tenant databases in other systems. You can simply copy the\\ntenant database as a template to other systems.\\nPrerequisites and Implementation Considerations\\nA new tenant database will be created in the target system. Therefore, the target tenant\\ndatabase must not already exist in the target system.\\nThe target system must have a software version equal to, or higher than the source\\nsystem.\\nDuring the copy and move process, data must be replicated using a secure (SSL/TLS)\\nnetwork connection by default.\\nIn a running system replication, it is possible to copy or move tenant databases into a\\nprimary system, or from a primary system into another target system that is different than\\nthe secondary system.\\nThere can be no changes to the topology of the original tenant database while the move or\\ncopy is in progress.\\nIf the source system is configured for host auto-failover, the copy or process fails in the\\nevent of failover to a standby host.\\nThe administrator has the system privilege DATABASE ADMIN.\\nTenant replication is configured.\\nA complete system backup for the source tenant database has been created.\\nUnit 4: SAP HANA Tenant Replication\\n© Copyright. All rights reserved.\\n178'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 184}, page_content='Create a Tenant Database Using the SAP HANA Replication Mechanism\\nThe figure Create Tenant Using Replication  describes how to create a new tenant, based on an\\nexisting tenant using the SAP HANA replication mechanism on a target system performed\\nwith the SAP HANA Cockpit tool.\\nFigure 108: Create Tenant Using Replication\\n1. To create a new tenant based on an existing tenant, on the Database Management screen\\nof your SAP HANA target systems SYSTEMDB, choose Create Tenant   \\n Create Tenant\\nUsing Replication.\\n2. Follow the guided steps. To create a copy of an existing tenant database, select \\nCopy\\nusing replication . To remove the original tenant after the copy has been created, select\\nMove using replication . Choose the source system- and tenant databases and enter a\\nname for the new tenant.\\n3. Perform the following steps:\\nOptional: Specify the number of the internal communication port of the listed services.\\n(For high isolation systems only) Enter a dedicated OS user and group for the source.\\nIf configuration changes are required for the replication, warnings appear to indicate\\nthe required changes. Select Approve to proceed.\\nIf prompted, enter the SAP Control credentials required for the restart of the system.\\nIf a trust relationship has not yet been established between the source system and the\\ntarget system, select an existing public key certificate or upload a certificate.\\nReview the summary, then choose Copy Tenant Database  or Move Tenant Database , to\\nstart replicating the tenant database.\\n4. The new tenant database appears in the list of databases of your target systems\\nSYSTEMDB.\\nLesson: Explaining Tenant Replication\\n© Copyright. All rights reserved.\\n179'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 185}, page_content='Note:\\nFor detailed information about creating tenant databases using replication, please\\ncheck the SAP HANA Administration Guide and the SAP HANA Administration\\nwith SAP HANA Cockpit document.\\nCopy a Tenant Database Using the SAP HANA Replication Mechanism\\nThe figures Copy Tenant Using Replication (1, 2, and 3) describe how to copy a tenant\\ndatabase to another system using the SAP HANA replication mechanism and the SAP HANA\\nCockpit tool.\\nFigure 109: Copy Tenant Using Replication (1/3)\\nFigure 110: Copy Tenant Using Replication (2/3)\\nUnit 4: SAP HANA Tenant Replication\\n© Copyright. All rights reserved.\\n180'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 186}, page_content='Figure 111: Copy Tenant Using Replication (3/3)\\n1. On the Database Management screen of your SAP HANA source systems SYSTEMDB,\\nmark your source tenant.\\n2. Choose Tenant Actions   \\n Replicate Tenant Using Replication .\\n3. Choose Copy using replication .\\n4. The Source System Database and the Source Tenant  will be provided automatically.\\n5. Choose the Target System Database  and enter a name for the Target Tenant .\\nOptional: Under Advanced Settings, specify the port number for each service. If you do\\nnot enter a port, it is assigned automatically based on port number availability. In\\nmultihost systems enter the host and port of a service.\\n(For high isolation systems only) Enter a dedicated OS user and group for the source.\\n6. If configuration changes are required for the replication, warnings appear to indicate the\\nrequired changes. Select Approve to proceed.\\nIf prompted, enter the SAP Control credentials required for the restart of the system.\\n7. If a trust relationship has not yet been established between the source system and the\\ntarget system, select an existing public key certificate or upload a certificate.\\n8. Review the summary, then choose Copy Tenant Database , to start replicating the tenant\\ndatabase.\\n9. Observe the following:\\na. The Progress page shows the running configuration process, the system restarts, and\\nthe certification installation.\\nb. After finishing, the progress bar indicates the status of the tenant replication.\\n10. The copied tenant database appears in the Database Management screen of the target\\nsystems SYSTEMDB.\\nLesson: Explaining Tenant Replication\\n© Copyright. All rights reserved.\\n181'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 187}, page_content='Move a Tenant Database Using the SAP HANA Replication Mechanism\\nThe figures Move Tenant Using Replication (1 and 2)  describe how to move a tenant database\\nto another system using the SAP HANA replication mechanism and the SAP HANA Cockpit\\ntool.\\nFigure 112: Move Tenant Using Replication (1/2)\\nFigure 113: Move Tenant Using Replication (2/2)\\nAs mentioned before, copying and moving a tenant database are essentially the same\\nprocess.\\nThe differences are:\\nUnit 4: SAP HANA Tenant Replication\\n© Copyright. All rights reserved.\\n182'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 188}, page_content='In step 4), choose Move using replication . This will remove the original tenant after the\\ncopy has been created.\\nIn step 5), the button is named Move Tenant Database .\\nNote:\\nThe process of copying and moving tenant databases is described in detail in the\\nSAP HANA Administration Guide and the SAP HANA Administration with SAP\\nHANA Cockpit document.\\nCopy and Move Process\\nThe process of copying or moving a tenant database is driven entirely by the target system.\\n1. To prepare the copy and move process, the system administrator performs the following\\ntasks:\\nVerifies that TLS/SSL is enabled on internal communication channels.\\nOpens communication from the target system to the source system by enabling\\nsource system services to listen on all network interfaces.\\nCreates credentials for authenticated access to the source system.\\nConfigures a secure connection from the target system to source system.\\nBacks up the source tenant database.\\n2. The system administrator triggers the creation of the tenant database as a replica of the\\nsource tenant database by executing the SQL statement CREATE DATABASE AS\\nREPLICA.\\n3. During the copy process, the system database of the target system performs the following\\ntasks:\\nEstablishes a secure connection to the system database using the stored credentials\\ncreated earlier.\\nCreates a new tenant database with the same topology as the tenant database in the\\nsource system.\\nInitiates replication of data between the services in the source tenant database and the\\ncorresponding services in the target database.\\nCommits the copy by executing the SQL statement \\nALTER DATABASE FINALIZE\\nREPLICA when the replication status is ACTIVE.\\n4. To finalize the copy and move process, the following steps are performed:\\nThe system database of the target system starts the target tenant database and\\nperforms clean-up operations.\\nThe system administrator performs manual post-copy or post-move steps.\\nSetup for the Exercise\\nIn the following exercise, you will copy and move a tenant database from a source system to a\\ntarget system using the SAP HANA system replication mechanism.\\nLesson: Explaining Tenant Replication\\n© Copyright. All rights reserved.\\n183'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 189}, page_content='Figure 114: Exercise: Copy and Move a Tenant Database Between Systems\\nLESSON SUMMARY\\nYou should now be able to:\\nUnderstand the setup of tenant replication\\nUnit 4: SAP HANA Tenant Replication\\n© Copyright. All rights reserved.\\n184'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 190}, page_content='Unit 4\\nLearning Assessment\\n1. Moving tenant databases can be used for a tenant database-specific upgrade.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n© Copyright. All rights reserved.\\n185'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 191}, page_content='Unit 4\\nLearning Assessment - Answers\\n1. Moving tenant databases can be used for a tenant database-specific upgrade.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! If you want to upgrade a single tenant database but not the entire system,\\nyou move the tenant database to a system already running the higher version.\\n© Copyright. All rights reserved.\\n186'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 192}, page_content='UNIT 5\\nAppendix: HANA\\nAdditional Scripts\\nLesson 1\\nAppendix: Using Python Support Scripts in SAP HANA\\n188\\nLesson 2\\nAppendix: Reinitializing a Non-Recoverable System Database\\n195\\nUNIT OBJECTIVES\\nUnderstand the Python support scripts used in SAP HANA\\nReinitialize a non-recoverable system database\\n© Copyright. All rights reserved.\\n187'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 193}, page_content='Unit 5\\nLesson 1\\nAppendix: Using Python Support Scripts in\\nSAP HANA\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nUnderstand the Python support scripts used in SAP HANA\\nPython Support Scripts in SAP HANA\\nBusiness Example\\nAs an SAP HANA database administrator, sometimes you need to access the SAP HANA\\ndatabase directly from the command line, without the use of the SAP HANA Cockpit. There\\nare several useful Python scripts that you can use at the command line to access\\nconfiguration and monitor data stored in the SAP HANA database.\\nFigure 115: Overview of SAP HANA Python Scripts\\n© Copyright. All rights reserved.\\n188'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 194}, page_content='The Support Tool HDBAdmin.sh\\nFigure 116: The HDB Admin Tool\\nDuring the exercises, we used the HDBAdmin tool, therefore more explanation about this tool\\nmay be useful.\\nThis tool was created for internal use by SAP and is not supported for public use. You can use\\nthe tool if you wish, but SAP does not provide support for issues encountered while using the\\ntool or the result set produced by the tool.\\nDuring our exercises, the HDBAdmin tool was very useful because it had the one-second\\nautomatic refresh feature, so we could see the host auto-failover happen in real time.\\nFor daily business, SAP recommends using the SAP HANA Cockpit 2.0 for system\\nadministration and performance monitoring tasks.\\nThe HDBAdmin tool has no documentation, which sometimes makes it difficult to use. Its\\norigin is the standalone TREX Admin tool for the SAP BW Accelerator. In that area, there is\\nsome documentation. Also, the HDBAdmin tool is used and shown in several demo videos in\\nthe SAP HANA Academy.\\nStarting the HDBAdmin Tool\\nLog on to the Linux desktop as the <sid>adm user to start the HDBAdmin tool. On Linux, the\\nHDB Admin tool has a graphical interface, therefore you need an X server installed on your\\nLinux server. This is often seen as a problem by Unix administrators, so starting HDBAdmin\\nlocally is difficult and you cannot use a terminal program that only supports text mode, such\\nas ssh.\\nA solution to this problem is simple. Because the X Window System is an architecture-\\nindependent system for remote graphical user interfaces over the network, you can use your\\nWindows PC or laptop as a graphical display.\\nMicrosoft Windows by default has no X Windows support, but there are many third-party\\nimplementations. Several of these implementations are free and open source. Some\\nexamples are Cygwin/X and Xming. Others are paid and proprietary, such as Exceed, MKS X/\\nServer, and Reflection X.\\nLesson: Appendix: Using Python Support Scripts in SAP HANA\\n© Copyright. All rights reserved.\\n189'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 195}, page_content='Caution:\\nAlways keep in mind that you use the HDBAdmin tool at your own risk, and SAP\\ndoes not provide support for issues encountered while using the tool.\\nUseful SAP Notes\\nSAP Note: 2534881 - Issues while working with HDBAdmin tool\\nThe hanasitter.py Script\\nFigure 117: The hanasitter.py Script\\nHANASitter Features:\\nDatabase online check\\nCPU, ping, and critical feature check\\nRecording mode for RTE dumps, stack calls, kernel profiler trace, and GStack\\nScale-out monitor\\nCritical session killer\\nThe SAP HANA sitter checks by default once an hour, if SAP HANA is online and primary. In\\nthis case, it starts to track. Tracking includes regularly (by default one minute) checking if\\nSAP HANA is responsive. If it is not, it starts to record.\\nRecording can include writing call stacks of all active threads, recording run time dumps,\\nindex server gstacks, and/or kernel profiler traces. By default, nothing is recorded.\\nIf SAP HANA is responsive, it checks many of the critical features of SAP HANA. As standard,\\nthe script checks if there are more than 30 active threads. If there are more than 30 active\\nthreads, the script starts to record.\\nWhen the script has finished recording, it exits. The script can be configured to restart from\\nthe command line.\\nUnit 5: Appendix: HANA Additional Scripts\\n© Copyright. All rights reserved.\\n190'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 196}, page_content='When the script has finished all the tests successfully, it sleeps for one hour, before it starts\\nall the checks again.\\nSetup Steps Overview\\n1. Create an SAP HANA user (for example, HANASITTER, but you can use a different name)\\nand assign the CATALOG READ privilege.\\n2. Create a user key (for example, SYSTEMKEY, but you can use a different name) in the\\nhdbuserstore.\\n3. Download the hanasitter.py script attached to SAP Note: 2399979.\\n4. Store the script in, for example, the python_support directory.\\n5. As <sid>adm, change to the python_support directory with the command \\ncdpy.\\n6. Execute the script with the command python hanasitter.py -ng 1\\n.\\nUseful SAP Notes\\nSAP Note: 2399979 - How-To: Configuring automatic SAP HANA Data Collection with SAP\\nHANASitter\\nThe hanacleaner.py Script\\nFigure 118: The hanacleaner.py Script\\nThe SAP HANA cleaner is a housekeeping service for SAP HANA. It can be used to clean the\\nbackup catalog, diagnostic files, and alerts, and to compress the backup logs. It should be\\nexecuted by <sid>adm or, if you use a CRON job, with the same environment as <sid>adm.\\nFor more information, see SAP Note: 2399996 and SAP Note: 2400024.\\nHANACleaner Features:\\nCleanup for backup catalog and backup logs\\nCleanup for trace and dump files\\nLog segment cleanup\\nLesson: Appendix: Using Python Support Scripts in SAP HANA\\n© Copyright. All rights reserved.\\n191'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 197}, page_content='Audit log cleanup\\nCleanup old alerts from the alert table\\nRemove old ini file history\\nRe-optimize table compression\\nCheck and repair disk fragmentation\\nSetup Steps Overview\\n1. Create an SAP HANA user (for example, HANACLEANER, but you can use a different\\nname) and assign the CATALOG READ privilege.\\n2. Create a user key (for example, SYSTEMKEY, but you can use a different name) in the\\nhdbuserstore.\\n3. Download the hanacleaner.py script attached to SAP Note: 2399996.\\n4. Store the script in, for example, the python_support directory.\\n5. As <sid>adm, change to the python_support directory with the command \\ncdpy.\\n6. Execute the script with the command python hanacleaner.py -be 20\\n.\\nUseful SAP Notes\\nSAP Note: 2399996 - How-To: Configuring automatic SAP HANA Cleanup with SAP\\nHANACleaner\\nSAP Note: 2400024 - How-To: SAP HANA Administration and Monitoring\\nDownload Locations for Additional SAP HANA Scripts\\nFigure 119: Additional Python Scripts and Locations\\nSAP HANACleaner, SAP HANASitter, SAP HANADumpViewer, SAP HANATimer, and SAP\\nHANAChecker are very useful tools for automating several SAP HANA administration tasks.\\nThese tools are provided “as is” and can be found at Github. The generic Github link is: \\nhttps://github.com/chriselswede\\n.\\nBefore using the tools, please read this disclaimer:\\nThe SAP HANA Tools are not SAP official software, so normal SAP support of SAP HANA\\nTools cannot be assumed.\\nThe SAP HANA Tools are open source.\\nUnit 5: Appendix: HANA Additional Scripts\\n© Copyright. All rights reserved.\\n192'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 198}, page_content='The SAP HANA Tools are provided \"as is\".\\nThe SAP HANA Tools are to be used at \"your own risk\".\\nThe SAP HANA Tools are a one-man\\'s hobby; developed, maintained and supported only\\nduring non-working hours.\\nPlease read all the SAP HANA Tools documentation before using the tools.\\nThe landscapeHostConfiguration.py Script\\nFigure 120: The landscapeHostConfiguration.py Script\\nDuring the exercises in Unit 2 and Unit 4, we used the script landscapeHostConfiguration.py\\nseveral times. This script is very useful to quickly get a complete overview of the landscape\\nsetup of a multi-host SAP HANA system.\\nAs the OS user <sid>adm, you can use the script landscapeHostConfiguration.py in the\\npython_support folder to display topology information. Unlike the monitoring views, this\\napproach can also be used when SAP HANA is down.\\nAs found in the help documentation of the landscapeHostConfiguration.py script, it can be\\nrun in three different modes.\\nlandscapeHostConfiguration.py [--localhost] [--sapcontrol=1]\\n1. Running the script without an additional command line option gives the overview as shown\\nin the previous figure.\\n2. Running the script with the optional command line option \\n--localhost\\n shows only the\\nconfiguration of the host where the script was started.\\n3. Running the script with the optional command line option \\n--sapcontrol=1\\n shows a\\ndetailed output of all landscape configuration settings and environment variables for each\\nhost. This is very useful when troubleshooting a failover problem using the command line.\\nUseful SAP Notes\\nSAP Note: 2000003 - FAQ: SAP HANA\\nSAP Note: 2340501 - Prohibit execution of hdbnsutil, systemReplicationStatus.py and\\nlandscapeHostConfiguration.py as root user\\nSAP Note: 2518979 - HANA : how to check system replication status\\nLesson: Appendix: Using Python Support Scripts in SAP HANA\\n© Copyright. All rights reserved.\\n193'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 199}, page_content='The systemReplicationStatus.py Script\\nFigure 121: The systemReplicationStatus.py Script\\nDuring the exercises in Unit 4, we used the script systemReplicationStatus.py several times.\\nThis script is very useful to quickly check the overall status of the system replication setup\\nusing the command line.\\nYou can monitor SAP HANA system replication using a command line script. Check the\\noverall status of the system replication using the script systemReplicationStatus.py as the\\n<sid>adm user.\\nThe script provides the following return codes:\\n10: No System Replication\\n11: Error\\n12: Unknown\\n13: Initializing\\n14: Syncing\\n15: Active\\nUseful SAP Notes\\nSAP Note: 2518979 - HANA : how to check system replication status\\nLESSON SUMMARY\\nYou should now be able to:\\nUnderstand the Python support scripts used in SAP HANA\\nUnit 5: Appendix: HANA Additional Scripts\\n© Copyright. All rights reserved.\\n194'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 200}, page_content='Unit 5\\nLesson 2\\nAppendix: Reinitializing a Non-Recoverable\\nSystem Database\\nLESSON OBJECTIVES\\nAfter completing this lesson, you will be able to:\\nReinitialize a non-recoverable system database\\nReinitialize a System Database\\nThe system DB is corrupted and cannot startup anymore, but all tenants are still working. You\\nneed to recreate your system DB and do not have a backup.\\nIn this situation it is possible to reinitialize the system DB instead of recovering the whole\\nsystem with all tenants.\\nThe command-line tool HDBMDCUTIL allows you to reinitialize the system database with\\ninformation on all tenant databases of the SAP HANA instance.\\nCaution:\\nThis feature will not restore any other data previously stored in the system\\ndatabase. This data, for example license information, users, delivery units,\\nsecurity templates and others, has to be restored manually using the SQL\\ninterface or other user interfaces and/or tools.\\nBecause of this limitation, the system database should always be recovered from a backup\\ninstead of using the HDBMDCUTIL tool.\\n© Copyright. All rights reserved.\\n195'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 201}, page_content='Figure 122: Reinitialize of a SystemDB\\nReinitialize a System Database Using the Command-Line Tool hdbmdcutil\\n1. Stop the SAP HANA system. Ensure that all hosts and services that are part of this system\\nhave been stopped.\\n2. Start the HDBMDCUTIL tool with the -restoreTopology option: \\nhdbmdcutil -\\nrestoreTopology\\nTo provide the password of the SYSTEM user of the system database, use the --\\nset_user_system_pw option:\\nhdbmdcutil -restoreTopology --set_user_system_pw\\n3. Enter the password of the SYSTEM user. Do not provide the password in the command\\nline.\\n4. Start the SAP HANA system.\\nFigure 123: Reinitialize System Database: Additional Information\\nLESSON SUMMARY\\nYou should now be able to:\\nReinitialize a non-recoverable system database\\nUnit 5: Appendix: HANA Additional Scripts\\n© Copyright. All rights reserved.\\n196'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 202}, page_content='Unit 5\\nLearning Assessment\\n1. The HDBAdmin tool is the primary monitoring tool for SAP HANA, and is fully supported\\nby SAP support.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\n2. Which SAP HANA tool can be used to automatically check the availability of the SAP\\nHANA database?\\nChoose the correct answer.\\nX\\nA HDBAdmin\\nX\\nB HANAsitter\\nX\\nC HANAcleaner\\nX\\nD HDBscheduler\\n3. Which part of the data is restored when you reinitialize a non-recoverable system\\ndatabase?\\nChoose the correct answer.\\nX\\nA License information\\nX\\nB Topology of the system database\\nX\\nC Delivery units\\nX\\nD Users and Roles\\n© Copyright. All rights reserved.\\n197'),\n",
                            " Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2021-04-28T17:10:09+00:00', 'source': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'file_path': '../data/pdf/HA201 - SAP HANA 2.0 SPS05 - High Availability and Disaster Tolerance Administration.pdf', 'total_pages': 204, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20210428171009Z', 'page': 203}, page_content='Unit 5\\nLearning Assessment - Answers\\n1. The HDBAdmin tool is the primary monitoring tool for SAP HANA, and is fully supported\\nby SAP support.\\nDetermine whether this statement is true or false.\\nX\\nTrue\\nX\\nFalse\\nYou are correct! The HDBAdmin tool is an internal SAP support tool. The customer can\\nuse it, but it is not supported by SAP.\\n2. Which SAP HANA tool can be used to automatically check the availability of the SAP\\nHANA database?\\nChoose the correct answer.\\nX\\nA HDBAdmin\\nX\\nB HANAsitter\\nX\\nC HANAcleaner\\nX\\nD HDBscheduler\\nYou are correct! HANAsitter can be used to automatically check the availability of the SAP\\nHANA database.\\n3. Which part of the data is restored when you reinitialize a non-recoverable system\\ndatabase?\\nChoose the correct answer.\\nX\\nA License information\\nX\\nB Topology of the system database\\nX\\nC Delivery units\\nX\\nD Users and Roles\\nYou are correct! Reinitialization of the system database does not restore any data\\npreviously stored in the system database. This data, for example license information,\\nusers, delivery units, and security templates has to be restored manually.\\n© Copyright. All rights reserved.\\n198')]"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
                "\n",
                "## load all the text files from the directory\n",
                "dir_loader=DirectoryLoader(\n",
                "    \"../data/pdf\",\n",
                "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
                "    loader_cls= PyMuPDFLoader, ##loader class to use\n",
                "    show_progress=False\n",
                "\n",
                ")\n",
                "\n",
                "pdf_documents=dir_loader.load()\n",
                "pdf_documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "8ddf0651",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import chromadb\n",
                "from chromadb.config import Settings\n",
                "import uuid\n",
                "from typing import List, Dict, Any, Tuple\n",
                "from sklearn.metrics.pairwise import cosine_similarity"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
